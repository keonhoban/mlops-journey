+++
date = '2025-06-10T19:49:29+09:00'
draft = false
title = '[Airflow - 5단계: PythonOperator + MLflow Tracking 연동]'
categories = 'Airflow'
+++

> 목표
> 
> 
> PythonOperator를 사용하여 MLflow로 실험(모델 학습)을 자동화하고, 파라미터, 메트릭, 모델을 기록하는 방법을 학습합니다.
> 

👉 실습 코드는 [🔗 GitHub (Mlflow - Tracking + FastAPI)](https://github.com/keonhoban/mlops-infra-labs/tree/main/airflow/05_Airflow_and_MLflow)

---

## 🧭 실습 전체 흐름 요약

```
[1단계] MLflow 실험 스크립트 작성
[2단계] Airflow DAG 구성
[3단계] DAG 실행 및 파라미터/메트릭 확인
[4단계] 모델 저장 및 로깅 상태 점검
```

---

## 📁 디렉토리 구조

```
airflow/
├── dags/
│   ├── train_with_mlflow.py        ← DAG 파일
├── ml_code/
│   ├── train_mlflow.py             ← MLflow 연동 학습 스크립트
└── mlruns/                         ← MLflow 로깅 결과 저장 폴더 (자동 생성)
```

---

## 🧪 1단계: MLflow 학습 스크립트 작성

```python
# airflow/ml_code/train_mlflow.py

import mlflow
import mlflow.sklearn
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

def run_experiment():
    mlflow.set_tracking_uri("file:/opt/airflow/mlruns")
    mlflow.set_experiment("airflow_mlflow_example")

    with mlflow.start_run():
        # 데이터 로딩
        data = load_iris()
        X, y = data.data, data.target

        # 모델 정의
        model = RandomForestClassifier(n_estimators=50, max_depth=3)
        model.fit(X, y)
        preds = model.predict(X)

        acc = accuracy_score(y, preds)

        # MLflow 기록
        mlflow.log_param("n_estimators", 50)
        mlflow.log_param("max_depth", 3)
        mlflow.log_metric("accuracy", acc)

        mlflow.sklearn.log_model(model, "model")
```

---

## 🧪 2단계: Airflow DAG 작성

```python
# airflow/dags/train_with_mlflow.py

from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import sys
sys.path.append("/opt/airflow/ml_code")

from train_mlflow import run_experiment

with DAG(
    dag_id='mlflow_tracking_dag',
    start_date=datetime(2023, 1, 1),
    schedule_interval=None,
    catchup=False,
) as dag:

    run_mlflow = PythonOperator(
        task_id='run_mlflow_training',
        python_callable=run_experiment,
    )
```

---

## ✅ 실행 절차

1. `train_mlflow.py` 작성
2. `train_with_mlflow.py` DAG 등록
3. Airflow UI에서 DAG 실행
4. Task 로그에서 파라미터/메트릭/모델 기록 확인

---

## ❓모듈 에러가 발생하면?

1. `docker-compose.yaml`에서 `volumes:` 항목 확인
    
    ```yaml
    volumes:
      - ./ml_code:/opt/airflow/ml_code
    ```
    
2. `docker-compose restart`로 컨테이너 재시작

---

## 🔧 `requirements.txt` 추가 및 Docker 재빌드

1. `requirements.txt` 파일에 MLflow 추가:
    
    ```
    mlflow
    ```
    
2. `docker-compose.yaml`에서 서비스에 `build` 설정 추가:
    
    ```yaml
    services:
      airflow-webserver:
        build:
          context: .
          dockerfile: Dockerfile
    ```
    
3. Dockerfile 작성:
    
    ```
    FROM apache/airflow:2.8.2
    COPY requirements.txt /requirements.txt
    RUN pip install -r /requirements.txt
    ```
    
4. Docker 재빌드:
    
    ```bash
    docker-compose down
    docker-compose build
    docker-compose up -d
    ```
    

---

## 🔍 확인 포인트

| 항목 | 확인 방법 |
| --- | --- |
| MLflow 로그 | `/opt/airflow/mlruns/` 경로에서 확인 |
| 정확도 로그 | DAG 로그에서 `acc = ...` 확인 |
| DAG 이름 | `mlflow_tracking_dag` |
| Experiment 이름 | `airflow_mlflow_example` |

---

## 🧩 실무 팁

| 항목 | 설명 |
| --- | --- |
| mlruns 디렉토리 | MLflow 실험 결과 자동 기록 |
| 실무 확장 | `train.py`, `predict.py`, `evaluate.py` 등을 모듈화하여 DAG 연계 가능 |
| MLflow Registry | 레지스트리에 모델 등록 후 배포 파이프라인 구성 |

---

## 🔧 MLOps 실전 연결

- Airflow는 MLflow/Kubeflow와 함께 **워크플로우 자동화**의 핵심 도구
- ML 데이터 전처리 → 모델 학습 → 평가/배포를 DAG로 설계 가능
- 이후, Airflow + ML 모델 학습/서빙 파이프라인 구성 예정
