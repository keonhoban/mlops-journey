+++
date = '2025-07-10T17:12:00+09:00'
draft = false
title = '[MLOps í”Œë«í¼ êµ¬ì¶• - 6ë‹¨ê³„: ì‹¤ì‹œê°„ ëª¨ë¸ í•«ìŠ¤ì™‘ êµ¬ì¡° ì‹¤í—˜]'
categories = ['MLOps Pipeline', 'Airflow', 'MLflow', 'FastAPI', 'NFS', 'PostgreSQL', 'AWS', 'Kubernetes', 'Helm', 'Git', '']
+++

## ğŸ§  ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…

> ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ì‹¤ì„œë¹„ìŠ¤ì— ë°°í¬í•  ë•Œ,
> ê¸°ì¡´ ëª¨ë¸ì„ ìƒˆ ëª¨ë¸ë¡œ ì•ˆì „í•˜ê²Œ êµì²´(hot-swap)í•˜ëŠ” ìë™í™” êµ¬ì¡°ëŠ”
> ë§¤ìš° ì¤‘ìš”í•œ ìš”êµ¬ì‚¬í•­ì…ë‹ˆë‹¤.

---

## âœ… TL;DR

- `Airflow`ì—ì„œ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ì¡°ê±´ë¶€ë¡œ ëª¨ë¸ ë“±ë¡
- ì„±ëŠ¥ ê¸°ì¤€ì„ ì¶©ì¡±í•œ ëª¨ë¸ì€ `Staging`ìœ¼ë¡œ ìë™ ìŠ¹ê²©
- `FastAPI`ëŠ” `/reload` ìš”ì²­ ì‹œ `Staging ëª¨ë¸`ì„ ë‹¤ì‹œ ë¡œë”© â†’ ì½”ë“œ ìˆ˜ì • ì—†ì´ í•«ìŠ¤ì™‘
- **ìš´ì˜ í™˜ê²½ì—ì„œì˜ ì‹¤í—˜ ìë™í™”, ëª¨ë¸ A/B í…ŒìŠ¤íŠ¸, ëª¨ë¸ ë¡¤ë°±** ë“±ì— í™•ì¥ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„

---

## ğŸ§  êµ¬ì¡° ë‹¤ì´ì–´ê·¸ë¨ (í•«ìŠ¤ì™‘ íë¦„)

![06](/mlops-journey/images/06.png)

---

## ğŸ§© í•µì‹¬ êµ¬ì„± ìš”ì†Œ

### 1. Airflow DAG - ì¡°ê±´ë¶€ ëª¨ë¸ ë“±ë¡

```python
# dags/dag_ml_experiment.py
from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from airflow.operators.empty import EmptyOperator
from airflow.models import Variable
from datetime import datetime, timedelta, timezone
import sys
sys.path.append('/opt/airflow/dags/repo/ml_code')
from train_and_log_model_fastapi import train_model

default_args = {
    'start_date': datetime.now(timezone.utc) - timedelta(days=1)
}

def run_and_check():
    # Variableë¡œ íŒŒë¼ë¯¸í„° ë™ì  ì œì–´
    try:
        C = float(Variable.get("logreg_C", default_var=1.0))
        max_iter = int(Variable.get("logreg_max_iter", default_var=200))
    except Exception as e:
        print(f"[ERROR] íŒŒë¼ë¯¸í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}. ê¸°ë³¸ê°’ ì‚¬ìš©.")
        C, max_iter = 1.0, 200

    # ì •í™•ë„ ê¸°ì¤€ìœ¼ë¡œ ì„±ê³µ/ì‹¤íŒ¨ ë¶„ê¸°
    acc = train_model(C=C, max_iter=max_iter)
    if acc > 0.9:
        return 'notify_success'
    else:
        return 'notify_failure'

def notify_success():
    print("ğŸ‰ ëª¨ë¸ ë“±ë¡ ë° í•«ìŠ¤ì™‘ ì„±ê³µ! FastAPIì— ìµœì‹  ëª¨ë¸ ë°˜ì˜ ì™„ë£Œ.")

def notify_failure():
    print("âŒ ì„±ëŠ¥ ê¸°ì¤€ ë¯¸ë‹¬. ëª¨ë¸ ë“±ë¡/ì„œë¹™ ìƒëµë¨.")

with DAG(
    dag_id="mlflow_experiment_conditional_register_runner_fastapi",
    default_args=default_args,
    schedule=None,
    catchup=False,
) as dag:

    branch_task = BranchPythonOperator(
        task_id='branch_by_accuracy',
        python_callable=run_and_check
    )

    success_notify_task = PythonOperator(
        task_id='notify_success',
        python_callable=notify_success
    )

    failure_notify_task = PythonOperator(
        task_id='notify_failure',
        python_callable=notify_failure
    )

    branch_task >> [success_notify_task, failure_notify_task]
```

---

### 2. ëª¨ë¸ í•™ìŠµ ë° ë“±ë¡

```python
# ml_code/train_and_log_model_fastapi.py
import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import sys
import requests
import time

mlflow.set_tracking_uri("http://mlflow-service.mlflow.svc.cluster.local:5000")
mlflow.set_experiment("train_and_register_model_exp")

def train_model(C, max_iter):
    X, y = load_iris(return_X_y=True)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    with mlflow.start_run() as run:
        clf = LogisticRegression(C=C, max_iter=max_iter)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        acc = accuracy_score(y_test, y_pred)

        mlflow.log_param("C", C)
        mlflow.log_param("max_iter", max_iter)
        mlflow.log_metric("accuracy", acc)
        mlflow.sklearn.log_model(clf, "model")

        print(f"[INFO] Logged model with accuracy={acc}")

        if acc > 0.9:
            # ëª¨ë¸ ë“±ë¡
            result = mlflow.register_model(
                model_uri=f"runs:/{run.info.run_id}/model",
                name="best_model"
            )
            version = result.version

            print(f"[INFO] âœ… ëª¨ë¸ ë“±ë¡ ì™„ë£Œ (version={version})")

            # ë“±ë¡ ì§í›„ DB ì—…ë°ì´íŠ¸ ì‹œê°„ í•„ìš”
            time.sleep(3)

            # ìŠ¤í…Œì´ì§€ ìŠ¹ê²© + ê¸°ì¡´ ë²„ì „ Archive
            client = MlflowClient()
            client.transition_model_version_stage(
                name="best_model",
                version=version,
                stage="Staging",
                archive_existing_versions=False  # ìŠ¤í…Œì´ì§•ì€ ì—¬ëŸ¬ ê°œ ê°€ëŠ¥
            )
            print(f"[INFO] ğŸš€ ëª¨ë¸ version {version} â†’ Staging ë°˜ì˜ ì™„ë£Œ")

            # FastAPI í•«ìŠ¤ì™‘ ìš”ì²­ (reload í˜¸ì¶œ)
            try:
                response = requests.post("http://fastapi.local/reload")
                print(f"[INFO] ğŸ” FastAPI ëª¨ë¸ ë¦¬ë¡œë“œ ìš”ì²­ ê²°ê³¼: {response.status_code} {response.text}")
            except Exception as e:
                print(f"[ERROR] âŒ FastAPI ë¦¬ë¡œë“œ ìš”ì²­ ì‹¤íŒ¨: {str(e)}")

        else:
            print("[WARN] âŒ ì„±ëŠ¥ ê¸°ì¤€ ë¯¸ë‹¬ (accuracy <= 0.9)")

        # ëª¨ë¸ ë²„ì „ ì¶œë ¥ (ì „í›„ ë¹„êµ ê°€ëŠ¥)
        client = MlflowClient()
        versions = client.get_latest_versions("best_model", stages=["None", "Staging", "Production"])
        for v in versions:
            print(f"[INFO] ğŸ”„ ëª¨ë¸ Version={v.version}, Stage={v.current_stage}")

        return acc

if __name__ == "__main__":
    acc = train_model(float(sys.argv[1]), int(sys.argv[2]))
```

---

### 3. FastAPI ëª¨ë¸ ì¬ë¡œë”© êµ¬ì¡°

```python
# FastAPI app/main.py
from fastapi import FastAPI, Request
import mlflow.pyfunc
import mlflow
from mlflow.tracking import MlflowClient
import os

app = FastAPI()
model = None
model_info = {}

def load_model_from_mlflow():
    global model, model_info

    tracking_uri = os.environ.get("MLFLOW_TRACKING_URI")
    model_name = os.environ.get("MODEL_NAME")
    model_stage = os.environ.get("MODEL_STAGE", "Staging")

    mlflow.set_tracking_uri(tracking_uri)
    model_uri = f"models:/{model_name}/{model_stage}"

    model = mlflow.pyfunc.load_model(model_uri)

    client = MlflowClient()
    latest = client.get_latest_versions(name=model_name, stages=[model_stage])[0]
    run_id = latest.run_id
    version = latest.version

    print(f"âœ… Reloaded model: name={model_name}, stage={model_stage}, version={version}, run_id={run_id}")
    model_info = {
        "model_name": model_name,
        "stage": model_stage,
        "version": version,
        "run_id": run_id,
        "model_uri": model_uri,
    }

@app.on_event("startup")
def startup_event():
    load_model_from_mlflow()

@app.get("/")
def root():
    return {"message": "FastAPI MLOps is running!"}

# í˜„ì¬ ëª¨ë¸ í™•ì¸ ê°€ëŠ¥
@app.get("/model-info")
def get_model_info():
    return model_info

@app.post("/predict")
async def predict(request: Request):
    input_data = await request.json()
    prediction = model.predict(input_data)
    return {"prediction": prediction.tolist()}

# Staging ëª¨ë¸ ë‹¤ì‹œ ë¡œë“œ
@app.post("/reload")
def reload_model():
    try:
        load_model_from_mlflow()
        return {"status": "success", "message": "ğŸ” Model reloaded successfully."}
    except Exception as e:
        return {"status": "error", "message": f"Reload failed: {str(e)}"}

```

---

## âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½

- `logreg_C`, `logreg_max_iter` íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµ DAG ì„¤ì • ê°€ëŠ¥
- ëª¨ë¸ ë“±ë¡ ì‹œ `Staging`ìœ¼ë¡œ ìë™ ìŠ¹ê²©
- FastAPI ì„œë²„ì— `/reload` í˜¸ì¶œ ì‹œ í•«ìŠ¤ì™‘ ì ìš©ë¨
- `/model-info`, `/predict`ì—ì„œ ìƒˆë¡œìš´ ëª¨ë¸ ì •ë³´ ë° ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸ ì™„ë£Œ

---

## ğŸ“ í…ŒìŠ¤íŠ¸ ê²€ì¦ (ëª¨ë¸ ë“±ë¡ + í•«ìŠ¤ì™‘ í™•ì¸)

```bash
# ê¸°ì¡´ ëª¨ë¸ ë²„ì „ í™•ì¸
curl http://fastapi.local/model-info | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   144  100   144    0     0  19251      0 --:--:-- --:--:-- --:--:-- 20571
{
  "model_name": "best_model",
  "stage": "Staging",
  "version": "1",
  "run_id": "8bd09505eabf40648337e811110ab22c",
  "model_uri": "models:/best_model/Staging"
}

# ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
curl -X POST http://fastapi.local/predict \
  -H "Content-Type: application/json" \
  -d '[ [5.1, 3.5, 1.4, 0.2] ]' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    42  100    18  100    24    311    415 --:--:-- --:--:-- --:--:--   736
{
  "prediction": [
    0
  ]
}

# ëª¨ë¸ reload (í•«ìŠ¤ì™‘)
curl -X POST http://fastapi.local/reload | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    66  100    66    0     0    186      0 --:--:-- --:--:-- --:--:--   186
{
  "status": "success",
  "message": "ğŸ” Model reloaded successfully."
}

# ì‹ ê·œ ëª¨ë¸ ë²„ì „ í™•ì¸
curl http://fastapi.local/model-info | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   144  100   144    0     0  42985      0 --:--:-- --:--:-- --:--:-- 48000
{
  "model_name": "best_model",
  "stage": "Staging",
  "version": "2",
  "run_id": "72f388927f5749c185b828a1a16bb063",
  "model_uri": "models:/best_model/Staging"
}

# ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
curl -X POST http://fastapi.local/predict \
  -H "Content-Type: application/json" \
  -d '[ [5.1, 3.5, 1.4, 0.2] ]' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    42  100    18  100    24   3831   5108 --:--:-- --:--:-- --:--:-- 10500
{
  "prediction": [
    0
  ]
}
```
