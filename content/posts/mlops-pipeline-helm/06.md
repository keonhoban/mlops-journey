+++
date = '2025-07-10T17:12:00+09:00'
draft = false
title = '[MLOps 플랫폼 구축 - 6단계: 실시간 모델 핫스왑 구조 실험]'
categories = ['MLOps Pipeline', 'Airflow', 'MLflow', 'FastAPI', 'NFS', 'PostgreSQL', 'AWS', 'Kubernetes', 'Helm', 'Git', '']
+++

## 🧠 시나리오 설명

> 머신러닝 모델을 실서비스에 배포할 때,
> 기존 모델을 새 모델로 안전하게 교체(hot-swap)하는 자동화 구조는
> 매우 중요한 요구사항입니다.

---

## ✅ TL;DR

- `Airflow`에서 학습 스크립트를 실행하고 조건부로 모델 등록
- 성능 기준을 충족한 모델은 `Staging`으로 자동 승격
- `FastAPI`는 `/reload` 요청 시 `Staging 모델`을 다시 로딩 → 코드 수정 없이 핫스왑
- **운영 환경에서의 실험 자동화, 모델 A/B 테스트, 모델 롤백** 등에 확장 가능하도록 설계

---

## 🧠 구조 다이어그램 (핫스왑 흐름)

![06](/mlops-journey/images/06.png)

---

## 🧩 핵심 구성 요소

### 1. Airflow DAG - 조건부 모델 등록

```python
# dags/dag_ml_experiment.py
from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from airflow.operators.empty import EmptyOperator
from airflow.models import Variable
from datetime import datetime, timedelta, timezone
import sys
sys.path.append('/opt/airflow/dags/repo/ml_code')
from train_and_log_model_fastapi import train_model

default_args = {
    'start_date': datetime.now(timezone.utc) - timedelta(days=1)
}

def run_and_check():
    # Variable로 파라미터 동적 제어
    try:
        C = float(Variable.get("logreg_C", default_var=1.0))
        max_iter = int(Variable.get("logreg_max_iter", default_var=200))
    except Exception as e:
        print(f"[ERROR] 파라미터 불러오기 실패: {str(e)}. 기본값 사용.")
        C, max_iter = 1.0, 200

    # 정확도 기준으로 성공/실패 분기
    acc = train_model(C=C, max_iter=max_iter)
    if acc > 0.9:
        return 'notify_success'
    else:
        return 'notify_failure'

def notify_success():
    print("🎉 모델 등록 및 핫스왑 성공! FastAPI에 최신 모델 반영 완료.")

def notify_failure():
    print("❌ 성능 기준 미달. 모델 등록/서빙 생략됨.")

with DAG(
    dag_id="mlflow_experiment_conditional_register_runner_fastapi",
    default_args=default_args,
    schedule=None,
    catchup=False,
) as dag:

    branch_task = BranchPythonOperator(
        task_id='branch_by_accuracy',
        python_callable=run_and_check
    )

    success_notify_task = PythonOperator(
        task_id='notify_success',
        python_callable=notify_success
    )

    failure_notify_task = PythonOperator(
        task_id='notify_failure',
        python_callable=notify_failure
    )

    branch_task >> [success_notify_task, failure_notify_task]
```

---

### 2. 모델 학습 및 등록

```python
# ml_code/train_and_log_model_fastapi.py
import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import sys
import requests
import time

mlflow.set_tracking_uri("http://mlflow-service.mlflow.svc.cluster.local:5000")
mlflow.set_experiment("train_and_register_model_exp")

def train_model(C, max_iter):
    X, y = load_iris(return_X_y=True)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    with mlflow.start_run() as run:
        clf = LogisticRegression(C=C, max_iter=max_iter)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        acc = accuracy_score(y_test, y_pred)

        mlflow.log_param("C", C)
        mlflow.log_param("max_iter", max_iter)
        mlflow.log_metric("accuracy", acc)
        mlflow.sklearn.log_model(clf, "model")

        print(f"[INFO] Logged model with accuracy={acc}")

        if acc > 0.9:
            # 모델 등록
            result = mlflow.register_model(
                model_uri=f"runs:/{run.info.run_id}/model",
                name="best_model"
            )
            version = result.version

            print(f"[INFO] ✅ 모델 등록 완료 (version={version})")

            # 등록 직후 DB 업데이트 시간 필요
            time.sleep(3)

            # 스테이지 승격 + 기존 버전 Archive
            client = MlflowClient()
            client.transition_model_version_stage(
                name="best_model",
                version=version,
                stage="Staging",
                archive_existing_versions=False  # 스테이징은 여러 개 가능
            )
            print(f"[INFO] 🚀 모델 version {version} → Staging 반영 완료")

            # FastAPI 핫스왑 요청 (reload 호출)
            try:
                response = requests.post("http://fastapi.local/reload")
                print(f"[INFO] 🔁 FastAPI 모델 리로드 요청 결과: {response.status_code} {response.text}")
            except Exception as e:
                print(f"[ERROR] ❌ FastAPI 리로드 요청 실패: {str(e)}")

        else:
            print("[WARN] ❌ 성능 기준 미달 (accuracy <= 0.9)")

        # 모델 버전 출력 (전후 비교 가능)
        client = MlflowClient()
        versions = client.get_latest_versions("best_model", stages=["None", "Staging", "Production"])
        for v in versions:
            print(f"[INFO] 🔄 모델 Version={v.version}, Stage={v.current_stage}")

        return acc

if __name__ == "__main__":
    acc = train_model(float(sys.argv[1]), int(sys.argv[2]))
```

---

### 3. FastAPI 모델 재로딩 구조

```python
# FastAPI app/main.py
from fastapi import FastAPI, Request
import mlflow.pyfunc
import mlflow
from mlflow.tracking import MlflowClient
import os

app = FastAPI()
model = None
model_info = {}

def load_model_from_mlflow():
    global model, model_info

    tracking_uri = os.environ.get("MLFLOW_TRACKING_URI")
    model_name = os.environ.get("MODEL_NAME")
    model_stage = os.environ.get("MODEL_STAGE", "Staging")

    mlflow.set_tracking_uri(tracking_uri)
    model_uri = f"models:/{model_name}/{model_stage}"

    model = mlflow.pyfunc.load_model(model_uri)

    client = MlflowClient()
    latest = client.get_latest_versions(name=model_name, stages=[model_stage])[0]
    run_id = latest.run_id
    version = latest.version

    print(f"✅ Reloaded model: name={model_name}, stage={model_stage}, version={version}, run_id={run_id}")
    model_info = {
        "model_name": model_name,
        "stage": model_stage,
        "version": version,
        "run_id": run_id,
        "model_uri": model_uri,
    }

@app.on_event("startup")
def startup_event():
    load_model_from_mlflow()

@app.get("/")
def root():
    return {"message": "FastAPI MLOps is running!"}

# 현재 모델 확인 가능
@app.get("/model-info")
def get_model_info():
    return model_info

@app.post("/predict")
async def predict(request: Request):
    input_data = await request.json()
    prediction = model.predict(input_data)
    return {"prediction": prediction.tolist()}

# Staging 모델 다시 로드
@app.post("/reload")
def reload_model():
    try:
        load_model_from_mlflow()
        return {"status": "success", "message": "🔁 Model reloaded successfully."}
    except Exception as e:
        return {"status": "error", "message": f"Reload failed: {str(e)}"}

```

---

## ✅ 테스트 결과 요약

- `logreg_C`, `logreg_max_iter` 파라미터로 학습 DAG 설정 가능
- 모델 등록 시 `Staging`으로 자동 승격
- FastAPI 서버에 `/reload` 호출 시 핫스왑 적용됨
- `/model-info`, `/predict`에서 새로운 모델 정보 및 예측 결과 확인 완료

---

## 🎓 테스트 검증 (모델 등록 + 핫스왑 확인)

```bash
# 기존 모델 버전 확인
curl http://fastapi.local/model-info | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   144  100   144    0     0  19251      0 --:--:-- --:--:-- --:--:-- 20571
{
  "model_name": "best_model",
  "stage": "Staging",
  "version": "1",
  "run_id": "8bd09505eabf40648337e811110ab22c",
  "model_uri": "models:/best_model/Staging"
}

# 예측 결과 확인
curl -X POST http://fastapi.local/predict \
  -H "Content-Type: application/json" \
  -d '[ [5.1, 3.5, 1.4, 0.2] ]' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    42  100    18  100    24    311    415 --:--:-- --:--:-- --:--:--   736
{
  "prediction": [
    0
  ]
}

# 모델 reload (핫스왑)
curl -X POST http://fastapi.local/reload | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    66  100    66    0     0    186      0 --:--:-- --:--:-- --:--:--   186
{
  "status": "success",
  "message": "🔁 Model reloaded successfully."
}

# 신규 모델 버전 확인
curl http://fastapi.local/model-info | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   144  100   144    0     0  42985      0 --:--:-- --:--:-- --:--:-- 48000
{
  "model_name": "best_model",
  "stage": "Staging",
  "version": "2",
  "run_id": "72f388927f5749c185b828a1a16bb063",
  "model_uri": "models:/best_model/Staging"
}

# 예측 결과 확인
curl -X POST http://fastapi.local/predict \
  -H "Content-Type: application/json" \
  -d '[ [5.1, 3.5, 1.4, 0.2] ]' | jq
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    42  100    18  100    24   3831   5108 --:--:-- --:--:-- --:--:-- 10500
{
  "prediction": [
    0
  ]
}
```
