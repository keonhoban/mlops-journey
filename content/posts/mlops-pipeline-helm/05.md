+++
date = '2025-07-07T17:11:55+09:00'
draft = false
title = '[MLOps 플랫폼 구축 - 5단계: FastAPI 서빙: MLflow 모델 연동 및 핫스왑 구조 구축]'
categories = ['FastAPI', 'AWS', 'Kubernetes', 'Helm']
+++

## 🧠 시나리오 설명

> “ 모델을 수동으로 넣는 것이 아니라,
> 
> MLflow에 등록된 Staging 모델을 서빙 API에서 **자동 로딩**하는 구조를 지향합니다.”
> 
- FastAPI는 경량화된 서빙 서버로서 적합
- MLflow `pyfunc.load_model()`을 통해 자동 로딩 → CI/CD 및 모델 자동화 가능
- S3와 연결되므로, “로컬 복사본 관리 X”, 재현성 유지
- API 호출을 통해 실제 추론 결과 확인 가능

---

## ✨ TL;DR

- MLflow에서 등록한 모델을 **FastAPI 기반 REST API**로 서빙합니다.
- `mlflow.pyfunc.load_model()`을 통해 **Stage별 버전 관리**, **핫스왑**, **모델 정보 조회**가 가능합니다.
- 쿠버네티스 기반으로 Helm Chart 배포 + AWS 인증 Secret + Ingress 접근까지 연동합니다.

---

## 📐 아키텍처 구성도

![05](/mlops-journey/images/05.png)

---

## 🐳 FastAPI 커스텀 이미지

### 📦 Dockerfile

```
FROM python:3.12

WORKDIR /app
COPY app /app
COPY requirements.txt .

RUN pip install --no-cache-dir -r requirements.txt

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 📄 requirements.txt

```
fastapi==0.110.2
uvicorn==0.29.0
mlflow==2.13.0
pandas==2.1.4
scikit-learn==1.6.1
pydantic==2.7.1
boto3==1.34.113
numpy==1.26.4
packaging==24.2
psutil==7.0.0
scipy==1.15.3
setuptools==69.5.1
```

### 🚀 빌드 & 푸시

```bash
docker build -t ghcr.io/hoizz/fastapi-ml:mlflow-model-info .
docker push ghcr.io/hoizz/fastapi-ml:mlflow-model-info
```

---

## 📄 app/main.py

```python
from fastapi import FastAPI, Request
import mlflow.pyfunc
import mlflow
from mlflow.tracking import MlflowClient
import os

app = FastAPI()
model = None
model_info = {}

def load_model_from_mlflow():
    global model, model_info

    tracking_uri = os.environ.get("MLFLOW_TRACKING_URI")
    model_name = os.environ.get("MODEL_NAME")
    model_stage = os.environ.get("MODEL_STAGE", "Production")

    mlflow.set_tracking_uri(tracking_uri)
    model_uri = f"models:/{model_name}/{model_stage}"

    model = mlflow.pyfunc.load_model(model_uri)

    client = MlflowClient()
    latest = client.get_latest_versions(name=model_name, stages=[model_stage])[0]
    run_id = latest.run_id
    version = latest.version

    print(f"✅ Reloaded model: name={model_name}, stage={model_stage}, version={version}, run_id={run_id}")
    model_info = {
        "model_name": model_name,
        "stage": model_stage,
        "version": version,
        "run_id": run_id,
        "model_uri": model_uri,
    }

@app.on_event("startup")
def startup_event():
    load_model_from_mlflow()

@app.get("/")
def root():
    return {"message": "FastAPI MLOps is running!"}

@app.get("/model-info")
def get_model_info():
    return model_info

@app.post("/predict")
async def predict(request: Request):
    input_data = await request.json()
    prediction = model.predict(input_data)
    return {"prediction": prediction.tolist()}
```

---

## 🛠️ Helm 배포 구성

### 🧾 values.yaml

```yaml
replicaCount: 1

image:
  repository: hoizz/fastapi-ml
  tag: mlflow-model-info
  pullPolicy: IfNotPresent

service:
  name: fastapi-service
  type: ClusterIP
  port: 80

ingress:
  enabled: true
  className: nginx
  host: fastapi.local
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /

env:
  MLFLOW_TRACKING_URI: "http://mlflow-service.mlflow.svc.cluster.local:5000"
  MODEL_NAME: "best_model"
  MODEL_STAGE: "Staging"

envFrom:
  - secretRef:
      name: aws-credentials-secret
```

---

## 📄 핵심 템플릿

### fastapi-deployment.yaml

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fastapi-server
  namespace: fastapi
spec:
  replicas: 1
  selector:
    matchLabels:
      app: fastapi
  template:
    metadata:
      labels:
        app: fastapi
    spec:
      containers:
        - name: fastapi
          image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
          ports:
            - containerPort: 8000
          env:
            - name: MLFLOW_TRACKING_URI
              value: {{ .Values.env.MLFLOW_TRACKING_URI }}
            - name: MODEL_NAME
              value: {{ .Values.env.MODEL_NAME }}
            - name: MODEL_STAGE
              value: {{ .Values.env.MODEL_STAGE }}
          envFrom:
            - secretRef:
                name: aws-credentials-secret
```

### fastapi-service.yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  name: fastapi-service
  namespace: fastapi
spec:
  type: {{ .Values.service.type }}
  selector:
    app: fastapi
  ports:
    - port: {{ .Values.service.port }}
      targetPort: 8000
```

### fastapi-ingress.yaml

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: fastapi-ingress
  namespace: fastapi
  annotations:
    {{- range $key, $value := .Values.ingress.annotations }}
    {{ $key }}: {{ $value | quote }}
    {{- end }}
spec:
  ingressClassName: {{ .Values.ingress.className }}
  rules:
    - host: {{ .Values.ingress.host }}
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: fastapi-service
                port:
                  number: {{ .Values.service.port }}
```

---

## ⏱ 배포

```bash
kubectl create namespace fastapi
helm install fastapi fastapi-helm -n fastapi

# hosts 수정
{node_ip} fastapi.local

# 접근 url
[http://fastapi.local](http://fastapi.local/)
```

---

## 🧩 Tip

| 항목 | 팁 |
| --- | --- |
| 모델 핫스왑 | `/model-info` API 제공 → 운영 시 버전 추적 필수 |
| 모델 미존재 | load_model 시 `MlflowException` 발생 → FastAPI가 죽지 않도록 예외 처리 |
| Ingress 설정 | `/etc/hosts`, className, rewrite-target 필수 확인 |
| 리소스 할당 | 배포 시 CPU/RAM 제한 설정으로 예측 지연 방지 |

---

## 🔧 MLOps 실전 연결

| 항목 | 실제 의미 |
| --- | --- |
| FastAPI REST 서빙 | 실시간 추론 API 운영에 적합 |
| mlflow Stage 사용 | 운영과 실험 모델 분리 및 핫스왑 가능 |
| boto3 연동 | S3 객체 접근, 로그 추적, 리포트 저장 자동화 |
| Helm 기반 배포 | 팀 내 재사용 가능한 마이크로서비스 패턴 완성 |

---

## 🧭 다음 포스트 예고

> 🧠 실시간 모델 핫스왑 구조 실험
> 
> 
> → Airflow에서 모델 학습 DAG을 실행하면, 
> MLflow에 모델이 자동 등록되고 FastAPI 서버를 리로드시 새로운 모델이 적용되도록 진행 예정입니다.
>
