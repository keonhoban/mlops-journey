+++
date = '2025-06-26T17:11:49+09:00'
draft = false
title = '[MLOps 플랫폼 구축 - 2단계: S3 & PostgreSQL 연동을 위한 보안 구성 및 Secret 관리 전략]'
categories = ['PostgreSQL', 'AWS', 'Kubernetes']
+++

## ✨ TL;DR

- 외부 리소스(AWS S3, DB 등)와 연결할 때, 인증 정보를 직접 코드나 YAML에 노출하는 건 보안상 위험
- Kubernetes에서는 `Secret`과 `ConfigMap`, 그리고 `envFrom`, `volumeMount` 방식을 조합하여 사용 가능
- 이번 포스팅에서는 MLflow, Airflow, FastAPI와 AWS S3 & PostgreSQL을 연동할 때 사용한 **Secret 구성 전략**과 마주친 이슈 및 해결책 공유

---

## 🧱 아키텍처 구성도

```mermaid
graph TD

subgraph Kubernetes Cluster
  MLflow[MLflow Pod]
  Airflow[Airflow Pod]
  FastAPI[FastAPI Pod]
end

subgraph Kubernetes Secrets
  Secret_AWS[(aws-credentials-secret)]
  Secret_DB_MLFLOW[(mlflow-db-secret)]
  Secret_DB_AIRFLOW[(airflow-db-secret)]
end

subgraph External Systems
  S3[(AWS S3)]
  DB[(PostgreSQL VM)]
end

%% Secret 주입
Secret_AWS --> MLflow
Secret_DB_MLFLOW --> MLflow

Secret_AWS --> FastAPI

Secret_AWS --> Airflow
Secret_DB_AIRFLOW --> Airflow

%% 외부 연동
MLflow --> S3
MLflow --> DB

FastAPI --> S3
FastAPI --> MLflow

Airflow --> S3
Airflow --> DB

```

---

## 🔐 왜 Secret 처리가 중요한가?

| 항목 | 이유 |
| --- | --- |
| AWS Access Key | 노출 시 데이터 삭제/탈취 위험 있음 |
| PostgreSQL 접속 URI | 내부망 DB 구조 노출 + Credential 유출 위험 |
| MLflow Tracking URI | 내부 시스템 구조 노출 가능 |

> ✅ 실무에선 반드시 인증정보를 Git에 노출하지 않고, 환경에 안전하게 주입할 수 있어야 함
> 
- 부득이하게 git에 업로드해야할 경우 SealedSecret 또는 SOPS 사용해 암호화 처리할 수 있음
    - .gitignore 등으로 아예 제외하는 방법도 가능

---

## 📦 S3 인증 정보 처리 전략

### 🔸 실습 환경 조건

- MLflow, FastAPI, Airflow에서 모두 `boto3`로 S3에 접근해야 함
- FastAPI는 `env` 방식으로 처리, Airflow는 `volumeMount` 방식이 안정적임

---

### ✅ Secret 생성 (env 방식 - MLflow & FastAPI)

```bash
kubectl create secret generic aws-credentials-secret \
  --from-literal=AWS_ACCESS_KEY_ID=your-access-key \
  --from-literal=AWS_SECRET_ACCESS_KEY=your-secret-key \
  --from-literal=MLFLOW_S3_ENDPOINT_URL=https://s3.ap-northeast-2.amazonaws.com \
  -n mlflow
```

> 🔐 envFrom.secretRef로 사용하면 환경변수로 바로 주입됨 → boto3가 자동 인식
> 

```yaml
envFrom:
  - secretRef:
      name: aws-credentials-secret
```

---

### ✅ Secret 생성 (volumeMount 방식 - Airflow 전용)

```bash
# .aws/credentials 파일 예시
[default]
aws_access_key_id = your-access-key
aws_secret_access_key = your-secret-key
region = ap-northeast-2
```

```bash
kubectl create secret generic aws-credentials-secret \
  --from-file=credentials=.aws/credentials \
  -n airflow
```

> Airflow는 Task마다 새 Pod가 뜨고 mlflow 와 S3 연동시 boto3 사용 
따라서, AWS EKS가 아닌 로컬 k8s 환경구조상  .aws 경로 마운트 방식이 안정적
> 

```yaml
extraVolumes:
  - name: aws-credentials
    secret:
      secretName: aws-credentials-secret
extraVolumeMounts:
  - name: aws-credentials
    mountPath: /home/airflow/.aws
    readOnly: true
```

---

## 🗄 PostgreSQL 접속 정보 관리 전략

### 🔸 목표

- Helm 차트 내부에서 `backend-store-uri` 혹은 `sql_alchemy_conn` 값을 직접 넣지 않음
- 대신 `Secret`이나 `ConfigMap`으로 구성 요소 분리

---

## 🔐 1. MLflow 접속 정보 구성 (🔀 Secret + ConfigMap 분리 방식)

> 목표: 실험 metadata 저장소(PostgreSQL)에 대한 안전한 연결 설정
> 

### 🧱 시크릿 & 설정 분리 방식

```bash
# 1-1. Secret: 인증 정보 (username/password)
kubectl create secret generic mlflow-db-secret \
  --from-literal=username=mlflow_user \
  --from-literal=password=mlflow1234 \
  -n mlflow

# 1-2. ConfigMap: 일반 정보 (host/port/dbname)
kubectl create configmap mlflow-db-config \
  --from-literal=host=192.168.18.142 \
  --from-literal=port=5432 \
  --from-literal=dbname=mlflow_db \
  -n mlflow
```

> 📦 Helm chart에서 env.valueFrom으로 조합하여 주입 가능
> 

```yaml
- name: DB_USER
  valueFrom:
    secretKeyRef:
      name: mlflow-db-secret
      key: username
- name: DB_PASSWORD
  valueFrom:
    secretKeyRef:
      name: mlflow-db-secret
      key: password
- name: DB_HOST
  valueFrom:
    configMapKeyRef:
      name: mlflow-db-config
      key: host
- name: DB_PORT
  valueFrom:
    configMapKeyRef:
      name: mlflow-db-config
      key: port
- name: DB_NAME
  valueFrom:
    configMapKeyRef:
      name: mlflow-db-config
      key: dbname
```

---

## 🔐 2. Airflow 접속 정보 구성 (🧩 통합 URI 방식)

> 목표: Airflow 메타 DB(PostgreSQL) URI를 단일 문자열로 관리
> 

```bash
kubectl create secret generic airflow-db-secret \
  --from-literal=connection="postgresql://airflow_user:airflow1234@192.168.18.142:5432/airflow_db" \
  -n airflow
```

> 📦 Helm values.yaml에서 metadataSecretName 으로 참조
> 

```yaml
data:
  metadataSecretName: airflow-db-secret
```

→ 내부적으로 `AIRFLOW__DATABASE__SQL_ALCHEMY_CONN` 환경변수로 설정됨

---

## 🔄 Secret 방식 정리 비교

| 방식 | 대상 | 장점 | 단점 |
| --- | --- | --- | --- |
| `envFrom.secretRef` | MLflow, FastAPI | 깔끔하고 가독성 좋음 | Airflow에서는 실패 가능성 존재 |
| `.aws` 마운트 | Airflow | Task Pod에서도 안정적 | 경로 구조 명확히 맞춰야 함 (boto3 대비) |
| base64 `Secret` | DB URI, 민감한 키 | Helm에서 깔끔히 관리 | Git에 올리면 암호화 없이 노출됨 (주의) |

---

## 🧩 실무 팁

- `kubectl create secret` 후에는 반드시 `kubectl describe secret` 또는 `env` 명령어로 실제 주입 여부를 확인할 것
- 민감한 키가 담긴 `.aws/credentials`, `values.yaml` 파일은 `.gitignore`에 포함하고 작업 완료 후 삭제
- 실무에서는 **SealedSecret**, **SOPS**, **External Secrets Operator** 등을 이용한 암호화 연동 고려해야 함

---

## 🔧 MLOps 실전 연결

| 연결 대상 | 실전에서의 의미 |
| --- | --- |
| S3 + MLflow | 모델 아티팩트 저장소로 필수. 인증 실패 시 실험/모델 로깅 전부 실패 |
| S3 + Airflow | S3 버킷에서 Data Load, Export 작업 수행 |
| DB URI + MLflow/Airflow | `backend-store-uri` 설정 실패 시 전체 서비스 로딩 실패 발생 |

---

## 🚨 트러블슈팅 예시

### 🔻 TS_01: Airflow DAG Task에서 `boto3` 인증 실패

| 증상 | 원인 | 해결 |
| --- | --- | --- |
| `botocore.exceptions.NoCredentialsError` | `env` 방식으로 주입했지만 Task Pod에는 적용되지 않음 | `.aws/credentials` 경로로 마운트 방식 사용해야 함 |

---

## 🧭 다음 포스트 예고

> 📦 MLflow 실전 배포: PostgreSQL + S3 연동, Helm 구성, 커스텀 이미지, Ingress 구성까지
> 
> 
> → MLflow를 Helm으로 완전하게 배포하는 과정을 작성할 예정입니다.
>
