+++
date = '2025-11-15T17:10:21+09:00'
draft = false
title = '[MLOps 플랫폼 Observability & Data Pipeline - 8단계 : Data Pipeline 고도화]'
categories = ['Data Pipeline', 'MLOps Pipeline', 'Kubernetes', 'Airflow', 'AWS', 'Python', 'Observability', 'Grafana', 'Loki']
+++

## Data Pipeline 고도화: 스키마/메타데이터 + KST 타임라인

---

## 🧠 시나리오 설명

> “이전 **MLOps 플랫폼 Observability & Data Pipeline - 7단계**에서 
우리는 S3 Raw → 전처리 → Feature CSV → S3 저장까지
> 
> 
> 동작하는 엔드투엔드 데이터 파이프라인(v1)을 만들었습니다.”
> 
> “하지만 실무 ML 플랫폼 입장에서는,
> 
> ‘그때 그 실행에서 어떤 데이터를, 어떤 품질로, 어느 버전에 저장했는지’가
> 
> **시간·버전·스키마·메타데이터**까지 한 번에 남아야 합니다.”
> 
> “그래서 이번 단계에서는 **기존 v1 파이프라인을 버리지 않고**,
> 
> 그 위에 **버전 디렉터리 구조 + schema.json + metadata.json + KST 타임라인**을 얹어
> 
> **실제 ML Feature Store에 더 가까운 v2 파이프라인**으로 고도화했습니다.”
> 

---

## 🎯 핵심 요약 (v1 → v2 변화 한눈에 보기)

이전 단계(v1)와 이번 단계(v2)의 차이를 먼저 정리하면:

- **저장 방식**
    - v1: `features_20251119.csv` 같은 **단일 CSV 파일**로 저장 (덮어쓰기 구조)
    - v2: 실행마다
        
        `.../features/daily_user_events/v_YYYYMMDDTHHMMSS/` 아래에
        
        - `feature.csv`
        - `schema.json`
        - `metadata.json`
            
            **3종 세트로 버전 디렉터리 생성**
            
- **시간/타임존**
    - v1: `datetime.utcnow().isoformat()` 기반 (명시적 타임존 관리 X)
    - v2: `datetime.now(KST)` 기반으로 **항상 한국 시간(KST)** 기준 기록
- **메타데이터**
    - v1: 데이터 품질/라인리지 정보는 **로그에만 존재**
    - v2:
        - `schema.json`: 컬럼/타입, pipeline_name, feature_version, created_at(KST)
        - `metadata.json`: source_raw_path, rows_raw, rows_feature, null_rate, valid 등
            
            → **나중에 다른 시스템에서 읽기만 해도 이 실행이 어떤 의미인지 바로 이해 가능**
            
- **코드 구조**
    - DAG: `dag_data_pipeline_daily.py` → `dag_data_pipeline_daily_v2.py` 추가 (기존도 유지)
    - 로직: `ml_code/data_pipeline.py` → `ml_code/data_pipeline_v2.py` 로 확장

이제 이 변화들이 코드와 구조에서 어떻게 드러나는지 단계별로 풀어보겠습니다.

---

## 1️⃣ 전체 구조 (v2 기준)

기본 플로우는 v1과 동일하지만,

**Feature 저장 이후의 S3 구조와 메타데이터가 완전히 달라진 상태**입니다.

![mermaid-datapipeline-advancement-01.png](/mlops-journey/images/mermaid-datapipeline-advancement-01.png)

---

## 2️⃣ 구성 요소 (v1 대비 추가/변경된 파일)

### ✅ DAG 레벨

- 기존: `dag_data_pipeline_daily.py` → `ml_code.data_pipeline` 사용
- 신규: `dag_data_pipeline_daily_v2.py` → `ml_code.data_pipeline_v2` 사용

> 두 DAG가 같이 존재하므로,
> 
> - `data_pipeline_daily_dev`: v1 구조 테스트용
> - `data_pipeline_daily_dev_v2`: 버전·스키마·메타데이터까지 포함된 v2 구조
>     
>     로 병행 운영/비교 가능하게 설계했습니다.
>     

### ✅ Python 로직 레벨

```bash
airflow-dags-dev/
 ├── dags/
 │    ├── dag_data_pipeline_daily.py        # v1
 │    ├── dag_data_pipeline_daily_v2.py     # v2
 │    └── ml_code/
 │         ├── data_pipeline.py             # v1 로직
 │         └── data_pipeline_v2.py          # v2 로직

```

- `data_pipeline.py`
    
    → “**CSV 하나 만들어 S3에 저장하는**” 단순한 ETL 파이프라인
    
- `data_pipeline_v2.py`
    
    → 같은 ETL 흐름 위에
    
    **버전 관리 + schema.json + metadata.json + KST 기반 시간 관리**를 얹은 파이프라인
    

---

## 3️⃣ v1 → v2: DAG 레벨에서 바뀐 점

### ■ v1: `dag_data_pipeline_daily.py`

```python
from ml_code.data_pipeline import (
    extract_raw_data,
    validate_data,
    build_features,
    store_features,
    summarize_run,
)

def _get_pipeline_config():
    try:
        raw_path = Variable.get(
            "dp_raw_path",
            default_var="s3://datapipeline-raw-data-keonho/daily/user_events_20251119.csv"
        )

        feature_path = Variable.get(
            "dp_feature_path",
            default_var="s3://datapipeline-raw-data-keonho/features/user_events_feat_20251119.csv"
        )
        ...

```

- `feature_path`는 **최종 파일 경로**:
    - `.../features/user_events_feat_20251119.csv`
- `store_features()`가 이 경로에 그대로 `put_object` → **실행할 때마다 같은 파일 덮어쓰기**

---

### ■ v2: `dag_data_pipeline_daily_v2.py`

```python
from ml_code.data_pipeline_v2 import (
    extract_raw_data,
    validate_data,
    build_features,
    store_features,
    summarize_run,
)

def _get_pipeline_config():
    try:
        raw_path = Variable.get(
            "dp_raw_path",
            default_var="s3://datapipeline-raw-data-keonho/daily/user_events_20251119.csv"
        )

        feature_path = Variable.get(
            "dp_feature_path",
            default_var="s3://datapipeline-raw-data-keonho/features/daily_user_events/"
        )
        ...

```

- `feature_path`의 의미를 “디렉터리 프리픽스”로 변경:
    - `.../features/daily_user_events/`
- 실제 저장 시에는 내부에서 다음과 같이 쓰입니다.

```
s3://datapipeline-raw-data-keonho/features/daily_user_events/
  └── v_20251129T111532/
        ├── feature.csv
        ├── schema.json
        └── metadata.json

```

> ✅ DAG 입장에서는 변한 게 거의 없고,
> 
> 
> “feature_path를 파일 → 디렉터리 프리픽스로 바꿔서 v2 로직에 넘긴다” 정도만 달라졌습니다.
> 

---

## 4️⃣ Extract & Validate 단계 (v1과 거의 동일)

### ✔ extract_raw_data

- S3 `head_object`로 RAW 파일 존재 확인
- 성공 시 `dp_raw_path` XCom 저장

```python
def extract_raw_data(raw_path: str, pipeline_name: str, ti):
    s3 = _get_s3_client()
    bucket, key = _parse_s3_uri(raw_path)

    s3.head_object(Bucket=bucket, Key=key)

    ti.xcom_push(key="dp_raw_path", value=raw_path)

```

### ✔ validate_data

- CSV 전체 read
- row 수 / null_count / null_rate 계산
- 아주 간단한 룰:
    - `rows == 0` 이거나 `null_rate > 0.5` → invalid
- `dp_rows`, `dp_null_rate`, `dp_valid` XCom 푸시

v1에서도 존재하던 단계이고, v2에서는 **로그와 구현 스타일만 조금 정리된 정도**입니다.

---

## 5️⃣ v2의 핵심 ① — build_features에서 “스키마·메타데이터까지” 생성

### ■ v1: Feature CSV만 만들고 끝

```python
feature_header = ["row_sum"]
buf = io.StringIO()
writer = csv.writer(buf)
writer.writerow(feature_header)
writer.writerows(feature_rows)
feature_csv = buf.getvalue()

ti.xcom_push(key="dp_feature_csv", value=feature_csv)
ti.xcom_push(key="dp_feature_rows", value=len(feature_rows))
ti.xcom_push(key="dp_feature_path", value=feature_path)

```

- `row_sum` 하나짜리 Feature CSV만 XCom으로 전달
- 스키마/메타데이터는 **로그에만 존재**

---

### ■ v2: Feature + schema.json + metadata.json 설계

```python
from datetime import datetime, timezone, timedelta
KST = timezone(timedelta(hours=9))

def build_features(raw_path: str, feature_path: str, pipeline_name: str, ti):
    ...
    # row_sum feature_rows 계산 부분은 v1과 동일

    # --- schema.json ---
    schema = {
        "feature_version": None,                 # 나중에 store_features에서 채움
        "columns": {"row_sum": "float"},
        "created_at": datetime.now(KST).isoformat(),
        "pipeline_name": pipeline_name,
    }

    # --- metadata.json ---
    metadata = {
        "source_raw_path": raw_path,
        "rows_raw": ti.xcom_pull(key="dp_rows", task_ids="validate_data"),
        "rows_feature": len(feature_rows),
        "raw_null_rate": ti.xcom_pull(key="dp_null_rate", task_ids="validate_data"),
        "raw_valid": ti.xcom_pull(key="dp_valid", task_ids="validate_data"),
        "created_at": datetime.now(KST).isoformat(),
        "pipeline_name": pipeline_name,
    }

    # CSV 직렬화
    buf = io.StringIO()
    writer = csv.writer(buf)
    writer.writerow(["row_sum"])
    writer.writerows(feature_rows)
    feature_csv = buf.getvalue()

    ti.xcom_push(key="dp_feature_csv", value=feature_csv)
    ti.xcom_push(key="dp_feature_rows", value=len(feature_rows))
    ti.xcom_push(key="dp_feature_path", value=feature_path)
    ti.xcom_push(key="dp_schema_dict", value=schema)
    ti.xcom_push(key="dp_metadata_dict", value=metadata)

```

여기서 중요한 포인트는:

1. **KST 기준 타임라인**
    - `datetime.now(KST).isoformat()`
        
        → 블로그/운영에서 보는 시간 = **항상 한국 시간**
        
2. **schema.json 설계**
    - 어떤 컬럼이 어떤 타입인지, 언제 생성됐는지, 어느 파이프라인인지
    - 나중에 다른 시스템(Feature Store, Data Catalog 등)에서 읽을 때 **즉시 해석 가능**
3. **metadata.json 설계**
    - RAW → Feature 변환 시
        - row 수
        - null_rate
        - 유효성 여부
        - RAW 파일 경로
    - 데이터 품질/계보(lineage)를 **파일로 남기는 구조**

> 요약하면,
> 
> 
> “**이제 build_features는 단순 전처리 함수가 아니라,
> ‘Feature + 스키마 + 메타데이터 패키지’를 한 번에 만들어내는 단계**”로 고도화되었습니다.
> 

---

## 6️⃣ v2의 핵심 ② — store_features에서 “버전 디렉터리 + 3종 세트 저장”

### ■ v1: 단일 CSV 파일 저장

```python
bucket, key = _parse_s3_uri(feature_path)
s3.put_object(
    Bucket=bucket,
    Key=key,
    Body=feature_csv.encode("utf-8"),
    ContentType="text/csv",
)

```

- 매 실행마다 **같은 key에 덮어쓰기**
- 버전/실행 이력은 **별도 관리 없으면 잃어버림**

---

### ■ v2: 실행 시간 기반 버전 디렉터리 생성 (KST 기준)

```python
def store_features(feature_path: str, pipeline_name: str, ti):
    feature_csv = ti.xcom_pull(key="dp_feature_csv", task_ids="build_features")
    feature_rows = ti.xcom_pull(key="dp_feature_rows", task_ids="build_features")
    schema = ti.xcom_pull(key="dp_schema_dict", task_ids="build_features")
    metadata = ti.xcom_pull(key="dp_metadata_dict", task_ids="build_features")

    exec_date = getattr(ti, "execution_date", None)

    if exec_date is None:
        exec_date = datetime.now(KST)
    else:
        if exec_date.tzinfo is None:
            exec_date = exec_date.replace(tzinfo=timezone.utc).astimezone(KST)
        else:
            exec_date = exec_date.astimezone(KST)

    run_ts = exec_date.strftime("%Y%m%dT%H%M%S")
    version_id = f"v_{run_ts}"

    bucket, prefix = _parse_s3_uri(feature_path)
    if not prefix.endswith("/"):
        prefix += "/"

    base_prefix = f"{prefix}{version_id}/"
    ...

```

- Airflow `execution_date`를 기준으로, 항상 **KST 타임라인**으로 버전 생성
- `v_20251129T111532` 형태의 version_id 부여
- 이 version_id를 기준으로 **디렉터리 구조를 쪼갬**

---

### ■ v2: feature.csv + schema.json + metadata.json 동시 저장

```python
    # feature.csv
    s3.put_object(
        Bucket=bucket,
        Key=f"{base_prefix}feature.csv",
        Body=feature_csv.encode("utf-8"),
        ContentType="text/csv",
    )

    # schema.json
    schema["feature_version"] = version_id
    s3.put_object(
        Bucket=bucket,
        Key=f"{base_prefix}schema.json",
        Body=json.dumps(schema, ensure_ascii=False, indent=2).encode("utf-8"),
        ContentType="application/json",
    )

    # metadata.json
    s3.put_object(
        Bucket=bucket,
        Key=f"{base_prefix}metadata.json",
        Body=json.dumps(metadata, ensure_ascii=False, indent=2).encode("utf-8"),
        ContentType="application/json",
    )

    ti.xcom_push(key="dp_stored_rows", value=feature_rows)
    ti.xcom_push(key="dp_feature_version", value=version_id)
    ti.xcom_push(key="dp_feature_prefix", value=base_prefix)

```

S3 구조 예시는 다음과 같습니다.

```
s3://datapipeline-raw-data-keonho/features/daily_user_events/
  ├── v_20251129T111532/
  │     ├── feature.csv
  │     ├── schema.json
  │     └── metadata.json
  ├── v_20251129T141030/
  │     ├── feature.csv
  │     ├── schema.json
  │     └── metadata.json
  └── ...

```

> 이 구조 덕분에:
> 
> - 실행 시점별 버전 비교
> - 특정 날/실행 버전 재현
> - 스키마/품질 변화를 시간축에 따라 추적
>     
>     이 모두가 **파일 구조만 봐도 가능**해졌습니다.
>     

---

## 7️⃣ v2의 핵심 ③ — summarize_run: 버전까지 포함한 실행 요약

### ■ v1

```python
feature_path = ti.xcom_pull(key="dp_feature_path", task_ids="build_features")
stored_rows = ti.xcom_pull(key="dp_stored_rows", task_ids="store_features")

logger.info(
    "[DP] pipeline=%s step=summarize_run "
    "raw_path=%s feature_path=%s "
    "rows=%s null_rate=%s valid=%s stored_rows=%s",
    ...
)

```

- “어디서 읽어서 어디에 저장했는지”만 로깅

---

### ■ v2

```python
feature_prefix = ti.xcom_pull(key="dp_feature_prefix", task_ids="store_features")
feature_version = ti.xcom_pull(key="dp_feature_version", task_ids="store_features")
stored_rows = ti.xcom_pull(key="dp_stored_rows", task_ids="store_features")

logger.info(
    "[DP] pipeline=%s step=summarize_run raw_path=%s feature_prefix=%s "
    "feature_version=%s rows=%s null_rate=%.4f valid=%s stored_rows=%s",
    pipeline_name,
    raw_path,
    feature_prefix,
    feature_version,
    rows,
    null_rate,
    valid,
    stored_rows,
)

```

- 이제 로그 한 줄만 봐도:
    - 어떤 RAW에서
    - 어떤 버전 디렉터리로
    - 몇 건을 저장했는지
    - 데이터 품질은 어땠는지
        
        **정확하게 재구성 가능**
        

→ Loki / Grafana에서 이 로그를 쿼리하면

“버전별 파이프라인 성공/실패/품질 상태”를 한 번에 모니터링할 수 있는 기반이 됩니다.

---

## 8️⃣ 실전 Troubleshooting/운영 관점에서 얻은 것

- S3 Explorer / AWS 콘솔만 봐도:
    - 오늘 새벽 파이프라인이 돌았는지
    - 어떤 버전이 마지막으로 성공했는지
    - schema/metadata에서 데이터 품질이 어땠는지
        
        바로 확인 가능
        
- Loki 로그 쿼리로:
    - `feature_version="v_..."` 조건으로 특정 실행만 필터링
    - null_rate가 비정상적으로 높았던 실행만 모아서 확인
- 나중에 MLflow, Feature Store, Data Catalog를 붙일 때:
    - 굳이 코드로 다시 파고들지 않고
        
        **schema.json / metadata.json을 기준으로 메타데이터 인입**이 가능
        

---

## 9️⃣ Data Pipeline 전용 Grafana 대시보드 (Logs & Metrics (compact))

v2 파이프라인은 S3 구조와 schema/metadata만 고도화된 게 아니라,

**Loki 로그를 기준으로 “파이프라인 관측 전용 대시보드”**까지 적용했습니다.

### ✔ 대시보드 개요

- 제목: `Data Pipeline (daily_user_events) - Logs & Metrics (Compact)`
- 태그: `mlops`, `data-pipeline`, `loki`
- 템플릿 변수:
    - `datasource`: Loki 데이터소스 선택 (dev/prod 공용)
    - `namespace`: `airflow-dev`, `airflow-prod` 등 K8s 네임스페이스
    - `pipeline`: `daily_user_events` (필요 시 다른 파이프라인으로 확장 가능)

### ✔ 패널 구성

1. **Data Pipeline Logs ([DP]) — Logs 패널**
    - 쿼리 예시:
    `{namespace="$namespace"} |= "[DP]" |= "pipeline=$pipeline"`
    - Airflow 로그 중 `[DP]` 태그가 붙은 로그만 필터링해서,
        - `step=extract_raw_data`
        - `step=validate_data`
        - `step=build_features`
        - `step=store_features`
        - `step=summarize_run`
        를 시간순으로 한눈에 볼 수 있습니다.
    - 한 실행 안에서 각 단계가 어떻게 흘렀는지, 어디에서 멈췄는지를 **Row 단위 로그**로 바로 확인할 수 있습니다.
2. **Pipeline Runs (summarize_run count) — TimeSeries 패널**
    - 쿼리 예시:
    `sum by (pipeline) (count_over_time({namespace="$namespace"} |= "[DP]" |= "step=summarize_run" [$__interval]))`
    - 일정 구간마다 `step=summarize_run` 로그가 몇 번 발생했는지를 카운트해서,
        - 파이프라인이 **언제, 얼마나 자주 실행됐는지**
        - 중간에 스케줄이 빠지거나, 특정 시간대에 실행이 몰린 구간은 없는지
        를 시계열로 확인할 수 있습니다.

### ✔ 운영에서의 사용 포인트

- 새 Raw 데이터가 들어왔을 때
    
    → Logs 패널에서 `[DP]` 흐름을 따라가며
    
    `extract_raw_data → validate_data → build_features → store_features → summarize_run`
    
    순서대로 **어디에서 실패했는지** 바로 파악할 수 있습니다.
    
- 특정 시간대에 파이프라인이 안 돌았다고 의심될 때
    
    → TimeSeries 패널에서 `summarize_run` 카운트를 보고
    
    **해당 시간대에 실행이 있었는지 / 몇 번 있었는지** 빠르게 확인할 수 있습니다.
    
- 주기적인 스케줄 상태를 보고 싶을 때
    
    → TimeSeries 패널을 `Last 24 hours / Last 7 days` 등으로 바꿔보면서
    
    **“매일 새벽 3시에 1회 실행” 같은 패턴이 깨진 구간**을 관찰할 수 있습니다.
    

> 지금 구성은
> 
> 
> **“각 실행의 자세한 단계 로그(Logs) + 실행 빈도/패턴(TimeSeries)”**
> 
> 두 가지 관점으로 Data Pipeline을 모니터링하는 최소 대시보드입니다.
> 

---

## 🔧 MLOps 실전 연결

이번 v2 고도화 덕분에, 앞으로는 이렇게 확장할 수 있습니다.

- **MLflow**
    - `feature_version`, `schema.json`, `metadata.json`을 학습 실험에 태그/아티팩트로 연결
- **Feature Store / Data Warehouse**
    - version별 feature.csv를 로딩 후, schema/metadata를 그대로 카탈로그에 반영
- **Observability**
    - Loki 로그 + S3 구조 + Grafana 대시보드로
        
        “**어느 날, 어느 파이프라인 실행이, 어떤 데이터를 얼마나 처리하고, 품질이 어땠는지**”를 시계열로 추적
        

즉, 이번 단계는 단순히 “코드 리팩토링”이 아니라,

“데이터 파이프라인을 ML 플랫폼의 정식 구성원으로 승격시킨 단계”라고 볼 수 있습니다.

---

## 🏁 정리

이번 v2 고도화까지 정리하면, 데이터 파이프라인은 다음을 모두 만족합니다.

- S3 RAW ingest
- Extract → Validate → Transform → Load(E2E)
- Airflow DAG orchestration
- Python 기반 Feature Engineering
- 버전 디렉터리 기반 S3 저장 구조
- `feature.csv + schema.json + metadata.json` 3종 세트 생성
- KST 기준 타임라인 & 버전 ID 관리
- Loki/Grafana에서 재구성 가능한 풍부한 실행 로그
- Data Pipeline 전용 Grafana 대시보드(Logs & Metrics (compact))를 통한 실행 관측

이제 이 Data Pipeline은

단순 “전처리 스크립트”를 넘어서,

“MLflow & 모델 학습 자동화와 바로 연결 가능한 데이터 레이어”가 되었습니다.
