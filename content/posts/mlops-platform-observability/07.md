+++
date = '2025-11-10T17:10:21+09:00'
draft = false
title = '[MLOps í”Œë«í¼ Observability & Data Pipeline - 7ë‹¨ê³„ : Data Pipeline êµ¬ì¶•]'
categories = ['Data Pipeline', 'MLOps Pipeline', 'Kubernetes', 'Airflow', 'AWS', 'Python', 'Observability']
+++

## Data Pipeline êµ¬ì¶•

---

## ğŸ§  ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…

> â€œëª¨ë¸ì˜ ì„±ëŠ¥ì€ ê²°êµ­ ë°ì´í„° í’ˆì§ˆì—ì„œ ê²°ì •ë©ë‹ˆë‹¤.
> 
> 
> ê·¸ëŸ°ë° ê·¸ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ì¶”ì¶œí•˜ê³ , ê²€ì¦í•˜ê³ , ê°€ê³µí•˜ê³ , ì €ì¥í•˜ëŠ”ì§€ê¹Œì§€ ìë™í™”í•˜ì§€ ì•Šìœ¼ë©´
> 
> MLOpsëŠ” ì ˆëŒ€ ì™„ì„±ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.â€
> 
> â€œê·¸ë˜ì„œ ì´ë²ˆ ë‹¨ê³„ì—ì„œëŠ” Raw S3 â†’ ì „ì²˜ë¦¬ â†’ Feature â†’ ì €ì¥ê¹Œì§€ ì´ì–´ì§€ëŠ”
> 
> **ì—”ë“œíˆ¬ì—”ë“œ ë°ì´í„° íŒŒì´í”„ë¼ì¸**ì„ ì§ì ‘ êµ¬ì¶•í•´
> 
> ì´í›„ MLflow í•™ìŠµ ìë™í™”ì™€ ë°”ë¡œ ì—°ê²°ë  â€˜ë°ì´í„° ë ˆì´ì–´â€™ë¥¼ ë¨¼ì € ë‹¤ì¡ŒìŠµë‹ˆë‹¤.â€
> 

---

### ğŸ¯ í•µì‹¬ ìš”ì•½

- **Raw ë°ì´í„°**ë¥¼ S3ì—ì„œ ê°€ì ¸ì˜¤ê³ 
- **Airflow DAG**ì—ì„œ ë‹¨ê³„ë³„ ì²˜ë¦¬ íë¦„ì„ ê´€ë¦¬í•˜ë©°
- **Python ì „ì²˜ë¦¬ ì½”ë“œ**ì—ì„œ Feature ìƒì„±
- ìµœì¢… Featureë¥¼ **Feature Bucket**ì— ì €ì¥í•˜ëŠ”
    
    **ì—”ë“œíˆ¬ì—”ë“œ ë°ì´í„° íŒŒì´í”„ë¼ì¸**ì…ë‹ˆë‹¤.
    

ì´ íŒŒì´í”„ë¼ì¸ì€ ETL/MLOps êµ¬ì¡°ë¥¼ â€œì¶•ì†Œí˜•ìœ¼ë¡œ ì™„ì „í•˜ê²Œ ì¬í˜„â€í•œ ë²„ì „ì´ë©°, ì´í›„ MLflow â†’ ëª¨ë¸ í•™ìŠµ ìë™í™”ì™€ ì—°ê²°ë  ê¸°ë°˜ì´ ë©ë‹ˆë‹¤.

---

## 1ï¸âƒ£ ì „ì²´ êµ¬ì¡°

![mermaid-observability-04.png](/mlops-journey/images/mermaid-observability-04.png)

---

## 2ï¸âƒ£ êµ¬ì„± ìš”ì†Œ

---

## 3ï¸âƒ£ Repo ë° ë””ë ‰í„°ë¦¬ êµ¬ì¡°

```
airflow-dags-dev/
 â”œâ”€â”€ dags/
 â”‚    â”œâ”€â”€ dag_data_pipeline_daily.py
 â”‚    â””â”€â”€ ml_code/
 â”‚         â””â”€â”€ data_pipeline.py

```

- DAG ìŠ¤ì¼€ì¤„ ì •ì˜: `dag_data_pipeline_daily.py`
- ETL ë¡œì§: `ml_code/data_pipeline.py`

---

## 4ï¸âƒ£ E2E Pipeline Flow

### â–  ì „ì²´ íë¦„

1. **extract_raw_data**
    
    S3 Raw CSV í—¤ë” í™•ì¸ â†’ CSV ë‚´ìš© ì½ê¸°
    
    XComìœ¼ë¡œ Text ì „ë‹¬
    
2. **validate_data**
    
    CSV êµ¬ì¡° ê²€ì¦ (í—¤ë”, ìµœì†Œ ì»¬ëŸ¼ ìˆ˜, ê²°ì¸¡ ì²´í¬)
    
3. **build_features**
    
    ìˆ«ìí˜• ì»¬ëŸ¼ ìë™ íƒì§€ â†’ ì „ì²˜ë¦¬ â†’ row_sum Feature ìƒì„±
    
    Feature CSVë¥¼ XComìœ¼ë¡œ ì „ë‹¬
    
4. **store_features**
    
    ì „ë‹¬ë°›ì€ Feature CSV â†’ S3 Feature Bucketì— ì €ì¥
    
5. **summarize_run**
    
    ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹… (row ìˆ˜, ì €ì¥ ê²½ë¡œ ë“±)
    

Pipeline = **ì¶”ì¶œ â†’ ê²€ì¦ â†’ ê°€ê³µ â†’ ì €ì¥ â†’ ìš”ì•½** ë¡œ êµ¬ì„±ëœ ê¹”ë”í•œ ETL êµ¬ì¡°ì…ë‹ˆë‹¤.

---

## 5ï¸âƒ£ Raw ë°ì´í„° êµ¬ì¡°

ì˜ˆì‹œ íŒŒì¼:

```
s3://datapipeline-raw-data-keonho/user_events_20251119.csv

```

CSV í—¤ë”:

```
event_time,user_id,session_id,event_type,device,country,is_premium,event_value,amount,session_length_sec

```

| êµ¬ì„± ìš”ì†Œ | ì„¤ëª… |
| --- | --- |
| **S3 Raw Bucket** | `s3://datapipeline-raw-data-keonho` |
| **S3 Feature Bucket** | `s3://datapipeline-feature-data-keonho` |
| **Airflow** | DAG ìŠ¤ì¼€ì¤„ë§, Task ê´€ë¦¬ |
| **Python ì „ì²˜ë¦¬ ì½”ë“œ** | CSV íŒŒì‹±, ê²€ì¦, Feature ìƒì„± |
| **XCom** | Task ê°„ ë°ì´í„° ì „ë‹¬ |
| **Kubernetes** | Airflow Worker ìš´ì˜ |

ì´ ì´ë²¤íŠ¸ ê¸°ë°˜ Raw ë¡œê·¸ëŠ” ì‹¤ë¬´ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” í˜•íƒœì´ë©°

**Feature ì—”ì§€ë‹ˆì–´ë§ì˜ ê¸°ë³¸ ë‹¨ìœ„**ì…ë‹ˆë‹¤.

---

## 6ï¸âƒ£ DAG êµ¬ì„±

DAGëŠ” ë‹¤ìŒ 5ê°œ Taskë¡œ êµ¬ì„±:

```
extract_raw_data
    â†“
validate_data
    â†“
build_features
    â†“
store_features
    â†“
summarize_run

```

### DAG ì˜ˆì‹œ:

```python
task_extract_raw_data = PythonOperator(
    task_id="extract_raw_data",
    python_callable=extract_raw_data,
    op_kwargs={"raw_path": raw_s3_path},
)

```

Airflow Worker â†’ Python â†’ AWS SDK (boto3) ìˆœìœ¼ë¡œ í˜¸ì¶œë©ë‹ˆë‹¤.

---

## 7ï¸âƒ£ Python ì „ì²˜ë¦¬ ì½”ë“œ í•µì‹¬

ëª¨ë“  ì‹¤ì „í˜• íŒŒì´í”„ë¼ì¸ì´ ê³µí†µì ìœ¼ë¡œ ê°€ì ¸ì•¼ í•˜ëŠ”

**Extract â†’ Validate â†’ Transform â†’ Load(E2E)** íë¦„ì„ ì¶©ì‹¤íˆ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

---

## âœ” 1) extract_raw_data()

- `head_object` ë¡œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
- CSV Raw í…ìŠ¤íŠ¸ ë¡œë”©
- XCom push

ê²°ê³¼ ì˜ˆ:

```
[DP] step=extract_raw_data action=get_object bucket=... key=...

```

---

## âœ” 2) validate_data()

- header ì¡´ì¬ ì²´í¬
- row ê¸¸ì´ ê²€ì¦
- ìœ íš¨í•˜ì§€ ì•Šì€ ë¼ì¸ì€ drop
- ê¸°ë³¸ì ì¸ Schema Validation ì—­í• 

---

## âœ” 3) build_features() (í•µì‹¬)

### ğŸ” ìë™ ìˆ«ìí˜• ì»¬ëŸ¼ íƒì§€

```python
numeric_candidates = {"user_id", "is_premium", "event_value", "amount", "session_length_sec"}

numeric_indices = [
    idx for idx, col in enumerate(header) if col in numeric_candidates
]

```

- í—¤ë”ì™€ í›„ë³´ ëª©ë¡ì„ ë¹„êµ
- **ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ìë™ ì¶”ì¶œ**
    
    â†’ Raw íŒŒì¼ì´ ì»¬ëŸ¼ ì¶”ê°€/ë³€ê²½ë˜ì–´ë„ ì•ˆì •ì ìœ¼ë¡œ ë™ì‘
    

### ğŸ”§ Feature ìƒì„± ë¡œì§

```python
numeric_values.append(float(cell)) if ê°€ëŠ¥ else 0.0
row_sum = sum(numeric_values)

```

- ìˆ«ìë¡œ íŒŒì‹±ë˜ì§€ ì•Šìœ¼ë©´ 0.0 ì²˜ë¦¬
- ë ˆì½”ë“œ ë‹¨ìœ„ Feature(row_sum) ìƒì„±

### ğŸ“¤ XCom Push

```python
ti.xcom_push(key="dp_feature_csv", value=feature_csv)

```

---

## âœ” 4) store_features()

XComì—ì„œ feature_csv ë¬¸ìì—´ ìˆ˜ì‹  â†’ S3 Feature Bucket ì €ì¥:

```
s3://datapipeline-feature-data-keonho/features_20251119.csv

```

---

## âœ” 5) summarize_run()

- ìƒì„±ëœ Feature row count
- ì²˜ë¦¬í•œ íŒŒì¼ëª…
- ì €ì¥ ê²½ë¡œ
- Task ì„±ê³µ/ì‹¤íŒ¨ ë¡œê·¸

---

## 8ï¸âƒ£ Feature ê²°ê³¼ ì˜ˆì‹œ

ìƒì„±ëœ row_sum feature ì˜ˆì‹œ:

```
1302.0
36733.0
1185.0
1546.0
...

```

Raw â†’ ìˆ«ì ì»¬ëŸ¼ â†’ ì „ì²˜ë¦¬ â†’ Feature

**ì •ìƒì ìœ¼ë¡œ ì¶”ì¶œëœ pipelineì˜ ëŒ€í‘œì ì¸ ì¶œë ¥ë¬¼**ì…ë‹ˆë‹¤.

---

## 9ï¸âƒ£ ì‹¤ì „ Troubleshooting ì •ë¦¬

### âœ” S3 HeadObject í™•ì¸

```
action=head_object

```

ë¡œê¹…ìœ¼ë¡œ Raw íŒŒì¼ ëˆ„ë½ ì—¬ë¶€ í™•ì¸ ê°€ëŠ¥.

---

### âœ” Worker Pod ë¡œê·¸

```bash
kubectl -n airflow-dev logs <pod>

```

íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ ì›ì¸ ëŒ€ë¶€ë¶„ì´ ì—¬ê¸°ì„œ ë“œëŸ¬ë‚©ë‹ˆë‹¤.

---

### âœ” NameResolutionError

Airflow UIì—ì„œ Worker Log ì¡°íšŒ ì‹œ ì¢…ì¢… ë°œìƒí•˜ëŠ” ì •ìƒ í˜„ìƒ

(Worker PodëŠ” ephemeralì´ë¯€ë¡œ ë¬¸ì œ ì—†ìŒ)

---

### âœ” CSV Parsing ì‹¤íŒ¨

- â€œì—´ ê°œìˆ˜ê°€ ì¼ì •í•˜ì§€ ì•ŠìŒâ€
- â€œë¹ˆ ë¼ì¸ í¬í•¨â€

â†’ validate_data()ì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ ë°©ì–´ë¨.

---

## ğŸ”Ÿ MLOps ì‹¤ì „ ì—°ê²°

ì´ íŒŒì´í”„ë¼ì¸ì€ ì´í›„ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì‰½ê²Œ í™•ì¥ë©ë‹ˆë‹¤:

- MLflow Tracking ì—°ë™ â†’ Feature ê¸°ë°˜ ì‹¤í—˜ ìë™í™”
- Airflow DAG â†’ ëª¨ë¸ í•™ìŠµ/í‰ê°€ ì—°ê²°
- ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­ â†’ Prometheus/Loki ê´€ì¸¡
- S3 Raw/Feature ë ˆì´ì–´ â†’ DeltaLake/Snowflake/Staging ë“± í™•ì¥ ê°€ëŠ¥

**ì¦‰, MLOps ì „ì²´ êµ¬ì¡°ì˜ ì „ì²˜ë¦¬Â·ë°ì´í„° ë ˆì´ì–´ë¥¼ êµ¬ì„±í•˜ëŠ” ì‹¤ì „í˜• ëª¨ë“ˆ**ì…ë‹ˆë‹¤.

---

## ğŸ ì •ë¦¬

êµ¬ì¶•í•œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì€ ë‹¤ìŒì„ ëª¨ë‘ ì¶©ì¡±í•©ë‹ˆë‹¤:

- S3 ingest
- Extract â†’ Validate â†’ Transform â†’ Load
- Airflow DAG orchestration
- Python ê¸°ë°˜ Feature Engineering
- Task ê°„ XCom ì „ì†¡
- Worker í™˜ê²½ì—ì„œì˜ ì‹¤ì „ ì—ëŸ¬ í•¸ë“¤ë§

ETL/MLOps êµ¬ì¡°ì—ì„œ ìš”êµ¬í•˜ëŠ” **í•µì‹¬ ìš”ì†Œê°€ í¬í•¨ëœ ì™„ì „í˜• íŒŒì´í”„ë¼ì¸**ì…ë‹ˆë‹¤.
