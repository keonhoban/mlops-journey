+++
date = '2025-06-13T20:58:51+09:00'
draft = false
title = '[Airflow ê¸°ì´ˆ ìžë™í™” - Airflow â†’ MLflow â†’ FastAPI]'
categories = ['MLOps Pipeline', 'Airflow', 'MLflow', 'FastAPI']
+++

## ðŸ§­ ì „ì²´ íë¦„ ì˜ˆì‹œ

```
[AIRFLOW DAG ì‹¤í–‰]
   â†“
[train_mlflow.py]
   - iris ëª¨ë¸ í•™ìŠµ
   - íŒŒë¼ë¯¸í„°/ë©”íŠ¸ë¦­ ë¡œê¹…
   - ëª¨ë¸ Registry ë“±ë¡
   â†“
[promote_mlflow.py]
   - ìµœì‹  ëª¨ë¸ì„ Productionìœ¼ë¡œ ì „í™˜
   â†“
[FastAPI]
   - models:/IrisModel/Production â†’ ì‹¤ì‹œê°„ ì˜ˆì¸¡
```

ðŸ‘‰ ì‹¤ìŠµ ì½”ë“œëŠ” [ðŸ”— GitHub (Airflow + MLflow + FastAPI)](https://github.com/keonhoban/mlops-infra-labs/tree/main/airflow_mlflow_fastapi)

---

## âœ… [1ë‹¨ê³„] í”„ë¡œì íŠ¸ ê¸°ë³¸ í´ë” êµ¬ì¡° ì„¤ê³„

### ðŸ“ 1. ì „ì²´ ë””ë ‰í† ë¦¬ êµ¬ì„±ë„

```
mlops_project/
â”œâ”€â”€ airflow/                       ðŸ›« Airflow ì„¤ì • ë° DAG ìŠ¤ì¼€ì¤„ëŸ¬
â”‚   â”œâ”€â”€ dags/                      â† DAG ì •ì˜ ë””ë ‰í† ë¦¬
â”‚   â”‚   â””â”€â”€ train_with_mlflow.py   â† í•™ìŠµ DAG (MLflow ì—°ë™)
â”‚   â”œâ”€â”€ Dockerfile.airflow         â† Airflowìš© Dockerfile
â”‚   â”œâ”€â”€ requirements.txt           â† Airflow ì˜ì¡´ì„±
â”‚   â””â”€â”€ .dockerignore
â”‚
â”œâ”€â”€ fastapi/              âš¡ FastAPI ì˜ˆì¸¡ API ì„œë²„
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ main.py        â† ëª¨ë¸ ì„œë¹™ ì—”ë“œí¬ì¸íŠ¸
â”‚   â”œâ”€â”€ Dockerfile.api     â† FastAPIìš© Dockerfile
â”‚   â”œâ”€â”€ requirements.txt   â† FastAPI ì˜ì¡´ì„±
â”‚   â””â”€â”€ .dockerignore
â”‚
â”œâ”€â”€ ml_code/               ðŸ§  ML í•™ìŠµ ë° í”„ë¡œëª¨ì…˜ ì½”ë“œ
â”‚   â”œâ”€â”€ train_mlflow.py     â† ëª¨ë¸ í•™ìŠµ ë° MLflow ë¡œê¹…
â”‚   â””â”€â”€ promte_mlflow.py    â† ëª¨ë¸ í”„ë¡œëª¨ì…˜ (Staging â†’ Production)
â”‚
â”œâ”€â”€ mlflow_store/          ðŸ—‚ï¸ MLflow ì €ìž¥ì†Œ ê²½ë¡œ (ë³¼ë¥¨)
â”‚   â”œâ”€â”€ Dockerfile.mlflow   â† MLflow ì„œë²„ ì»¤ìŠ¤í„°ë§ˆì´ì§•
â”‚   â”œâ”€â”€ mlflow.db           â† Model Registry DB (sqlite)
â”‚   â”œâ”€â”€ mlruns/             â† ì‹¤í—˜ ë¡œê·¸ ë””ë ‰í† ë¦¬
â”‚   â”œâ”€â”€ artifacts/          â† ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì €ìž¥ì†Œ
â”‚   â””â”€â”€ .dockerignore
â”‚
â”œâ”€â”€ docker-compose.yaml    ðŸ§© ì „ì²´ ì„œë¹„ìŠ¤ êµ¬ì„± ì •ì˜
â”œâ”€â”€ .env                   ðŸ” ë¯¼ê° ì •ë³´ (.envë¡œ ë¶„ë¦¬)
â”œâ”€â”€ README.md              ðŸ“ ì „ì²´ í”„ë¡œì íŠ¸ ë¬¸ì„œí™”
â”œâ”€â”€ .gitignore
â””â”€â”€ .dockerignore

```

---

## âœ… [2ë‹¨ê³„] `docker-compose.yaml` í†µí•© êµ¬ì„±

### ðŸ§­ êµ¬ì„± ëª©í‘œ

| ì„œë¹„ìŠ¤ëª… | ì„¤ëª… | í¬íŠ¸ |
| --- | --- | --- |
| `airflow` | DAG ì‹¤í–‰ í™˜ê²½ (webserver/scheduler) | `8080` |
| `postgres` | Airflow ë©”íƒ€ë°ì´í„° ì €ìž¥ìš© DB | ë‚´ë¶€ í†µì‹  |
| `mlflow` | MLflow UI + Registry ê¸°ëŠ¥ | `5000` |
| `fastapi` | ì¶”ë¡  API ì„œë²„ (ëª¨ë¸ ë¡œë”©) | `8000` |

- ì´ë¯¸ì§€ ì‚¬ìš©ì‹œ ì£¼ì˜ (UIë§Œ ì œê³µí•˜ëŠ” ì´ë¯¸ì§€ ì¡´ìž¬)

---

### ðŸ“„ `docker-compose.yaml` ì „ì²´ ì˜ˆì‹œ

```yaml
version: '3.8'

services:
  # ðŸ“¦ PostgreSQL: Airflow ë©”íƒ€ë°ì´í„° ì €ìž¥ìš© DB
  postgres:
    image: postgres:13
    container_name: postgres
    env_file:
      - .env  # â† ë¯¼ê°ì •ë³´ ë¶„ë¦¬ (ì•„ì´ë””/ë¹„ë²ˆ)
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:  # â† ì½”ë“œ/ë°ì´í„° ê³µìœ  ë° ì˜ì†ì„± ë³´ìž¥
      - postgres_data:/var/lib/postgresql/data  # â† DB ë°ì´í„° ìœ ì§€ (ìž¬ì‹œìž‘ ëŒ€ë¹„)

  # ðŸ›« Airflow: DAG ìŠ¤ì¼€ì¤„ëŸ¬ ë° íƒœìŠ¤í¬ ì‹¤í–‰
  airflow:
    build:
      context: ./airflow           # â†’ Airflow ì „ìš© Dockerfile ê²½ë¡œ
      dockerfile: Dockerfile.airflow
    container_name: airflow
    command: standalone           # â†’ ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨ ì‹¤í–‰ ëª…ë ¹ 
                      # (- Scheduler + Webserver + DB ì´ˆê¸°í™”ê¹Œì§€ ìžë™ìœ¼ë¡œ í•œë²ˆì— ì‹¤í–‰)
                      # (- ì‹¤ë¬´/ìš´ì˜ì—ì„œëŠ” airflow-webserver, airflow-scheduler í•„ë“œ ë¶„ë¦¬)
    ports:
      - "8080:8080"               # â†’ Airflow ì›¹ UI (localhost:8080)
    depends_on:
      - postgres                  # â†’ DBê°€ ë¨¼ì € ì˜¬ë¼ì™€ì•¼ Airflow ì‹œìž‘ ê°€ëŠ¥
    env_file:
      - .env
    environment:
      # Airflow ë©”íƒ€ë°ì´í„° DB ì—°ê²° ì£¼ì†Œ
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW__CORE__SQL_ALCHEMY_CONN}
      # Airflow ì˜ˆì œ DAG ë¶ˆëŸ¬ì˜¬ì§€ ì—¬ë¶€
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES}  
      MLFLOW_TRACKING_URI: http://mlflow:5000  # â†’ DAG ì½”ë“œì—ì„œ MLflow ì—°ë™
    volumes:
      - ./airflow/dags:/opt/airflow/dags     # DAG íŒŒì¼ mount
      - ./ml_code:/opt/airflow/ml_code       # í•™ìŠµ ì½”ë“œ ê³µìœ 
      - ./mlflow_store:/mlflow               # ëª¨ë¸ ì €ìž¥ì†Œ ê³µìœ 

  # ðŸ”¬ MLflow: ì‹¤í—˜ ì¶”ì  + ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì„œë²„
  mlflow:
    build:
      context: ./mlflow_store                # ì»¤ìŠ¤í…€ Dockerfile ìœ„ì¹˜
      dockerfile: Dockerfile.mlflow
    ports:
      - "5000:5000"                          # â†’ MLflow UI (localhost:5000)
    volumes:
      - ./mlflow_store:/mlflow              # ì‹¤í—˜ ë¡œê·¸ + DB + artifacts ì €ìž¥
    environment:
      - MLFLOW_TRACKING_URI=http://0.0.0.0:5000  # ë‚´ë¶€ ì»¨í…Œì´ë„ˆ ê¸°ì¤€ URI

  # âš¡ FastAPI: ëª¨ë¸ ì„œë¹™ API
  fastapi:
    build:
      context: ./fastapi
      dockerfile: Dockerfile.api
    container_name: fastapi
    ports:
      - "8000:8000"                          # â†’ ì˜ˆì¸¡ API ì—”ë“œí¬ì¸íŠ¸ (localhost:8000)
    volumes:
      - ./fastapi/app:/app/app              # FastAPI app ë””ë ‰í† ë¦¬ mount
      - ./ml_code:/app/ml_code              # í•™ìŠµ/ëª¨ë¸ ì½”ë“œ ê³µìœ 
      - ./mlflow_store:/mlflow              # ì €ìž¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ mount

# ðŸ—‚ï¸ ë³¼ë¥¨ ì •ì˜ (Postgres DB ì˜ì†ì„± ìœ ì§€)
volumes:
  postgres_data:
```

---

## ðŸŽ ì¶”ê°€ë¡œ í•´ì•¼ í•  ê²ƒ

- Airflow ì²« ì‹¤í–‰ í›„ì—” ë³´í†µ **ê´€ë¦¬ìž ê³„ì • ìƒì„±**ë„ í•´ì¤˜ì•¼ í•¨:

```bash
# airflow ì»¨í…Œì´ë„ˆ ì ‘ì†
docker exec -it airflow bash

# ê´€ë¦¬ìž ê³„ì • ìƒì„±
airflow users create \
  --username airflow \
  --password airflow \
  --firstname Keoho \
  --lastname Ban \
  --role Admin \
  --email airflow@example.com
```

---

### ðŸ” [êµ¬ì¶• Tip] **Airflow, FastAPI, MLflow ê°„ ê³µìœ  ë³¼ë¥¨ êµ¬ì¡° í™•ì¸**

| ê³µìœ  ë¦¬ì†ŒìŠ¤ | ì„¤ëª… |
| --- | --- |
| `./mlflow_store:/mlflow` (MLflow) | MLflow ì„œë²„ê°€ ì“°ëŠ” ë¡œê·¸/ëª¨ë¸ ì €ìž¥ì†Œ |
| `./mlflow_store:/mlflow` (Airflow) | í•™ìŠµ í›„ ëª¨ë¸ ì €ìž¥ ìœ„ì¹˜ ê³µìœ  |
| `./mlflow_store:/mlflow` (FastAPI) | ëª¨ë¸ ì¶”ë¡  ì‹œ ë¡œë“œ ê²½ë¡œ ê³µìœ  |

âž¡ **ê²½ë¡œ í†µì¼ì„±**ì´ ë§¤ìš° ì¤‘ìš”í•¨! ì§€ê¸ˆì€ ëª¨ë‘ `./mlflow`ë¡œ ê³µìœ  (./mlflow í•˜ìœ„ì— /mlruns ì¡´ìž¬)

---

### âœ… [ê¶Œìž¥] `.env`ë¡œ ë¯¼ê° ì •ë³´ ë¶„ë¦¬í•˜ê¸°

### ðŸ“„ 1. `.env` íŒŒì¼ ìž‘ì„±

```
# .env

# PostgreSQL
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow

# Airflow í™˜ê²½ ë³€ìˆ˜
AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
AIRFLOW__CORE__LOAD_EXAMPLES=False
```

> ðŸ‘‰ ì´ ê°’ë“¤ì€ ì˜ˆì‹œìš©ì´ê³ , ì‹¤ì œë¡œëŠ” ë¹„ë°€ë²ˆí˜¸ë‚˜ DB ì´ë¦„ì„ ë” ë³µìž¡í•˜ê²Œ ì„¤ì •í•˜ëŠ” ê²Œ ì¢‹ìŒ
> 

---

## âœ… [3ë‹¨ê³„] Dockerfile êµ¬ì„±

### ðŸ˜ 1. `Dockerfile.airflow` (Airflow ì»¨í…Œì´ë„ˆ)

> DAG ì‹¤í–‰, ML ì½”ë“œ ì‹¤í–‰, MLflow ë¡œê¹…ê¹Œì§€ ê°€ëŠ¥í•œ í™˜ê²½ì„ ë§Œë“¤ìž.
> 

ðŸ“„ **`airflow/Dockerfile.airflow`**

```
FROM apache/airflow:2.8.1-python3.10

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ENV AIRFLOW_HOME=/opt/airflow

# Airflow ì‹¤í–‰ ì‚¬ìš©ìžë¡œ ì „í™˜
USER airflow

# í•„ìš”í•œ ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (mlflow, scikit-learn ë“±)
RUN pip install --no-cache-dir \
    mlflow \
    scikit-learn \
    pandas
```

---

### âš™ï¸ `airflow/requirements.txt` ì˜ˆì‹œ (ì„ íƒ)

```
mlflow
scikit-learn
pandas
```

> â— í•˜ì§€ë§Œ Dockerfile.airflowì—ì„œ ì§ì ‘ pip install í–ˆê¸° ë•Œë¬¸ì— ê¼­ í•„ìš”í•˜ì§„ ì•Šì§€ë§Œ, ê´€ë¦¬ìš©ìœ¼ë¡œ ë‘ëŠ” ê²ƒë„ ì¢‹ìŒ
> 

---

### ðŸš€ 2. `Dockerfile.mlflow` (FastAPI ì»¨í…Œì´ë„ˆ)

ðŸ“„ **`mlflow_store/Dockerfile.mlflow`**

```
FROM python:3.10-slim

# ì‹œìŠ¤í…œ ë„êµ¬ ì„¤ì¹˜
RUN apt update && apt install -y curl sqlite3 git

# MLflow ì„¤ì¹˜
RUN pip install mlflow[extras] scikit-learn

# ìž‘ì—… ë””ë ‰í† ë¦¬
WORKDIR /mlflow

CMD ["mlflow", "server", \
     "--backend-store-uri=sqlite:///mlflow.db", \
     "--default-artifact-root=/mlflow/artifacts", \
     "--host=0.0.0.0", \
     "--port=5000", \
     "--serve-artifacts"]
```

> â— docker-compose.yaml ì˜ command ì—ì„œ ì§„í–‰ì•ˆë ì‹œ ì‚¬ìš©
> 

---

### ðŸš€ 3. `Dockerfile.api` (FastAPI ì»¨í…Œì´ë„ˆ)

ðŸ“„ **`fastapi/Dockerfile.api`**

```
FROM python:3.10-slim

# ìž‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# ì•± ë””ë ‰í† ë¦¬ ë³µì‚¬
COPY app /app/app

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt /app/requirements.txt
RUN pip install --no-cache-dir --upgrade pip && \
    pip install -r /app/requirements.txt

# FastAPI ì•± ì‹¤í–‰ (uvicorn)
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

> â— íŒ¨í‚¤ì§€ ê°œìˆ˜ê°€ ë§Žë‹¤ë©´ requirementë¥¼ COPY í•˜ì—¬ ì‚¬ìš©ë„ ê°€ëŠ¥
> 

---

### âš™ï¸ `fastapi/requirements.txt`

```
fastapi
uvicorn
mlflow
scikit-learn
pydantic
```

> í•„ìš” ì‹œ pandas, joblib, numpyë„ ì¶”ê°€ ê°€ëŠ¥
> 

---

## ðŸ“ FastAPI êµ¬ì„± (`fastapi/app/main.py`)

```python
from fastapi import FastAPI
from pydantic import BaseModel
from typing import List
import mlflow.pyfunc
import pandas as pd

# ðŸŽ¯ FastAPI ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
app = FastAPI()

# ðŸ“Œ MLflow ì¶”ì  ì„œë²„ URI ì„¤ì • (MLflow Tracking Serverë¡œ ì—°ê²°)
mlflow.set_tracking_uri("http://mlflow:5000")

# ðŸ”„ Production ë‹¨ê³„ ëª¨ë¸ ë¡œë“œ (ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ì´ë¦„ + ìŠ¤í…Œì´ì§€ ê¸°ë°˜ ë¡œë“œ)
#     - "models:/IrisModel/Production" í˜•ì‹
#     - ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì‹œì ì— ëª¨ë¸ì´ ì´ë¯¸ ë“±ë¡ & í”„ë¡œë•ì…˜ ìƒíƒœì—¬ì•¼ í•¨
model = mlflow.pyfunc.load_model("models:/IrisModel/Production")

# ðŸ“¦ ìž…ë ¥ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜
#     - í´ë¼ì´ì–¸íŠ¸ê°€ JSONìœ¼ë¡œ ë„˜ê²¨ì•¼ í•  ë°ì´í„° í˜•íƒœ ëª…ì‹œ
#     - pydanticìœ¼ë¡œ ìžë™ ìœ íš¨ì„± ê²€ì‚¬ ê°€ëŠ¥
class IrisInput(BaseModel):
    sepal_length: float
    sepal_width: float
    petal_length: float
    petal_width: float

# âœ… í—¬ìŠ¤ ì²´í¬ìš© ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
def home():
    return {"message": "FastAPI + MLflow ì˜ˆì¸¡ API"}

# ðŸ”® ì˜ˆì¸¡ ìš”ì²­ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸
@app.post("/predict")
def predict(data: List[IrisInput]):
    # 1ï¸âƒ£ ìž…ë ¥ ë°ì´í„° â†’ pandas DataFrame ë³€í™˜ (= 2ì°¨ì› êµ¬ì¡° / í˜„ìž¬ 1í–‰ 4ì—´)
    input_df = pd.DataFrame([item.dict() for item in data])

    # 2ï¸âƒ£ ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©í–ˆë˜ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½ ë° ë°ì´í„° ìˆœì„œ ì •ë ¬ (ìŠ¤í‚¤ë§ˆ ë§žì¶¤)
    input_df.columns = [
        "sepal length (cm)",
        "sepal width (cm)",
        "petal length (cm)",
        "petal width (cm)"
    ]

    # 3ï¸âƒ£ MLflowë¡œë¶€í„° ë¡œë“œëœ ëª¨ë¸ì„ í™œìš©í•œ ì˜ˆì¸¡ ìˆ˜í–‰ (= serving)
    preds = model.predict(input_df)

    # 4ï¸âƒ£ ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ë°˜í™˜
    return {"predictions": preds.tolist()}
```

---

## âœ… [4ë‹¨ê³„] Airflow DAG + MLflow ì—°ë™

### ðŸŽ¯ ëª©í‘œ ìš”ì•½

| í•­ëª© | ë‚´ìš© |
| --- | --- |
| DAG ì—­í•  | PythonOperatorë¡œ ML í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ |
| ML ì½”ë“œ | `train_mlflow.py`ë° `promote_mlflow.py` ë¥¼  ì‹¤í–‰í•˜ì—¬ í•™ìŠµ ë° ìŠ¹ê²© + MLflow ë¡œê¹…  |
| ì—°ë™ ê²°ê³¼ | íŒŒë¼ë¯¸í„°, ë©”íŠ¸ë¦­, ëª¨ë¸ ì €ìž¥ + Model Registry ë“±ë¡í›„ ìŠ¤í…Œì´ì§€ â€œproductionâ€ ìŠ¹ê²©ê¹Œì§€ ìžë™í™” |

---

## ðŸ§ª 1. ML í•™ìŠµ ì½”ë“œ ìž‘ì„± (`ml_code/train_mlflow.py`)

```python
# ml_code/train_mlflow.py

import mlflow
import mlflow.sklearn
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

def run_experiment():
  # ðŸ“ MLflow ì„œë²„ ì£¼ì†Œ ì„¤ì • (Tracking URI) 
  # (- docker-compose.yamlì˜ airflowì— environmentë¡œ MLFLOW_TRACKING_URI ì¡´ìž¬ì‹œ ìƒëžµ ê°€ëŠ¥)
    mlflow.set_tracking_uri("http://mlflow:5000")  # ë‹¨, ë¡œì»¬ì—ì„œ ì§„í–‰ì‹œ í•„ìš”

    # ðŸ§ª ì‹¤í—˜ ì´ë¦„ ì„¤ì • (ì—†ìœ¼ë©´ ìžë™ ìƒì„±)
    mlflow.set_experiment("iris_experiment")

    # ðŸš€ ìƒˆë¡œìš´ ì‹¤í—˜ run ì‹œìž‘
    with mlflow.start_run() as run:
        # ðŸ“Š ë°ì´í„° ë¡œë”©
        data = load_iris()
        X, y = data.data, data.target

        # ðŸ” ëª¨ë¸ í•™ìŠµ
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X, y)
        preds = model.predict(X)

        # âœ… ì„±ëŠ¥ í‰ê°€
        acc = accuracy_score(y, preds)

        # ðŸ“ ì‹¤í—˜ ì •ë³´ ë¡œê¹…
        mlflow.log_param("n_estimators", 100)
        mlflow.log_metric("accuracy", acc)

        # ðŸ“¦ ëª¨ë¸ ì €ìž¥ + ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡
        #    - `artifact_path`: ì•„í‹°íŒ©íŠ¸ ì €ìž¥ ë””ë ‰í† ë¦¬ ì´ë¦„
        #    - `registered_model_name`: ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ëª¨ë¸ ì´ë¦„ìœ¼ë¡œ ê´€ë¦¬ë¨
        mlflow.sklearn.log_model(
            model,
            artifact_path="model",
            registered_model_name="IrisModel"
        )

        # ðŸ–¨ï¸ ê²°ê³¼ ì¶œë ¥
        print(f"âœ… Run ID: {run.info.run_id}, Accuracy: {acc}")

# ðŸ”§ ì§ì ‘ ì‹¤í–‰í•  ê²½ìš°ë§Œ í•¨ìˆ˜ ì‹¤í–‰
if __name__ == "__main__":
    run_experiment()
```

---

## ðŸ§ª 2. ML í•™ìŠµ ì½”ë“œ ìž‘ì„± (`ml_code/promote_mlflow.py`)

```python
# ml_code/promote_mlflow.py

from mlflow.tracking import MlflowClient

def promote_model():
    # ðŸ§­ MLflow í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì„œë²„ì™€ ì§ì ‘ í†µì‹ )
    # (- docker-compose.yamlì˜ airflowì— environmentë¡œ MLFLOW_TRACKING_URI ì¡´ìž¬í•¨)
    client = MlflowClient()

    # ðŸ” "IrisModel"ì˜ ë“±ë¡ëœ ëª¨ë¸ ì¤‘ í˜„ìž¬ ì–´ë–¤ Stageì—ë„ ë°°ì •ë˜ì§€ ì•Šì€ ìµœì‹  ë²„ì „ ê°€ì ¸ì˜¤ê¸°
    latest_versions = client.get_latest_versions("IrisModel", stages=["None"])
    
    if not latest_versions:
        print("â— ë“±ë¡ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # â« ê°€ìž¥ ìµœì‹  ë²„ì „ ì„ íƒ (= .version ì„ í†µí•´ ì†ì„± ê°’ ì¶”ì¶œ / .name or .stage ë“± ê°€ëŠ¥)
    latest_version = latest_versions[0].version

    # ðŸš€ í•´ë‹¹ ë²„ì „ì„ Production ë‹¨ê³„ë¡œ ì „í™˜
    client.transition_model_version_stage(
        name="IrisModel",
        version=latest_version,
        stage="Production"
    )

    # âœ… ê²°ê³¼ ì¶œë ¥
    print(f"ðŸš€ IrisModel version {latest_version} â†’ Production ë“±ë¡ ì™„ë£Œ")

# ðŸ”§ Airflowë‚˜ CLIì—ì„œ í˜¸ì¶œë  ìˆ˜ ìžˆë„ë¡ í•¨ìˆ˜í™”
```

---

## ðŸ› ï¸ 2. Airflow DAG ìž‘ì„± (`airflow/dags/train_with_mlflow.py`)

```python
# airflow/dags/train_with_mlflow.py

# ðŸ”§ Airflow DAG ê¸°ë³¸ êµ¬ì„±
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import sys

# ðŸ“ ml_code ë””ë ‰í† ë¦¬ ê²½ë¡œ ì¶”ê°€ (import ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •)
sys.path.append("/opt/airflow/ml_code")

# ðŸ“¦ í•™ìŠµ í•¨ìˆ˜ì™€ ìŠ¹ê²© í•¨ìˆ˜ import
from train_mlflow import run_experiment      # ëª¨ë¸ í•™ìŠµ ë° ë“±ë¡
from promote_mlflow import promote_model    # ëª¨ë¸ ìŠ¤í…Œì´ì§€ ì „í™˜

# ðŸ§¾ DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'start_date': datetime(2023, 1, 1),
    'retries': 1,  # ì‹¤íŒ¨ ì‹œ ìž¬ì‹œë„ íšŸìˆ˜
}

# ðŸ“… DAG ì •ì˜
with DAG(
    dag_id='train_with_mlflow',             # DAG ì´ë¦„ (Airflow UIì— í‘œì‹œ)
    default_args=default_args,
    schedule_interval=None,                 # ìˆ˜ë™ ì‹¤í–‰ (ìŠ¤ì¼€ì¤„ ì—†ìŒ)
    catchup=False,                          # ê³¼ê±° ë‚ ì§œ ì‹¤í–‰ ì•ˆ í•¨
    tags=['ml', 'mlflow'],                  # íƒœê·¸ (í•„í„°ë§ìš©)
) as dag:

    # ðŸ§ª [1ë‹¨ê³„] ëª¨ë¸ í•™ìŠµ ë° MLflowì— ë“±ë¡
    train_task = PythonOperator(
        task_id='run_training',
        python_callable=run_experiment,     # ì‹¤í–‰í•  í•¨ìˆ˜ ì§€ì •
    )

    # ðŸš€ [2ë‹¨ê³„] ìµœì‹  ë²„ì „ ëª¨ë¸ì„ Productionìœ¼ë¡œ Promote
    promote_task = PythonOperator(
        task_id='promote_model_to_production',
        python_callable=promote_model,
    )

    # ðŸ“ ìž‘ì—… ì‹¤í–‰ ìˆœì„œ ì •ì˜: í•™ìŠµ í›„ â†’ ìŠ¹ê²©
    train_task >> promote_task
```

---

## ðŸ”§ 3. Docker ê²½ë¡œì™€ ë³¼ë¥¨ ì •ë¦¬ (ë³µìŠµ)

| ì»¨í…Œì´ë„ˆ | ë¡œë”© ê²½ë¡œ | ì—­í•  |
| --- | --- | --- |
| Airflow | `/opt/airflow/ml_code/train_mlflow.py` | í•™ìŠµ ì‹¤í–‰ |
| MLflow | `/mlflow/mlruns/` | ëª¨ë¸ ì €ìž¥ì†Œ |
| FastAPI | `/mlflow/mlruns/` | ëª¨ë¸ ë¡œë“œ |

âž¡ ë¡œì»¬ì˜ `/mlflow_store`ë¥¼ **ëª¨ë“  ì»¨í…Œì´ë„ˆì— ê³µí†µ mount**í–ˆê¸° ë•Œë¬¸ì— ë¬¸ì œì—†ì´ ê³µìœ ë¨!

---

## âœ… 4. ì‹¤í–‰ í›„ ê¸°ëŒ€ ê²°ê³¼

```bash
$ docker-compose up --build
```

Airflow ì›¹ UIì—ì„œ `train_with_mlflow` DAG ì‹¤í–‰ â†’

âœ… ëª¨ë¸ì´ í•™ìŠµë˜ê³ 

âœ… `/mlflow/mlruns/`ì— artifactê°€ ì €ìž¥ë˜ë©°

âœ… `IrisModel`ì´ **Model Registry**ì— ë“±ë¡ë¨
âœ… `promote_mlflow.py` ì‹¤í–‰ì„ í†µí•´, ë“±ë¡ëœ ëª¨ë¸ì„ **Staging** ë˜ëŠ” **Production** ë‹¨ê³„ë¡œ ìžë™ ìŠ¹ê²©í•¨

---

## ðŸ” í™•ì¸ ë°©ë²•

1. Airflow ì›¹ UI â†’ `localhost:8080`
2. MLflow UI â†’ `localhost:5000`
    - Experiments â†’ `iris_experiment`
    - ëª¨ë¸ ì„±ëŠ¥ ë¡œê·¸ + `IrisModel` ë“±ë¡ ì—¬ë¶€ í™•ì¸ ê°€ëŠ¥

---

### ðŸ§ª í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '[
    {
      "sepal_length": 5.1,
      "sepal_width": 3.5,
      "petal_length": 1.4,
      "petal_width": 0.2
    },
    {
      "sepal_length": 6.0,
      "sepal_width": 2.9,
      "petal_length": 4.5,
      "petal_width": 1.5
    }
  ]'
```

> ì˜ˆì‹œ ê²°ê³¼:
> 

```json
{
"predictions":[0,1]
}
```
