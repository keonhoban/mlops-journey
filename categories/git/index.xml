<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Git on 🏔️ MLOps Journey</title><link>https://keonhoban.github.io/mlops-journey/categories/git/</link><description>Recent content in Git on 🏔️ MLOps Journey</description><generator>Hugo -- 0.145.0</generator><language>ko</language><lastBuildDate>Tue, 15 Jul 2025 17:55:05 +0900</lastBuildDate><atom:link href="https://keonhoban.github.io/mlops-journey/categories/git/index.xml" rel="self" type="application/rss+xml"/><item><title>[MLOps 플랫폼 구축 : Airflow-MLflow-FastAPI (Helm)]</title><link>https://keonhoban.github.io/mlops-journey/projects/mlops_pipeline/helm/</link><pubDate>Tue, 15 Jul 2025 17:55:05 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/projects/mlops_pipeline/helm/</guid><description>&lt;h2 id="-전체-시리즈-요약">📌 전체 시리즈 요약&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>순서&lt;/th>
&lt;th>주제&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/01/">🔗 실습을 위한 인프라 사전 구성 (Kubernetes, NFS, PostgreSQL, S3 등)&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/02/">🔗 Secret/보안 구성 및 Kubernetes 연동&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/03/">🔗 MLflow Tracking 서버 및 Registry 구축&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>4&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/04/">🔗 Airflow DAG Git 연동 및 Secret 기반 구성&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>5&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/05/">🔗 FastAPI 모델 서빙 &amp;amp; MLflow 모델 자동 로딩&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>6&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/06/">🔗 Airflow + MLflow + FastAPI 연결을 통해 모델 핫스왑&lt;/a>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="-지금까지-구현한-아키텍처-요약">💡 지금까지 구현한 아키텍처 요약&lt;/h2>
&lt;pre tabindex="0">&lt;code class="language-mermaid" data-lang="mermaid">graph TD
%% 클러스터 구성
subgraph &amp;#34;Kubernetes Cluster&amp;#34;
subgraph &amp;#34;Namespace: mlflow&amp;#34;
MLflow[📦 MLflow Pod]
end
subgraph &amp;#34;Namespace: airflow&amp;#34;
Airflow[📦 Airflow Pod]
end
subgraph &amp;#34;Namespace: fastapi&amp;#34;
FastAPI[📦 FastAPI Pod]
end
end
%% 외부 시스템
subgraph &amp;#34;External Systems&amp;#34;
S3[🪣 S3 Bucket]
DB_PostgreSQL[🗄️ PostgreSQL DB]
end
%% Secret 구성
subgraph &amp;#34;Kubernetes Secrets&amp;#34;
AWS_Secret[🔐 aws-credentials-secret]
MLflow_DB_Secret[🔐 mlflow-db-secret]
Airflow_DB_Secret[🔐 airflow-db-secret]
end
%% MLflow 연동
MLflow --&amp;gt;|&amp;#34;모델 메타데이터 저장&amp;#34;| DB_PostgreSQL
MLflow --&amp;gt;|&amp;#34;모델 아티팩트 저장&amp;#34;| S3
AWS_Secret --&amp;gt; MLflow
MLflow_DB_Secret --&amp;gt; MLflow
%% Airflow 연동
Airflow --&amp;gt;|&amp;#34;모델 학습 후 등록&amp;#34;| MLflow
Airflow --&amp;gt;|&amp;#34;추론 결과 저장&amp;#34;| DB_PostgreSQL
AWS_Secret --&amp;gt; Airflow
Airflow_DB_Secret --&amp;gt; Airflow
%% FastAPI 연동
FastAPI --&amp;gt;|&amp;#34;모델 메타정보 조회&amp;#34;| MLflow
FastAPI --&amp;gt;|&amp;#34;모델 파일 다운로드&amp;#34;| S3
FastAPI --&amp;gt;|&amp;#34;추론 입력 데이터 접근&amp;#34;| S3
AWS_Secret --&amp;gt; FastAPI
%% 서비스 흐름 강조
style FastAPI fill:#d1f7c4,stroke:#3fa34d,stroke-width:2px
style Airflow fill:#cfe2ff,stroke:#2c6ecb,stroke-width:2px
style MLflow fill:#fce2c8,stroke:#e09100,stroke-width:2px
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;strong>Kubernetes 기반 Pod로 모든 구성 요소 운영&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Secret 기반 AWS 인증 정보 및 DB 정보 주입&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Ingress 기반 접근 (ex. airflow.local, mlflow.local, fastapi.local)&lt;/strong>&lt;/li>
&lt;li>&lt;strong>MLflow + Airflow + FastAPI 연계로 실시간 모델 관리/서빙 자동화&lt;/strong>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-실무-관점에서-강점">🎯 실무 관점에서 강점&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>항목&lt;/th>
&lt;th>내용&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>모델 실험 자동화&lt;/td>
&lt;td>Airflow DAG + MLflow 연동으로 다양한 모델 버전 학습 자동화&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>서빙 안정성&lt;/td>
&lt;td>FastAPI가 &lt;code>Production&lt;/code> Stage 기준으로 모델 로드 → 무중단 핫스왑 가능&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>보안 구성&lt;/td>
&lt;td>AWS 인증 정보 및 DB 정보는 Secret으로 주입&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>인프라 이식성&lt;/td>
&lt;td>Helm + Docker + Kubernetes 기반 → 어디서든 이식 가능&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>실시간 추론 확인&lt;/td>
&lt;td>Ingress 기반 UI/Endpoint 연결 → 바로 curl 테스트 가능&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="-회고">🔍 회고&lt;/h2>
&lt;h3 id="-프로덕션-환경-고려">✅ 프로덕션 환경 고려&lt;/h3>
&lt;ul>
&lt;li>운영 가능한 MLOps 구조로 설계 (유지보수/보안 고려)&lt;/li>
&lt;li>AWS S3, PostgreSQL, Kubernetes, GitOps까지 현실 환경 가정하고 구성&lt;/li>
&lt;li>Secret 설계, Volume 마운트, GitSync, 커스텀 이미지 등 세세한 부분까지 설계 주도&lt;/li>
&lt;/ul>
&lt;h3 id="-자동화-기반-설계">✅ 자동화 기반 설계&lt;/h3>
&lt;ul>
&lt;li>Airflow를 통해 모델 학습 → Registry 등록 → 서빙까지 자동화&lt;/li>
&lt;li>모델 핫스왑 실험까지 성공적으로 구현&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-부족했던-점--보완-계획">🧱 부족했던 점 &amp;amp; 보완 계획&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>항목&lt;/th>
&lt;th>개선 포인트&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>모니터링&lt;/td>
&lt;td>Prometheus + Grafana로 서빙/실험 성능 모니터링 추가 필요&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>모델 테스트 자동화&lt;/td>
&lt;td>pytest + CI 파이프라인 구성으로 품질 확보 고려&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Kubeflow 연계&lt;/td>
&lt;td>Kubeflow Pipelines 및 Katib 등과의 비교 분석 예정&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Terraform 기반 전환&lt;/td>
&lt;td>Helm 구성 요소를 코드로 관리하는 Terraform 인프라 전환 계획&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="-다음-단계-설계">📈 다음 단계 설계&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>기간&lt;/th>
&lt;th>목표&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>2025년 8월&lt;/td>
&lt;td>Kubeflow 기반 재구성 + 모델 자동 튜닝 실험&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2025년 9월&lt;/td>
&lt;td>Triton Inference Server 연동 + GPU 서빙 실습&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2025년 10월&lt;/td>
&lt;td>ScyllaDB &amp;amp; LLM 서빙 구조 실험&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>연말&lt;/td>
&lt;td>MLOps 포트폴리오 정리 및 지원서 작성&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="-마치며">✨ 마치며&lt;/h2>
&lt;p>이번 시리즈는 단순한 학습이 아니라, 설계에 대해 고민하며&lt;/p></description></item><item><title>[MLOps 플랫폼 구축 - 6단계: 실시간 모델 핫스왑 구조 실험]</title><link>https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/06/</link><pubDate>Thu, 10 Jul 2025 17:12:00 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/06/</guid><description>&lt;h2 id="-tldr">✅ TL;DR&lt;/h2>
&lt;ul>
&lt;li>&lt;code>Airflow&lt;/code>에서 선택한 모델 버전에 따라 학습 스크립트를 다르게 실행&lt;/li>
&lt;li>학습된 모델을 &lt;code>MLflow Model Registry&lt;/code>에 등록 → Production 단계로 자동 승격&lt;/li>
&lt;li>&lt;code>FastAPI&lt;/code> 서버는 &lt;code>Production 모델&lt;/code>을 다시 로드 → 별도 코드 수정 없이 핫스왑 완료&lt;/li>
&lt;li>실무에서 모델 검증/배포 사이클 자동화에 바로 응용 가능&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-구조-다이어그램-핫스왑-흐름">🧠 구조 다이어그램 (핫스왑 흐름)&lt;/h2>
&lt;pre tabindex="0">&lt;code class="language-mermaid" data-lang="mermaid">flowchart TD
A1[Airflow DAG: 모델 학습 스크립트 실행] --&amp;gt; B1[MLflow 모델 등록 - 버전 선택]
B1 --&amp;gt; C1[모델 Production 승격]
C1 --&amp;gt; D1[FastAPI 서버 재시작]
D1 --&amp;gt; E1[FastAPI → 최신 모델 로드]
E1 --&amp;gt; F1[추론 API 서빙]
subgraph 실험 관리
B1
C1
end
subgraph 추론 서비스
D1
E1
F1
end
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-핵심-구성-요소">🧩 핵심 구성 요소&lt;/h2>
&lt;h3 id="1-airflow-dag---모델-버전-선택">1. Airflow DAG - 모델 버전 선택&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># dags/train_promote_pipeline_share.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow &lt;span style="color:#f92672">import&lt;/span> DAG
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow.operators.bash &lt;span style="color:#f92672">import&lt;/span> BashOperator
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow.models &lt;span style="color:#f92672">import&lt;/span> Variable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datetime &lt;span style="color:#f92672">import&lt;/span> datetime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>default_args &lt;span style="color:#f92672">=&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;start_date&amp;#39;&lt;/span>: datetime(&lt;span style="color:#ae81ff">2023&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> DAG(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dag_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;train_promote_pipeline_share&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> default_args&lt;span style="color:#f92672">=&lt;/span>default_args,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> schedule&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">None&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> catchup&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tags&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;ml&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>) &lt;span style="color:#66d9ef">as&lt;/span> dag:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># moedel_version 변수 default_var 지정&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model_version &lt;span style="color:#f92672">=&lt;/span> Variable&lt;span style="color:#f92672">.&lt;/span>get(&lt;span style="color:#e6db74">&amp;#34;model_version&amp;#34;&lt;/span>, default_var&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;v1&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> debug_aws &lt;span style="color:#f92672">=&lt;/span> BashOperator(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;debug_aws_credentials&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bash_command&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;echo $HOME &amp;amp;&amp;amp; ls -al $HOME/.aws &amp;amp;&amp;amp; cat $HOME/.aws/credentials&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> env&lt;span style="color:#f92672">=&lt;/span>{&lt;span style="color:#e6db74">&amp;#34;HOME&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/home/airflow&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> run_train_script &lt;span style="color:#f92672">=&lt;/span> BashOperator(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;run_train_script&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># merdel_version 변수화&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bash_command&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#39;python /opt/airflow/dags/repo/ml_code/train_model_&lt;/span>&lt;span style="color:#e6db74">{&lt;/span>model_version&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">.py&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> env&lt;span style="color:#f92672">=&lt;/span>{&lt;span style="color:#e6db74">&amp;#34;HOME&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/home/airflow&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> promote_model &lt;span style="color:#f92672">=&lt;/span> BashOperator(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;promote_model_to_production&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bash_command&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;python /opt/airflow/dags/repo/ml_code/promote_model.py&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> env&lt;span style="color:#f92672">=&lt;/span>{&lt;span style="color:#e6db74">&amp;#34;HOME&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/home/airflow&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> debug_aws &lt;span style="color:#f92672">&amp;gt;&amp;gt;&lt;/span> run_train_script &lt;span style="color:#f92672">&amp;gt;&amp;gt;&lt;/span> promote_model
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>→ &lt;code>Airflow UI &amp;gt; Admin &amp;gt; Variables&lt;/code> 에서 &lt;code>model_version = v1&lt;/code> 또는 &lt;code>v2&lt;/code> 설정 가능&lt;/p></description></item><item><title>[MLOps 플랫폼 구축 - 4단계: Airflow : GitSync + 외부 PostgreSQL + Secret 연동]</title><link>https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/04/</link><pubDate>Thu, 03 Jul 2025 17:11:53 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/04/</guid><description>&lt;h2 id="-tldr">✨ TL;DR&lt;/h2>
&lt;ul>
&lt;li>Helm을 통해 Airflow를 배포하면서 DAG 코드를 Git 저장소에서 자동으로 동기화하는 구조 설계&lt;/li>
&lt;li>GitSync, Secret 기반 SSH 인증, 외부 PostgreSQL, AWS S3 연동까지 포함해 구성&lt;/li>
&lt;li>UI 접근은 Ingress를 통해 이루어지며, 로그는 PVC 또는 S3로 설정 가능&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-아키텍처-구성도">📐 아키텍처 구성도&lt;/h2>
&lt;pre tabindex="0">&lt;code class="language-mermaid" data-lang="mermaid">flowchart TD
subgraph K8s_Cluster[&amp;#34;Kubernetes Cluster&amp;#34;]
Scheduler[(Airflow Scheduler Pod)]
Worker[(Airflow Worker Pod)]
Webserver[(Airflow Webserver Pod)]
end
subgraph DAG_Repo[&amp;#34;Git Repository&amp;#34;]
DAG[(airflow-dags.git)]
end
subgraph Secrets[&amp;#34;K8s Secrets + Configs&amp;#34;]
SecretAWS[(aws-credentials-secret)]
SecretDB[(airflow-db-secret)]
end
subgraph External[&amp;#34;External Systems&amp;#34;]
PG[(PostgreSQL: External Metadata DB)]
NFS[(NFS: airflow-logs-pvc)]
end
%% GitSync
DAG --&amp;gt; Scheduler
DAG --&amp;gt; Worker
DAG --&amp;gt; Webserver
%% Secret 주입
SecretAWS --&amp;gt; Scheduler
SecretAWS --&amp;gt; Worker
SecretAWS --&amp;gt; Webserver
SecretDB --&amp;gt; Scheduler
%% 외부 연동
Scheduler --&amp;gt; PG
Scheduler --&amp;gt; NFS
Worker --&amp;gt; NFS
Webserver --&amp;gt; NFS
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-커스텀-airflow-이미지-구성">🐳 커스텀 Airflow 이미지 구성&lt;/h2>
&lt;p>GitSync DAG에서 MLflow 연동 또는 AWS SDK 사용을 위한 Python 패키지 설치 필요&lt;/p></description></item></channel></rss>