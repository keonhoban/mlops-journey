<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Airflow | ğŸ”ï¸ MLOps Journey</title>
<meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://keonhoban.github.io/mlops-journey/categories/airflow/><link crossorigin=anonymous href=/mlops-journey/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=https://keonhoban.github.io/mlops-journey/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://keonhoban.github.io/mlops-journey/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://keonhoban.github.io/mlops-journey/favicon-32x32.png><link rel=apple-touch-icon href=https://keonhoban.github.io/mlops-journey/apple-touch-icon.png><link rel=mask-icon href=https://keonhoban.github.io/mlops-journey/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://keonhoban.github.io/mlops-journey/categories/airflow/index.xml><link rel=alternate hreflang=en href=https://keonhoban.github.io/mlops-journey/categories/airflow/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://keonhoban.github.io/mlops-journey/categories/airflow/"><meta property="og:site_name" content="ğŸ”ï¸  MLOps Journey"><meta property="og:title" content="Airflow"><meta property="og:locale" content="ko"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Airflow"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://keonhoban.github.io/mlops-journey/ accesskey=h title="ğŸ”ï¸  MLOps Journey (Alt + H)">ğŸ”ï¸ MLOps Journey</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://keonhoban.github.io/mlops-journey/ title="ğŸ  Home"><span>ğŸ  Home</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/projects/ title="ğŸ“‚ Projects"><span>ğŸ“‚ Projects</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/posts/ title="ğŸ“ Blog"><span>ğŸ“ Blog</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/about/ title="ğŸ§— About"><span>ğŸ§— About</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/categories/ title="ğŸ“– Categories"><span>ğŸ“– Categories</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://keonhoban.github.io/mlops-journey/>Home</a>&nbsp;Â»&nbsp;<a href=https://keonhoban.github.io/mlops-journey/categories/>Categories</a></div><h1>Airflow</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[MLOps í”Œë«í¼ êµ¬ì¶• - 4ë‹¨ê³„: Airflow : GitSync + ì™¸ë¶€ PostgreSQL + Secret ì—°ë™]</h2></header><div class=entry-content><p>ğŸ§  ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª… â€œì‹¤ë¬´ì—ì„œëŠ” ë°ì´í„° íŒŒì´í”„ë¼ì¸ì´ë‚˜ ëª¨ë¸ í•™ìŠµ ì‘ì—…ì„ ìˆ˜ì‹œë¡œ ì—…ë°ì´íŠ¸í•˜ê²Œ ë˜ë©°,
ì´ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì—…ë¡œë“œí•˜ì§€ ì•Šê³  Git ê¸°ë°˜ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ í•„ìˆ˜ì…ë‹ˆë‹¤.
AirflowëŠ” GitSync ê¸°ëŠ¥ì„ í†µí•´ DAGë¥¼ ìë™ ë™ê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.â€
DAG ì½”ë“œê°€ Gitìœ¼ë¡œ ê´€ë¦¬ë˜ì–´ì•¼ ë¦¬ë·°, íˆìŠ¤í† ë¦¬, í˜‘ì—… ê°€ëŠ¥ GitSync â†’ DAG ìë™ ë°°í¬ (CI/CD ê°œë… ì ìš©) Secretìœ¼ë¡œ Git ì¸ì¦ â†’ ì¡°ì§ ë‚´ GitOps ë¬¸í™”ì™€ ì—°ê³„ âœ¨ TL;DR Helmì„ í†µí•´ Airflowë¥¼ ë°°í¬í•˜ë©´ì„œ DAG ì½”ë“œë¥¼ Git ì €ì¥ì†Œì—ì„œ ìë™ìœ¼ë¡œ ë™ê¸°í™”í•˜ëŠ” êµ¬ì¡° ì„¤ê³„ GitSync, Secret ê¸°ë°˜ SSH ì¸ì¦, ì™¸ë¶€ PostgreSQL, AWS S3 ì—°ë™ê¹Œì§€ í¬í•¨í•´ êµ¬ì„± UI ì ‘ê·¼ì€ Ingressë¥¼ í†µí•´ ì´ë£¨ì–´ì§€ë©°, ë¡œê·¸ëŠ” PVC ë˜ëŠ” S3ë¡œ ì„¤ì • ê°€ëŠ¥ ğŸ“ ì•„í‚¤í…ì²˜ êµ¬ì„±ë„ ...</p></div><footer class=entry-footer><span title='2025-07-03 17:11:53 +0900 +0900'>July 3, 2025</span>&nbsp;Â·&nbsp;4 min</footer><a class=entry-link aria-label="post link to [MLOps í”Œë«í¼ êµ¬ì¶• - 4ë‹¨ê³„: Airflow : GitSync + ì™¸ë¶€ PostgreSQL + Secret ì—°ë™]" href=https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/04/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow ê¸°ì´ˆ ìë™í™” - Airflow â†’ MLflow â†’ FastAPI]</h2></header><div class=entry-content><p>ğŸ§­ ì „ì²´ íë¦„ ì˜ˆì‹œ [AIRFLOW DAG ì‹¤í–‰] â†“ [train_mlflow.py] - iris ëª¨ë¸ í•™ìŠµ - íŒŒë¼ë¯¸í„°/ë©”íŠ¸ë¦­ ë¡œê¹… - ëª¨ë¸ Registry ë“±ë¡ â†“ [promote_mlflow.py] - ìµœì‹  ëª¨ë¸ì„ Productionìœ¼ë¡œ ì „í™˜ â†“ [FastAPI] - models:/IrisModel/Production â†’ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ğŸ‘‰ ì‹¤ìŠµ ì½”ë“œëŠ” ğŸ”— GitHub (Airflow + MLflow + FastAPI)
âœ… [1ë‹¨ê³„] í”„ë¡œì íŠ¸ ê¸°ë³¸ í´ë” êµ¬ì¡° ì„¤ê³„ ğŸ“ 1. ì „ì²´ ë””ë ‰í† ë¦¬ êµ¬ì„±ë„ mlops_project/ â”œâ”€â”€ airflow/ ğŸ›« Airflow ì„¤ì • ë° DAG ìŠ¤ì¼€ì¤„ëŸ¬ â”‚ â”œâ”€â”€ dags/ â† DAG ì •ì˜ ë””ë ‰í† ë¦¬ â”‚ â”‚ â””â”€â”€ train_with_mlflow.py â† í•™ìŠµ DAG (MLflow ì—°ë™) â”‚ â”œâ”€â”€ Dockerfile.airflow â† Airflowìš© Dockerfile â”‚ â”œâ”€â”€ requirements.txt â† Airflow ì˜ì¡´ì„± â”‚ â””â”€â”€ .dockerignore â”‚ â”œâ”€â”€ fastapi/ âš¡ FastAPI ì˜ˆì¸¡ API ì„œë²„ â”‚ â”œâ”€â”€ app/ â”‚ â”‚ â””â”€â”€ main.py â† ëª¨ë¸ ì„œë¹™ ì—”ë“œí¬ì¸íŠ¸ â”‚ â”œâ”€â”€ Dockerfile.api â† FastAPIìš© Dockerfile â”‚ â”œâ”€â”€ requirements.txt â† FastAPI ì˜ì¡´ì„± â”‚ â””â”€â”€ .dockerignore â”‚ â”œâ”€â”€ ml_code/ ğŸ§  ML í•™ìŠµ ë° í”„ë¡œëª¨ì…˜ ì½”ë“œ â”‚ â”œâ”€â”€ train_mlflow.py â† ëª¨ë¸ í•™ìŠµ ë° MLflow ë¡œê¹… â”‚ â””â”€â”€ promte_mlflow.py â† ëª¨ë¸ í”„ë¡œëª¨ì…˜ (Staging â†’ Production) â”‚ â”œâ”€â”€ mlflow_store/ ğŸ—‚ï¸ MLflow ì €ì¥ì†Œ ê²½ë¡œ (ë³¼ë¥¨) â”‚ â”œâ”€â”€ Dockerfile.mlflow â† MLflow ì„œë²„ ì»¤ìŠ¤í„°ë§ˆì´ì§• â”‚ â”œâ”€â”€ mlflow.db â† Model Registry DB (sqlite) â”‚ â”œâ”€â”€ mlruns/ â† ì‹¤í—˜ ë¡œê·¸ ë””ë ‰í† ë¦¬ â”‚ â”œâ”€â”€ artifacts/ â† ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì €ì¥ì†Œ â”‚ â””â”€â”€ .dockerignore â”‚ â”œâ”€â”€ docker-compose.yaml ğŸ§© ì „ì²´ ì„œë¹„ìŠ¤ êµ¬ì„± ì •ì˜ â”œâ”€â”€ .env ğŸ” ë¯¼ê° ì •ë³´ (.envë¡œ ë¶„ë¦¬) â”œâ”€â”€ README.md ğŸ“ ì „ì²´ í”„ë¡œì íŠ¸ ë¬¸ì„œí™” â”œâ”€â”€ .gitignore â””â”€â”€ .dockerignore âœ… [2ë‹¨ê³„] docker-compose.yaml í†µí•© êµ¬ì„± ğŸ§­ êµ¬ì„± ëª©í‘œ ì„œë¹„ìŠ¤ëª… ì„¤ëª… í¬íŠ¸ airflow DAG ì‹¤í–‰ í™˜ê²½ (webserver/scheduler) 8080 postgres Airflow ë©”íƒ€ë°ì´í„° ì €ì¥ìš© DB ë‚´ë¶€ í†µì‹  mlflow MLflow UI + Registry ê¸°ëŠ¥ 5000 fastapi ì¶”ë¡  API ì„œë²„ (ëª¨ë¸ ë¡œë”©) 8000 ì´ë¯¸ì§€ ì‚¬ìš©ì‹œ ì£¼ì˜ (UIë§Œ ì œê³µí•˜ëŠ” ì´ë¯¸ì§€ ì¡´ì¬) ğŸ“„ docker-compose.yaml ì „ì²´ ì˜ˆì‹œ version: '3.8' services: # ğŸ“¦ PostgreSQL: Airflow ë©”íƒ€ë°ì´í„° ì €ì¥ìš© DB postgres: image: postgres:13 container_name: postgres env_file: - .env # â† ë¯¼ê°ì •ë³´ ë¶„ë¦¬ (ì•„ì´ë””/ë¹„ë²ˆ) environment: POSTGRES_USER: ${POSTGRES_USER} POSTGRES_PASSWORD: ${POSTGRES_PASSWORD} POSTGRES_DB: ${POSTGRES_DB} volumes: # â† ì½”ë“œ/ë°ì´í„° ê³µìœ  ë° ì˜ì†ì„± ë³´ì¥ - postgres_data:/var/lib/postgresql/data # â† DB ë°ì´í„° ìœ ì§€ (ì¬ì‹œì‘ ëŒ€ë¹„) # ğŸ›« Airflow: DAG ìŠ¤ì¼€ì¤„ëŸ¬ ë° íƒœìŠ¤í¬ ì‹¤í–‰ airflow: build: context: ./airflow # â†’ Airflow ì „ìš© Dockerfile ê²½ë¡œ dockerfile: Dockerfile.airflow container_name: airflow command: standalone # â†’ ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨ ì‹¤í–‰ ëª…ë ¹ # (- Scheduler + Webserver + DB ì´ˆê¸°í™”ê¹Œì§€ ìë™ìœ¼ë¡œ í•œë²ˆì— ì‹¤í–‰) # (- ì‹¤ë¬´/ìš´ì˜ì—ì„œëŠ” airflow-webserver, airflow-scheduler í•„ë“œ ë¶„ë¦¬) ports: - "8080:8080" # â†’ Airflow ì›¹ UI (localhost:8080) depends_on: - postgres # â†’ DBê°€ ë¨¼ì € ì˜¬ë¼ì™€ì•¼ Airflow ì‹œì‘ ê°€ëŠ¥ env_file: - .env environment: # Airflow ë©”íƒ€ë°ì´í„° DB ì—°ê²° ì£¼ì†Œ AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW__CORE__SQL_ALCHEMY_CONN} # Airflow ì˜ˆì œ DAG ë¶ˆëŸ¬ì˜¬ì§€ ì—¬ë¶€ AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES} MLFLOW_TRACKING_URI: http://mlflow:5000 # â†’ DAG ì½”ë“œì—ì„œ MLflow ì—°ë™ volumes: - ./airflow/dags:/opt/airflow/dags # DAG íŒŒì¼ mount - ./ml_code:/opt/airflow/ml_code # í•™ìŠµ ì½”ë“œ ê³µìœ  - ./mlflow_store:/mlflow # ëª¨ë¸ ì €ì¥ì†Œ ê³µìœ  # ğŸ”¬ MLflow: ì‹¤í—˜ ì¶”ì  + ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì„œë²„ mlflow: build: context: ./mlflow_store # ì»¤ìŠ¤í…€ Dockerfile ìœ„ì¹˜ dockerfile: Dockerfile.mlflow ports: - "5000:5000" # â†’ MLflow UI (localhost:5000) volumes: - ./mlflow_store:/mlflow # ì‹¤í—˜ ë¡œê·¸ + DB + artifacts ì €ì¥ environment: - MLFLOW_TRACKING_URI=http://0.0.0.0:5000 # ë‚´ë¶€ ì»¨í…Œì´ë„ˆ ê¸°ì¤€ URI # âš¡ FastAPI: ëª¨ë¸ ì„œë¹™ API fastapi: build: context: ./fastapi dockerfile: Dockerfile.api container_name: fastapi ports: - "8000:8000" # â†’ ì˜ˆì¸¡ API ì—”ë“œí¬ì¸íŠ¸ (localhost:8000) volumes: - ./fastapi/app:/app/app # FastAPI app ë””ë ‰í† ë¦¬ mount - ./ml_code:/app/ml_code # í•™ìŠµ/ëª¨ë¸ ì½”ë“œ ê³µìœ  - ./mlflow_store:/mlflow # ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ mount # ğŸ—‚ï¸ ë³¼ë¥¨ ì •ì˜ (Postgres DB ì˜ì†ì„± ìœ ì§€) volumes: postgres_data: ğŸ ì¶”ê°€ë¡œ í•´ì•¼ í•  ê²ƒ Airflow ì²« ì‹¤í–‰ í›„ì—” ë³´í†µ ê´€ë¦¬ì ê³„ì • ìƒì„±ë„ í•´ì¤˜ì•¼ í•¨: # airflow ì»¨í…Œì´ë„ˆ ì ‘ì† docker exec -it airflow bash # ê´€ë¦¬ì ê³„ì • ìƒì„± airflow users create \ --username airflow \ --password airflow \ --firstname Keoho \ --lastname Ban \ --role Admin \ --email airflow@example.com ğŸ” [êµ¬ì¶• Tip] Airflow, FastAPI, MLflow ê°„ ê³µìœ  ë³¼ë¥¨ êµ¬ì¡° í™•ì¸ ê³µìœ  ë¦¬ì†ŒìŠ¤ ì„¤ëª… ./mlflow_store:/mlflow (MLflow) MLflow ì„œë²„ê°€ ì“°ëŠ” ë¡œê·¸/ëª¨ë¸ ì €ì¥ì†Œ ./mlflow_store:/mlflow (Airflow) í•™ìŠµ í›„ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜ ê³µìœ  ./mlflow_store:/mlflow (FastAPI) ëª¨ë¸ ì¶”ë¡  ì‹œ ë¡œë“œ ê²½ë¡œ ê³µìœ  â¡ ê²½ë¡œ í†µì¼ì„±ì´ ë§¤ìš° ì¤‘ìš”í•¨! ì§€ê¸ˆì€ ëª¨ë‘ ./mlflowë¡œ ê³µìœ  (./mlflow í•˜ìœ„ì— /mlruns ì¡´ì¬)
...</p></div><footer class=entry-footer><span title='2025-06-13 20:58:51 +0900 +0900'>June 13, 2025</span>&nbsp;Â·&nbsp;8 min</footer><a class=entry-link aria-label="post link to [Airflow ê¸°ì´ˆ ìë™í™” - Airflow â†’ MLflow â†’ FastAPI]" href=https://keonhoban.github.io/mlops-journey/projects/mlops_pipeline/basic/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 5ë‹¨ê³„: PythonOperator + MLflow Tracking ì—°ë™]</h2></header><div class=entry-content><p>ëª©í‘œ
PythonOperatorë¥¼ ì‚¬ìš©í•˜ì—¬ MLflowë¡œ ì‹¤í—˜(ëª¨ë¸ í•™ìŠµ)ì„ ìë™í™”í•˜ê³ , íŒŒë¼ë¯¸í„°, ë©”íŠ¸ë¦­, ëª¨ë¸ì„ ê¸°ë¡í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.
ğŸ‘‰ ì‹¤ìŠµ ì½”ë“œëŠ” ğŸ”— GitHub (Mlflow - Tracking + FastAPI)
ğŸ§­ ì‹¤ìŠµ ì „ì²´ íë¦„ ìš”ì•½ [1ë‹¨ê³„] MLflow ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± [2ë‹¨ê³„] Airflow DAG êµ¬ì„± [3ë‹¨ê³„] DAG ì‹¤í–‰ ë° íŒŒë¼ë¯¸í„°/ë©”íŠ¸ë¦­ í™•ì¸ [4ë‹¨ê³„] ëª¨ë¸ ì €ì¥ ë° ë¡œê¹… ìƒíƒœ ì ê²€ ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡° airflow/ â”œâ”€â”€ dags/ â”‚ â”œâ”€â”€ train_with_mlflow.py â† DAG íŒŒì¼ â”œâ”€â”€ ml_code/ â”‚ â”œâ”€â”€ train_mlflow.py â† MLflow ì—°ë™ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ â””â”€â”€ mlruns/ â† MLflow ë¡œê¹… ê²°ê³¼ ì €ì¥ í´ë” (ìë™ ìƒì„±) ğŸ§ª 1ë‹¨ê³„: MLflow í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± # airflow/ml_code/train_mlflow.py import mlflow import mlflow.sklearn from sklearn.datasets import load_iris from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score def run_experiment(): mlflow.set_tracking_uri("file:/opt/airflow/mlruns") mlflow.set_experiment("airflow_mlflow_example") with mlflow.start_run(): # ë°ì´í„° ë¡œë”© data = load_iris() X, y = data.data, data.target # ëª¨ë¸ ì •ì˜ model = RandomForestClassifier(n_estimators=50, max_depth=3) model.fit(X, y) preds = model.predict(X) acc = accuracy_score(y, preds) # MLflow ê¸°ë¡ mlflow.log_param("n_estimators", 50) mlflow.log_param("max_depth", 3) mlflow.log_metric("accuracy", acc) mlflow.sklearn.log_model(model, "model") ğŸ§ª 2ë‹¨ê³„: Airflow DAG ì‘ì„± # airflow/dags/train_with_mlflow.py from airflow import DAG from airflow.operators.python import PythonOperator from datetime import datetime import sys sys.path.append("/opt/airflow/ml_code") from train_mlflow import run_experiment with DAG( dag_id='mlflow_tracking_dag', start_date=datetime(2023, 1, 1), schedule_interval=None, catchup=False, ) as dag: run_mlflow = PythonOperator( task_id='run_mlflow_training', python_callable=run_experiment, ) âœ… ì‹¤í–‰ ì ˆì°¨ train_mlflow.py ì‘ì„± train_with_mlflow.py DAG ë“±ë¡ Airflow UIì—ì„œ DAG ì‹¤í–‰ Task ë¡œê·¸ì—ì„œ íŒŒë¼ë¯¸í„°/ë©”íŠ¸ë¦­/ëª¨ë¸ ê¸°ë¡ í™•ì¸ â“ëª¨ë“ˆ ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´? docker-compose.yamlì—ì„œ volumes: í•­ëª© í™•ì¸
...</p></div><footer class=entry-footer><span title='2025-06-10 19:49:29 +0900 +0900'>June 10, 2025</span>&nbsp;Â·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 5ë‹¨ê³„: PythonOperator + MLflow Tracking ì—°ë™]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/05/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 4ë‹¨ê³„: BashOperatorë¡œ ì™¸ë¶€ Python í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰]</h2></header><div class=entry-content><p>ëª©í‘œ
train.py ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë³„ë„ íŒŒì¼ë¡œ ì‘ì„± Airflow DAGì—ì„œ í•´ë‹¹ ìŠ¤í¬ë¦½íŠ¸ë¥¼ BashOperatorë¡œ ì‹¤í–‰ ëª¨ë¸ í•™ìŠµ ë° ê²°ê³¼ í™•ì¸ ğŸ‘‰ ì‹¤ìŠµ ì½”ë“œëŠ” ğŸ”— GitHub (Mlflow - Tracking + FastAPI)
ğŸ§­ ì‹¤ìŠµ ì „ì²´ íë¦„ ìš”ì•½ [1ë‹¨ê³„] í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± [2ë‹¨ê³„] BashOperatorë¡œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ DAG êµ¬ì„± [3ë‹¨ê³„] Airflow ì›¹ UIì—ì„œ ì‹¤í–‰ ë° ë¡œê·¸ í™•ì¸ ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡° airflow/ â”œâ”€â”€ dags/ â”‚ â””â”€â”€ run_train_script.py â† DAG íŒŒì¼ â”œâ”€â”€ ml_code/ â”‚ â”œâ”€â”€ train.py â† ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ â”‚ â””â”€â”€ model.pkl â† í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ğŸ§ª [1ë‹¨ê³„] í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (train.py) # airflow/ml_code/train.py import pickle from sklearn.datasets import load_iris from sklearn.ensemble import RandomForestClassifier # ë°ì´í„° ë¡œë”© data = load_iris() X, y = data.data, data.target # ëª¨ë¸ í•™ìŠµ model = RandomForestClassifier() model.fit(X, y) # ëª¨ë¸ ì €ì¥ model_path = "/opt/airflow/ml_code/model.pkl" with open(model_path, "wb") as f: pickle.dump(model, f) ëª¨ë¸ì€ /opt/airflow/ml_code/model.pkl ê²½ë¡œì— ì €ì¥ë©ë‹ˆë‹¤.
...</p></div><footer class=entry-footer><span title='2025-06-10 19:49:27 +0900 +0900'>June 10, 2025</span>&nbsp;Â·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 4ë‹¨ê³„: BashOperatorë¡œ ì™¸ë¶€ Python í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/04/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 3ë‹¨ê³„: ML íŒŒì´í”„ë¼ì¸ DAG êµ¬ì„±]</h2></header><div class=entry-content><p>ëª©í‘œ
ML ì›Œí¬í”Œë¡œìš°ë¥¼ DAG í˜•íƒœë¡œ êµ¬ì„±í•˜ì—¬
ë°ì´í„° ì¤€ë¹„ â†’ ëª¨ë¸ í•™ìŠµ â†’ ëª¨ë¸ ì €ì¥ íë¦„ì„ ì‹œë®¬ë ˆì´ì…˜í•¨
ğŸ‘‰ ì‹¤ìŠµ ì½”ë“œëŠ” ğŸ”— GitHub (Mlflow - Tracking + FastAPI)
ğŸ§­ ì‹¤ìŠµ ì „ì²´ íë¦„ ìš”ì•½ â‘  load_data (ê°€ìƒ ë°ì´í„° ê²½ë¡œ ë¦¬í„´) â‘¡ train_model (ë°ì´í„° ê²½ë¡œ ë°›ì•„ í•™ìŠµ í‰ë‚´) â‘¢ save_model (ëª¨ë¸ ê²½ë¡œ ë°›ì•„ ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€) â†’ XComì„ í†µí•´ ë‹¨ê³„ë³„ ê²°ê³¼ ì „ë‹¬ ğŸ“ ì‹¤ìŠµ ë””ë ‰í† ë¦¬ ì˜ˆì‹œ airflow/ â””â”€â”€ dags/ â””â”€â”€ ml_simulation.py ğŸ§ª ì‹¤ìŠµ ì½”ë“œ (ml_simulation.py) from airflow import DAG from airflow.operators.python import PythonOperator from datetime import datetime def load_data(): print("ğŸ“¥ ë°ì´í„° ë¡œë”© ì™„ë£Œ (ê°€ìƒ)") return {"data_path": "/tmp/fake_data.csv"} def train_model(**context): data = context['ti'].xcom_pull(task_ids='load_data') print(f"ğŸ§ª ë°ì´í„° ê²½ë¡œ: {data['data_path']}") print("ğŸš€ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (ê°€ìƒ)") return {"model_path": "/tmp/fake_model.pkl"} def save_model(**context): model = context['ti'].xcom_pull(task_ids='train_model') print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model['model_path']}") print("âœ… ì €ì¥ ì™„ë£Œ (ê°€ìƒ)") with DAG( dag_id='ml_simulation', start_date=datetime(2023, 1, 1), schedule_interval=None, catchup=False ) as dag: t1 = PythonOperator(task_id='load_data', python_callable=load_data) t2 = PythonOperator(task_id='train_model', python_callable=train_model, provide_context=True) t3 = PythonOperator(task_id='save_model', python_callable=save_model, provide_context=True) t1 >> t2 >> t3 âœ… ì €ì¥ ê²½ë¡œ: dags/ml_simulation.py
...</p></div><footer class=entry-footer><span title='2025-06-07 19:30:16 +0900 +0900'>June 7, 2025</span>&nbsp;Â·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 3ë‹¨ê³„: ML íŒŒì´í”„ë¼ì¸ DAG êµ¬ì„±]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/03/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 2ë‹¨ê³„: Python & Bash Operator + XCom ë°ì´í„° ì „ë‹¬]</h2></header><div class=entry-content><p>ëª©í‘œ
Python í•¨ìˆ˜ì™€ Bash ìŠ¤í¬ë¦½íŠ¸ë¥¼ í•˜ë‚˜ì˜ DAGìœ¼ë¡œ êµ¬ì„± XComì„ í™œìš©í•œ Task ê°„ ë°ì´í„° ì „ë‹¬ ì²´í—˜ Web UIì—ì„œ ì‹¤í–‰ íë¦„ê³¼ ë¡œê·¸ í™•ì¸ ğŸ‘‰ ì‹¤ìŠµ ì½”ë“œëŠ” ğŸ”— GitHub (Mlflow - Tracking + FastAPI)
ğŸ§­ ì‹¤ìŠµ ì „ì²´ íë¦„ ìš”ì•½ â‘  DAG ìƒì„±: PythonOperator + BashOperator ì¡°í•© â‘¡ XComìœ¼ë¡œ íƒœìŠ¤í¬ ê°„ ë©”ì‹œì§€ ì „ë‹¬ â‘¢ ë¡œê·¸ë¡œ ì „ë‹¬ ë©”ì‹œì§€ í™•ì¸ â‘£ ì „ì²´ DAG ì‹¤í–‰ ë° ì˜ì¡´ì„± í™•ì¸ ğŸ“ DAG íŒŒì¼ êµ¬ì¡° airflow/ â”œâ”€â”€ dags/ â”‚ â””â”€â”€ python_bash_xcom.py â† ì—¬ê¸° ì €ì¥ â””â”€â”€ docker-compose.yaml ğŸ§± DAG ì½”ë“œ ì˜ˆì‹œ from airflow import DAG from airflow.operators.python import PythonOperator from airflow.operators.bash import BashOperator from datetime import datetime def generate_message(): return "ğŸŒŸ Hello from PythonOperator!" def print_xcom_message(**context): msg = context['ti'].xcom_pull(task_ids='generate_task') print(f"ğŸ“¬ XCom received message: {msg}") with DAG( dag_id='python_bash_xcom', start_date=datetime(2023, 1, 1), schedule_interval=None, catchup=False, ) as dag: generate_task = PythonOperator( task_id='generate_task', python_callable=generate_message, ) consume_task = PythonOperator( task_id='consume_task', python_callable=print_xcom_message, provide_context=True, ) bash_task = BashOperator( task_id='bash_echo', bash_command="echo 'ğŸ‰ Bash task is running!'" ) generate_task >> consume_task >> bash_task ğŸ§ª ì‹¤í–‰ ë°©ë²• ìš”ì•½ docker-compose up -d # Airflow ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸ ë¸Œë¼ìš°ì € ì ‘ì†: http://localhost:8080 DAG ëª©ë¡ â†’ python_bash_xcom ON â–¶ ë²„íŠ¼ í´ë¦­ â†’ Trigger DAG ê° Task í´ë¦­ â†’ Log íƒ­ì—ì„œ ì‹¤í–‰ ê²°ê³¼ í™•ì¸ ğŸ“Š ê²°ê³¼ í™•ì¸ í¬ì¸íŠ¸ Task ë¡œê·¸ì—ì„œ í™•ì¸ ë‚´ìš© generate_task "ğŸŒŸ Hello from PythonOperator!" ë©”ì‹œì§€ ë¦¬í„´ consume_task ğŸ“¬ XCom received message: ì¶œë ¥ í™•ì¸ bash_task 'ğŸ‰ Bash task is running!' ë¡œê·¸ í™•ì¸ ğŸ§© ì‹¤ë¬´ íŒ XComì€ ê°„ë‹¨í•œ ë¬¸ìì—´/ê²½ë¡œ/ID ë“± ì†Œí˜• ë°ì´í„° ì „ë‹¬ì— ì í•© ëŒ€ìš©ëŸ‰ ê²°ê³¼ëŠ” S3/DBì— ì €ì¥ í›„ ê²½ë¡œë§Œ XComìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ë°©ì‹ ì¶”ì²œ ğŸ”§ MLOps ì‹¤ì „ ì—°ê²° ì‹¤ë¬´ ì‹œë‚˜ë¦¬ì˜¤ Airflow ì‚¬ìš© ë°©ì‹ í•™ìŠµ ê²°ê³¼ ì €ì¥ train_model â†’ register_model íƒœìŠ¤í¬ë¡œ XCom ì „ë‹¬ íƒœìŠ¤í¬ ì—°ê²° íë¦„ ì¶”ì  Graph Viewì—ì„œ DAG ì‹œê°í™”ë¡œ ê´€ë¦¬ í›„ì† ì‘ì—… ìë™í™” BashOperatorë¡œ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë“± ìë™í™” ê°€ëŠ¥</p></div><footer class=entry-footer><span title='2025-06-07 19:30:15 +0900 +0900'>June 7, 2025</span>&nbsp;Â·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 2ë‹¨ê³„: Python & Bash Operator &#43; XCom ë°ì´í„° ì „ë‹¬]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/02/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 1ë‹¨ê³„: ë¡œì»¬ í™˜ê²½ì—ì„œ ê¸°ë³¸ DAG ì‹¤í–‰]</h2></header><div class=entry-content><p>ëª©í‘œ
Docker ê¸°ë°˜ Airflow í™˜ê²½ êµ¬ì„± DAG íŒŒì¼ì„ ì‘ì„±í•˜ê³  ì‹¤í–‰ UIì—ì„œ ì›Œí¬í”Œë¡œìš° íë¦„ê³¼ ë¡œê·¸ë¥¼ ì§ì ‘ í™•ì¸ ğŸ‘‰ ì‹¤ìŠµ ì½”ë“œëŠ” ğŸ”— GitHub (Mlflow - Tracking + FastAPI)
ğŸ§­ ì‹¤ìŠµ ì „ì²´ íë¦„ ìš”ì•½ â‘  Docker ì„¤ì¹˜ í™•ì¸ â‘¡ ê³µì‹ Airflow ì˜ˆì œ ë‹¤ìš´ë¡œë“œ â‘¢ docker-compose ì‹¤í–‰ â‘£ DAG UI ì ‘ì† ë° ì‹¤í–‰ â‘¤ ë¡œê·¸ í™•ì¸ìœ¼ë¡œ ì •ìƒ ì—¬ë¶€ ê²€ì¦ ğŸ“ ì‹¤ìŠµ ë””ë ‰í† ë¦¬ êµ¬ì¡° airflow/ â”œâ”€â”€ dags/ # DAG íŒŒì¼ ì‘ì„± ìœ„ì¹˜ â”œâ”€â”€ logs/ # ì‘ì—… ë¡œê·¸ ì €ì¥ â”œâ”€â”€ plugins/ # ì»¤ìŠ¤í…€ í”ŒëŸ¬ê·¸ì¸ (ì„ íƒ) â”œâ”€â”€ docker-compose.yaml â””â”€â”€ .env # AIRFLOW_UID í¬í•¨ ğŸ”§ ì£¼ìš” ëª…ë ¹ì–´ ì •ë¦¬ # Airflow ì˜ˆì œ ë‹¤ìš´ë¡œë“œ git clone https://github.com/apache/airflow.git cd airflow/dev && ./docker-compose/setup.sh # ë˜ëŠ” ê°„ë‹¨í•œ ë²„ì „ curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.8.2/docker-compose.yaml' mkdir -p ./dags ./logs ./plugins echo -e "AIRFLOW_UID=$(id -u)" > .env # ì„œë¹„ìŠ¤ ì‹¤í–‰ docker-compose up -d # ì ‘ì† http://localhost:8080 (ID/PW: airflow / airflow) ğŸ’¡ ìƒ˜í”Œ DAG ì˜ˆì‹œ from airflow import DAG from airflow.operators.bash import BashOperator from datetime import datetime with DAG(dag_id="hello_airflow", start_date=datetime(2023, 1, 1), schedule_interval="@daily", catchup=False) as dag: t1 = BashOperator(task_id="print_date", bash_command="date") t2 = BashOperator(task_id="say_hello", bash_command="echo 'Hello, Airflow!'") t1 >> t2 ğŸ‘‰ dags/hello_airflow.py ë¡œ ì €ì¥
...</p></div><footer class=entry-footer><span title='2025-06-07 19:29:36 +0900 +0900'>June 7, 2025</span>&nbsp;Â·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 1ë‹¨ê³„: ë¡œì»¬ í™˜ê²½ì—ì„œ ê¸°ë³¸ DAG ì‹¤í–‰]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/01/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://keonhoban.github.io/mlops-journey/categories/airflow/>Â«&nbsp;Prev&nbsp;</a></nav></footer></main><footer class=footer><p style=margin-top:1rem>Â© 2025 Keonho Ban | <a href=https://github.com/keonhoban target=_blank>GitHub</a> | <a href=mailto:keonho0510@naver.com>Email</a></p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>