<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Airflow | 🏔️ MLOps Journey</title>
<meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://keonhoban.github.io/mlops-journey/categories/airflow/><link crossorigin=anonymous href=/mlops-journey/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=https://keonhoban.github.io/mlops-journey/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://keonhoban.github.io/mlops-journey/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://keonhoban.github.io/mlops-journey/favicon-32x32.png><link rel=apple-touch-icon href=https://keonhoban.github.io/mlops-journey/apple-touch-icon.png><link rel=mask-icon href=https://keonhoban.github.io/mlops-journey/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://keonhoban.github.io/mlops-journey/categories/airflow/index.xml><link rel=alternate hreflang=en href=https://keonhoban.github.io/mlops-journey/categories/airflow/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://keonhoban.github.io/mlops-journey/categories/airflow/"><meta property="og:site_name" content="🏔️  MLOps Journey"><meta property="og:title" content="Airflow"><meta property="og:locale" content="ko"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Airflow"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://keonhoban.github.io/mlops-journey/ accesskey=h title="🏔️  MLOps Journey (Alt + H)">🏔️ MLOps Journey</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://keonhoban.github.io/mlops-journey/ title="🏠 Home"><span>🏠 Home</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/projects/ title="📂 Projects"><span>📂 Projects</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/posts/ title="📝 Blog"><span>📝 Blog</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/about/ title="🧗 About"><span>🧗 About</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/categories/ title="📖 Categories"><span>📖 Categories</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://keonhoban.github.io/mlops-journey/>Home</a>&nbsp;»&nbsp;<a href=https://keonhoban.github.io/mlops-journey/categories/>Categories</a></div><h1>Airflow</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[MLOps 플랫폼 구축 : Airflow-MLflow-FastAPI (Helm)]</h2></header><div class=entry-content><p>🧩 실전 시나리오 기반 구성 배경 이 프로젝트는 단순 실습을 넘어서, 실제 발생하는 다음과 같은 문제들을 해결하기 위한 MLOps 인프라 구축을 목표로 설계되었습니다.
여러 모델 실험 결과가 뒤섞여 추적이 어려운 문제
→ MLflow Tracking 서버 + PostgreSQL 메타데이터 저장소 구성
모델 파일 및 로그가 로컬에만 저장되어 협업 및 재현성이 떨어지는 문제
→ S3 기반 artifact store 구성 + pyfunc 기반 모델 서빙 구조 설계
수작업 DAG 등록, 모델 배포 등의 비효율적 운영 문제
→ Airflow + GitSync 연동으로 파이프라인 자동화 및 버전 관리 가능
...</p></div><footer class=entry-footer><span title='2025-07-15 17:55:05 +0900 +0900'>July 15, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [MLOps 플랫폼 구축 : Airflow-MLflow-FastAPI (Helm)]" href=https://keonhoban.github.io/mlops-journey/projects/mlops_pipeline/helm/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[MLOps 플랫폼 구축 - 6단계: 실시간 모델 핫스왑 구조 실험]</h2></header><div class=entry-content><p>🧠 시나리오 설명 머신러닝 모델을 실서비스에 배포할 때, 기존 모델을 새 모델로 안전하게 교체(hot-swap)하는 자동화 구조는 매우 중요한 요구사항입니다.
✅ TL;DR Airflow에서 학습 스크립트를 실행하고 조건부로 모델 등록 성능 기준을 충족한 모델은 Staging으로 자동 승격 FastAPI는 /reload 요청 시 Staging 모델을 다시 로딩 → 코드 수정 없이 핫스왑 운영 환경에서의 실험 자동화, 모델 A/B 테스트, 모델 롤백 등에 확장 가능하도록 설계 🧠 구조 다이어그램 (핫스왑 흐름) 🧩 핵심 구성 요소 1. Airflow DAG - 조건부 모델 등록 # dags/dag_ml_experiment.py from airflow import DAG from airflow.operators.python import PythonOperator, BranchPythonOperator from airflow.operators.empty import EmptyOperator from airflow.models import Variable from datetime import datetime, timedelta, timezone import sys sys.path.append('/opt/airflow/dags/repo/ml_code') from train_and_log_model_fastapi import train_model default_args = { 'start_date': datetime.now(timezone.utc) - timedelta(days=1) } def run_and_check(): # Variable로 파라미터 동적 제어 try: C = float(Variable.get("logreg_C", default_var=1.0)) max_iter = int(Variable.get("logreg_max_iter", default_var=200)) except Exception as e: print(f"[ERROR] 파라미터 불러오기 실패: {str(e)}. 기본값 사용.") C, max_iter = 1.0, 200 # 정확도 기준으로 성공/실패 분기 acc = train_model(C=C, max_iter=max_iter) if acc > 0.9: return 'notify_success' else: return 'notify_failure' def notify_success(): print("🎉 모델 등록 및 핫스왑 성공! FastAPI에 최신 모델 반영 완료.") def notify_failure(): print("❌ 성능 기준 미달. 모델 등록/서빙 생략됨.") with DAG( dag_id="mlflow_experiment_conditional_register_runner_fastapi", default_args=default_args, schedule=None, catchup=False, ) as dag: branch_task = BranchPythonOperator( task_id='branch_by_accuracy', python_callable=run_and_check ) success_notify_task = PythonOperator( task_id='notify_success', python_callable=notify_success ) failure_notify_task = PythonOperator( task_id='notify_failure', python_callable=notify_failure ) branch_task >> [success_notify_task, failure_notify_task] 2. 모델 학습 및 등록 # ml_code/train_and_log_model_fastapi.py import mlflow import mlflow.sklearn from mlflow.tracking import MlflowClient from sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score import sys import requests import time mlflow.set_tracking_uri("http://mlflow-service.mlflow.svc.cluster.local:5000") mlflow.set_experiment("train_and_register_model_exp") def train_model(C, max_iter): X, y = load_iris(return_X_y=True) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) with mlflow.start_run() as run: clf = LogisticRegression(C=C, max_iter=max_iter) clf.fit(X_train, y_train) y_pred = clf.predict(X_test) acc = accuracy_score(y_test, y_pred) mlflow.log_param("C", C) mlflow.log_param("max_iter", max_iter) mlflow.log_metric("accuracy", acc) mlflow.sklearn.log_model(clf, "model") print(f"[INFO] Logged model with accuracy={acc}") if acc > 0.9: # 모델 등록 result = mlflow.register_model( model_uri=f"runs:/{run.info.run_id}/model", name="best_model" ) version = result.version print(f"[INFO] ✅ 모델 등록 완료 (version={version})") # 등록 직후 DB 업데이트 시간 필요 time.sleep(3) # 스테이지 승격 + 기존 버전 Archive client = MlflowClient() client.transition_model_version_stage( name="best_model", version=version, stage="Staging", archive_existing_versions=False # 스테이징은 여러 개 가능 ) print(f"[INFO] 🚀 모델 version {version} → Staging 반영 완료") # FastAPI 핫스왑 요청 (reload 호출) try: response = requests.post("http://fastapi.local/reload") print(f"[INFO] 🔁 FastAPI 모델 리로드 요청 결과: {response.status_code} {response.text}") except Exception as e: print(f"[ERROR] ❌ FastAPI 리로드 요청 실패: {str(e)}") else: print("[WARN] ❌ 성능 기준 미달 (accuracy &lt;= 0.9)") # 모델 버전 출력 (전후 비교 가능) client = MlflowClient() versions = client.get_latest_versions("best_model", stages=["None", "Staging", "Production"]) for v in versions: print(f"[INFO] 🔄 모델 Version={v.version}, Stage={v.current_stage}") return acc if __name__ == "__main__": acc = train_model(float(sys.argv[1]), int(sys.argv[2])) 3. FastAPI 모델 재로딩 구조 # FastAPI app/main.py from fastapi import FastAPI, Request import mlflow.pyfunc import mlflow from mlflow.tracking import MlflowClient import os app = FastAPI() model = None model_info = {} def load_model_from_mlflow(): global model, model_info tracking_uri = os.environ.get("MLFLOW_TRACKING_URI") model_name = os.environ.get("MODEL_NAME") model_stage = os.environ.get("MODEL_STAGE", "Staging") mlflow.set_tracking_uri(tracking_uri) model_uri = f"models:/{model_name}/{model_stage}" model = mlflow.pyfunc.load_model(model_uri) client = MlflowClient() latest = client.get_latest_versions(name=model_name, stages=[model_stage])[0] run_id = latest.run_id version = latest.version print(f"✅ Reloaded model: name={model_name}, stage={model_stage}, version={version}, run_id={run_id}") model_info = { "model_name": model_name, "stage": model_stage, "version": version, "run_id": run_id, "model_uri": model_uri, } @app.on_event("startup") def startup_event(): load_model_from_mlflow() @app.get("/") def root(): return {"message": "FastAPI MLOps is running!"} # 현재 모델 확인 가능 @app.get("/model-info") def get_model_info(): return model_info @app.post("/predict") async def predict(request: Request): input_data = await request.json() prediction = model.predict(input_data) return {"prediction": prediction.tolist()} # Staging 모델 다시 로드 @app.post("/reload") def reload_model(): try: load_model_from_mlflow() return {"status": "success", "message": "🔁 Model reloaded successfully."} except Exception as e: return {"status": "error", "message": f"Reload failed: {str(e)}"} ✅ 테스트 결과 요약 logreg_C, logreg_max_iter 파라미터로 학습 DAG 설정 가능 모델 등록 시 Staging으로 자동 승격 FastAPI 서버에 /reload 호출 시 핫스왑 적용됨 /model-info, /predict에서 새로운 모델 정보 및 예측 결과 확인 완료 🎓 테스트 검증 (모델 등록 + 핫스왑 확인) # 기존 모델 버전 확인 curl http://fastapi.local/model-info | jq % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 144 100 144 0 0 19251 0 --:--:-- --:--:-- --:--:-- 20571 { "model_name": "best_model", "stage": "Staging", "version": "1", "run_id": "8bd09505eabf40648337e811110ab22c", "model_uri": "models:/best_model/Staging" } # 예측 결과 확인 curl -X POST http://fastapi.local/predict \ -H "Content-Type: application/json" \ -d '[ [5.1, 3.5, 1.4, 0.2] ]' | jq % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 42 100 18 100 24 311 415 --:--:-- --:--:-- --:--:-- 736 { "prediction": [ 0 ] } # 모델 reload (핫스왑) curl -X POST http://fastapi.local/reload | jq % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 66 100 66 0 0 186 0 --:--:-- --:--:-- --:--:-- 186 { "status": "success", "message": "🔁 Model reloaded successfully." } # 신규 모델 버전 확인 curl http://fastapi.local/model-info | jq % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 144 100 144 0 0 42985 0 --:--:-- --:--:-- --:--:-- 48000 { "model_name": "best_model", "stage": "Staging", "version": "2", "run_id": "72f388927f5749c185b828a1a16bb063", "model_uri": "models:/best_model/Staging" } # 예측 결과 확인 curl -X POST http://fastapi.local/predict \ -H "Content-Type: application/json" \ -d '[ [5.1, 3.5, 1.4, 0.2] ]' | jq % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 42 100 18 100 24 3831 5108 --:--:-- --:--:-- --:--:-- 10500 { "prediction": [ 0 ] }</p></div><footer class=entry-footer><span title='2025-07-10 17:12:00 +0900 +0900'>July 10, 2025</span>&nbsp;·&nbsp;5 min</footer><a class=entry-link aria-label="post link to [MLOps 플랫폼 구축 - 6단계: 실시간 모델 핫스왑 구조 실험]" href=https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/06/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[MLOps 플랫폼 구축 - 4단계: Airflow : GitSync + 외부 PostgreSQL + Secret 연동]</h2></header><div class=entry-content><p>🧠 시나리오 설명 “실무에서는 데이터 파이프라인이나 모델 학습 작업을 수시로 업데이트하게 되며,
이를 수동으로 업로드하지 않고 Git 기반으로 관리하는 것이 필수입니다.
Airflow는 GitSync 기능을 통해 DAG를 자동 동기화할 수 있습니다.”
DAG 코드가 Git으로 관리되어야 리뷰, 히스토리, 협업 가능 GitSync → DAG 자동 배포 (CI/CD 개념 적용) Secret으로 Git 인증 → 조직 내 GitOps 문화와 연계 ✨ TL;DR Helm을 통해 Airflow를 배포하면서 DAG 코드를 Git 저장소에서 자동으로 동기화하는 구조 설계 GitSync, Secret 기반 SSH 인증, 외부 PostgreSQL, AWS S3 연동까지 포함해 구성 UI 접근은 Ingress를 통해 이루어지며, 로그는 PVC 또는 S3로 설정 가능 📐 아키텍처 구성도 ...</p></div><footer class=entry-footer><span title='2025-07-03 17:11:53 +0900 +0900'>July 3, 2025</span>&nbsp;·&nbsp;4 min</footer><a class=entry-link aria-label="post link to [MLOps 플랫폼 구축 - 4단계: Airflow : GitSync + 외부 PostgreSQL + Secret 연동]" href=https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/04/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow 기초 자동화 - Airflow → MLflow → FastAPI]</h2></header><div class=entry-content><p>🧭 전체 흐름 예시 [AIRFLOW DAG 실행] ↓ [train_mlflow.py] - iris 모델 학습 - 파라미터/메트릭 로깅 - 모델 Registry 등록 ↓ [promote_mlflow.py] - 최신 모델을 Production으로 전환 ↓ [FastAPI] - models:/IrisModel/Production → 실시간 예측 👉 실습 코드는 🔗 GitHub (Airflow + MLflow + FastAPI)
✅ [1단계] 프로젝트 기본 폴더 구조 설계 📁 1. 전체 디렉토리 구성도 mlops_project/ ├── airflow/ 🛫 Airflow 설정 및 DAG 스케줄러 │ ├── dags/ ← DAG 정의 디렉토리 │ │ └── train_with_mlflow.py ← 학습 DAG (MLflow 연동) │ ├── Dockerfile.airflow ← Airflow용 Dockerfile │ ├── requirements.txt ← Airflow 의존성 │ └── .dockerignore │ ├── fastapi/ ⚡ FastAPI 예측 API 서버 │ ├── app/ │ │ └── main.py ← 모델 서빙 엔드포인트 │ ├── Dockerfile.api ← FastAPI용 Dockerfile │ ├── requirements.txt ← FastAPI 의존성 │ └── .dockerignore │ ├── ml_code/ 🧠 ML 학습 및 프로모션 코드 │ ├── train_mlflow.py ← 모델 학습 및 MLflow 로깅 │ └── promte_mlflow.py ← 모델 프로모션 (Staging → Production) │ ├── mlflow_store/ 🗂️ MLflow 저장소 경로 (볼륨) │ ├── Dockerfile.mlflow ← MLflow 서버 커스터마이징 │ ├── mlflow.db ← Model Registry DB (sqlite) │ ├── mlruns/ ← 실험 로그 디렉토리 │ ├── artifacts/ ← 모델 아티팩트 저장소 │ └── .dockerignore │ ├── docker-compose.yaml 🧩 전체 서비스 구성 정의 ├── .env 🔐 민감 정보 (.env로 분리) ├── README.md 📝 전체 프로젝트 문서화 ├── .gitignore └── .dockerignore ✅ [2단계] docker-compose.yaml 통합 구성 🧭 구성 목표 서비스명 설명 포트 airflow DAG 실행 환경 (webserver/scheduler) 8080 postgres Airflow 메타데이터 저장용 DB 내부 통신 mlflow MLflow UI + Registry 기능 5000 fastapi 추론 API 서버 (모델 로딩) 8000 이미지 사용시 주의 (UI만 제공하는 이미지 존재) 📄 docker-compose.yaml 전체 예시 version: '3.8' services: # 📦 PostgreSQL: Airflow 메타데이터 저장용 DB postgres: image: postgres:13 container_name: postgres env_file: - .env # ← 민감정보 분리 (아이디/비번) environment: POSTGRES_USER: ${POSTGRES_USER} POSTGRES_PASSWORD: ${POSTGRES_PASSWORD} POSTGRES_DB: ${POSTGRES_DB} volumes: # ← 코드/데이터 공유 및 영속성 보장 - postgres_data:/var/lib/postgresql/data # ← DB 데이터 유지 (재시작 대비) # 🛫 Airflow: DAG 스케줄러 및 태스크 실행 airflow: build: context: ./airflow # → Airflow 전용 Dockerfile 경로 dockerfile: Dockerfile.airflow container_name: airflow command: standalone # → 로컬 테스트용 간단 실행 명령 # (- Scheduler + Webserver + DB 초기화까지 자동으로 한번에 실행) # (- 실무/운영에서는 airflow-webserver, airflow-scheduler 필드 분리) ports: - "8080:8080" # → Airflow 웹 UI (localhost:8080) depends_on: - postgres # → DB가 먼저 올라와야 Airflow 시작 가능 env_file: - .env environment: # Airflow 메타데이터 DB 연결 주소 AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW__CORE__SQL_ALCHEMY_CONN} # Airflow 예제 DAG 불러올지 여부 AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES} MLFLOW_TRACKING_URI: http://mlflow:5000 # → DAG 코드에서 MLflow 연동 volumes: - ./airflow/dags:/opt/airflow/dags # DAG 파일 mount - ./ml_code:/opt/airflow/ml_code # 학습 코드 공유 - ./mlflow_store:/mlflow # 모델 저장소 공유 # 🔬 MLflow: 실험 추적 + 모델 레지스트리 서버 mlflow: build: context: ./mlflow_store # 커스텀 Dockerfile 위치 dockerfile: Dockerfile.mlflow ports: - "5000:5000" # → MLflow UI (localhost:5000) volumes: - ./mlflow_store:/mlflow # 실험 로그 + DB + artifacts 저장 environment: - MLFLOW_TRACKING_URI=http://0.0.0.0:5000 # 내부 컨테이너 기준 URI # ⚡ FastAPI: 모델 서빙 API fastapi: build: context: ./fastapi dockerfile: Dockerfile.api container_name: fastapi ports: - "8000:8000" # → 예측 API 엔드포인트 (localhost:8000) volumes: - ./fastapi/app:/app/app # FastAPI app 디렉토리 mount - ./ml_code:/app/ml_code # 학습/모델 코드 공유 - ./mlflow_store:/mlflow # 저장된 모델 불러오기 위한 mount # 🗂️ 볼륨 정의 (Postgres DB 영속성 유지) volumes: postgres_data: 🎁 추가로 해야 할 것 Airflow 첫 실행 후엔 보통 관리자 계정 생성도 해줘야 함: # airflow 컨테이너 접속 docker exec -it airflow bash # 관리자 계정 생성 airflow users create \ --username airflow \ --password airflow \ --firstname Keoho \ --lastname Ban \ --role Admin \ --email airflow@example.com 🔁 [구축 Tip] Airflow, FastAPI, MLflow 간 공유 볼륨 구조 확인 공유 리소스 설명 ./mlflow_store:/mlflow (MLflow) MLflow 서버가 쓰는 로그/모델 저장소 ./mlflow_store:/mlflow (Airflow) 학습 후 모델 저장 위치 공유 ./mlflow_store:/mlflow (FastAPI) 모델 추론 시 로드 경로 공유 ➡ 경로 통일성이 매우 중요함! 지금은 모두 ./mlflow로 공유 (./mlflow 하위에 /mlruns 존재)
...</p></div><footer class=entry-footer><span title='2025-06-13 20:58:51 +0900 +0900'>June 13, 2025</span>&nbsp;·&nbsp;8 min</footer><a class=entry-link aria-label="post link to [Airflow 기초 자동화 - Airflow → MLflow → FastAPI]" href=https://keonhoban.github.io/mlops-journey/projects/mlops_pipeline/basic/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 5단계: PythonOperator + MLflow Tracking 연동]</h2></header><div class=entry-content><p>목표
PythonOperator를 사용하여 MLflow로 실험(모델 학습)을 자동화하고, 파라미터, 메트릭, 모델을 기록하는 방법을 학습합니다.
👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 [1단계] MLflow 실험 스크립트 작성 [2단계] Airflow DAG 구성 [3단계] DAG 실행 및 파라미터/메트릭 확인 [4단계] 모델 저장 및 로깅 상태 점검 📁 디렉토리 구조 airflow/ ├── dags/ │ ├── train_with_mlflow.py ← DAG 파일 ├── ml_code/ │ ├── train_mlflow.py ← MLflow 연동 학습 스크립트 └── mlruns/ ← MLflow 로깅 결과 저장 폴더 (자동 생성) 🧪 1단계: MLflow 학습 스크립트 작성 # airflow/ml_code/train_mlflow.py import mlflow import mlflow.sklearn from sklearn.datasets import load_iris from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score def run_experiment(): mlflow.set_tracking_uri("file:/opt/airflow/mlruns") mlflow.set_experiment("airflow_mlflow_example") with mlflow.start_run(): # 데이터 로딩 data = load_iris() X, y = data.data, data.target # 모델 정의 model = RandomForestClassifier(n_estimators=50, max_depth=3) model.fit(X, y) preds = model.predict(X) acc = accuracy_score(y, preds) # MLflow 기록 mlflow.log_param("n_estimators", 50) mlflow.log_param("max_depth", 3) mlflow.log_metric("accuracy", acc) mlflow.sklearn.log_model(model, "model") 🧪 2단계: Airflow DAG 작성 # airflow/dags/train_with_mlflow.py from airflow import DAG from airflow.operators.python import PythonOperator from datetime import datetime import sys sys.path.append("/opt/airflow/ml_code") from train_mlflow import run_experiment with DAG( dag_id='mlflow_tracking_dag', start_date=datetime(2023, 1, 1), schedule_interval=None, catchup=False, ) as dag: run_mlflow = PythonOperator( task_id='run_mlflow_training', python_callable=run_experiment, ) ✅ 실행 절차 train_mlflow.py 작성 train_with_mlflow.py DAG 등록 Airflow UI에서 DAG 실행 Task 로그에서 파라미터/메트릭/모델 기록 확인 ❓모듈 에러가 발생하면? docker-compose.yaml에서 volumes: 항목 확인
...</p></div><footer class=entry-footer><span title='2025-06-10 19:49:29 +0900 +0900'>June 10, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 5단계: PythonOperator + MLflow Tracking 연동]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/05/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 4단계: BashOperator로 외부 Python 학습 스크립트 실행]</h2></header><div class=entry-content><p>목표
train.py 모델 학습 스크립트를 별도 파일로 작성 Airflow DAG에서 해당 스크립트를 BashOperator로 실행 모델 학습 및 결과 확인 👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 [1단계] 학습 스크립트 작성 [2단계] BashOperator로 스크립트 실행 DAG 구성 [3단계] Airflow 웹 UI에서 실행 및 로그 확인 📁 디렉토리 구조 airflow/ ├── dags/ │ └── run_train_script.py ← DAG 파일 ├── ml_code/ │ ├── train.py ← 모델 학습 스크립트 │ └── model.pkl ← 학습된 모델 파일 🧪 [1단계] 학습 스크립트 작성 (train.py) # airflow/ml_code/train.py import pickle from sklearn.datasets import load_iris from sklearn.ensemble import RandomForestClassifier # 데이터 로딩 data = load_iris() X, y = data.data, data.target # 모델 학습 model = RandomForestClassifier() model.fit(X, y) # 모델 저장 model_path = "/opt/airflow/ml_code/model.pkl" with open(model_path, "wb") as f: pickle.dump(model, f) 모델은 /opt/airflow/ml_code/model.pkl 경로에 저장됩니다.
...</p></div><footer class=entry-footer><span title='2025-06-10 19:49:27 +0900 +0900'>June 10, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 4단계: BashOperator로 외부 Python 학습 스크립트 실행]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/04/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 3단계: ML 파이프라인 DAG 구성]</h2></header><div class=entry-content><p>목표
ML 워크플로우를 DAG 형태로 구성하여
데이터 준비 → 모델 학습 → 모델 저장 흐름을 시뮬레이션함
👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 ① load_data (가상 데이터 경로 리턴) ② train_model (데이터 경로 받아 학습 흉내) ③ save_model (모델 경로 받아 저장 완료 메시지) → XCom을 통해 단계별 결과 전달 📁 실습 디렉토리 예시 airflow/ └── dags/ └── ml_simulation.py 🧪 실습 코드 (ml_simulation.py) from airflow import DAG from airflow.operators.python import PythonOperator from datetime import datetime def load_data(): print("📥 데이터 로딩 완료 (가상)") return {"data_path": "/tmp/fake_data.csv"} def train_model(**context): data = context['ti'].xcom_pull(task_ids='load_data') print(f"🧪 데이터 경로: {data['data_path']}") print("🚀 모델 학습 완료 (가상)") return {"model_path": "/tmp/fake_model.pkl"} def save_model(**context): model = context['ti'].xcom_pull(task_ids='train_model') print(f"💾 모델 저장 경로: {model['model_path']}") print("✅ 저장 완료 (가상)") with DAG( dag_id='ml_simulation', start_date=datetime(2023, 1, 1), schedule_interval=None, catchup=False ) as dag: t1 = PythonOperator(task_id='load_data', python_callable=load_data) t2 = PythonOperator(task_id='train_model', python_callable=train_model, provide_context=True) t3 = PythonOperator(task_id='save_model', python_callable=save_model, provide_context=True) t1 >> t2 >> t3 ✅ 저장 경로: dags/ml_simulation.py
...</p></div><footer class=entry-footer><span title='2025-06-07 19:30:16 +0900 +0900'>June 7, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 3단계: ML 파이프라인 DAG 구성]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/03/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 2단계: Python & Bash Operator + XCom 데이터 전달]</h2></header><div class=entry-content><p>목표
Python 함수와 Bash 스크립트를 하나의 DAG으로 구성 XCom을 활용한 Task 간 데이터 전달 체험 Web UI에서 실행 흐름과 로그 확인 👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 ① DAG 생성: PythonOperator + BashOperator 조합 ② XCom으로 태스크 간 메시지 전달 ③ 로그로 전달 메시지 확인 ④ 전체 DAG 실행 및 의존성 확인 📁 DAG 파일 구조 airflow/ ├── dags/ │ └── python_bash_xcom.py ← 여기 저장 └── docker-compose.yaml 🧱 DAG 코드 예시 from airflow import DAG from airflow.operators.python import PythonOperator from airflow.operators.bash import BashOperator from datetime import datetime def generate_message(): return "🌟 Hello from PythonOperator!" def print_xcom_message(**context): msg = context['ti'].xcom_pull(task_ids='generate_task') print(f"📬 XCom received message: {msg}") with DAG( dag_id='python_bash_xcom', start_date=datetime(2023, 1, 1), schedule_interval=None, catchup=False, ) as dag: generate_task = PythonOperator( task_id='generate_task', python_callable=generate_message, ) consume_task = PythonOperator( task_id='consume_task', python_callable=print_xcom_message, provide_context=True, ) bash_task = BashOperator( task_id='bash_echo', bash_command="echo '🎉 Bash task is running!'" ) generate_task >> consume_task >> bash_task 🧪 실행 방법 요약 docker-compose up -d # Airflow 실행 중인지 확인 브라우저 접속: http://localhost:8080 DAG 목록 → python_bash_xcom ON ▶ 버튼 클릭 → Trigger DAG 각 Task 클릭 → Log 탭에서 실행 결과 확인 📊 결과 확인 포인트 Task 로그에서 확인 내용 generate_task "🌟 Hello from PythonOperator!" 메시지 리턴 consume_task 📬 XCom received message: 출력 확인 bash_task '🎉 Bash task is running!' 로그 확인 🧩 실무 팁 XCom은 간단한 문자열/경로/ID 등 소형 데이터 전달에 적합 대용량 결과는 S3/DB에 저장 후 경로만 XCom으로 전달하는 방식 추천 🔧 MLOps 실전 연결 실무 시나리오 Airflow 사용 방식 학습 결과 저장 train_model → register_model 태스크로 XCom 전달 태스크 연결 흐름 추적 Graph View에서 DAG 시각화로 관리 후속 작업 자동화 BashOperator로 배포 스크립트 실행 등 자동화 가능</p></div><footer class=entry-footer><span title='2025-06-07 19:30:15 +0900 +0900'>June 7, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 2단계: Python & Bash Operator &#43; XCom 데이터 전달]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/02/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 1단계: 로컬 환경에서 기본 DAG 실행]</h2></header><div class=entry-content><p>목표
Docker 기반 Airflow 환경 구성 DAG 파일을 작성하고 실행 UI에서 워크플로우 흐름과 로그를 직접 확인 👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 ① Docker 설치 확인 ② 공식 Airflow 예제 다운로드 ③ docker-compose 실행 ④ DAG UI 접속 및 실행 ⑤ 로그 확인으로 정상 여부 검증 📁 실습 디렉토리 구조 airflow/ ├── dags/ # DAG 파일 작성 위치 ├── logs/ # 작업 로그 저장 ├── plugins/ # 커스텀 플러그인 (선택) ├── docker-compose.yaml └── .env # AIRFLOW_UID 포함 🔧 주요 명령어 정리 # Airflow 예제 다운로드 git clone https://github.com/apache/airflow.git cd airflow/dev && ./docker-compose/setup.sh # 또는 간단한 버전 curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.8.2/docker-compose.yaml' mkdir -p ./dags ./logs ./plugins echo -e "AIRFLOW_UID=$(id -u)" > .env # 서비스 실행 docker-compose up -d # 접속 http://localhost:8080 (ID/PW: airflow / airflow) 💡 샘플 DAG 예시 from airflow import DAG from airflow.operators.bash import BashOperator from datetime import datetime with DAG(dag_id="hello_airflow", start_date=datetime(2023, 1, 1), schedule_interval="@daily", catchup=False) as dag: t1 = BashOperator(task_id="print_date", bash_command="date") t2 = BashOperator(task_id="say_hello", bash_command="echo 'Hello, Airflow!'") t1 >> t2 👉 dags/hello_airflow.py 로 저장
...</p></div><footer class=entry-footer><span title='2025-06-07 19:29:36 +0900 +0900'>June 7, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 1단계: 로컬 환경에서 기본 DAG 실행]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/01/></a></article></main><footer class=footer><p style=margin-top:1rem>© 2025 Keonho Ban | <a href=https://github.com/keonhoban target=_blank>GitHub</a> | <a href=mailto:keonho0510@naver.com>Email</a></p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>