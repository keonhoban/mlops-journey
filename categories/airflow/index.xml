<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Airflow on 🏔️ MLOps Journey</title><link>https://keonhoban.github.io/mlops-journey/categories/airflow/</link><description>Recent content in Airflow on 🏔️ MLOps Journey</description><generator>Hugo -- 0.145.0</generator><language>ko</language><lastBuildDate>Tue, 15 Jul 2025 17:55:05 +0900</lastBuildDate><atom:link href="https://keonhoban.github.io/mlops-journey/categories/airflow/index.xml" rel="self" type="application/rss+xml"/><item><title>[MLOps 플랫폼 구축 : Airflow-MLflow-FastAPI (Helm)]</title><link>https://keonhoban.github.io/mlops-journey/projects/mlops_pipeline/helm/</link><pubDate>Tue, 15 Jul 2025 17:55:05 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/projects/mlops_pipeline/helm/</guid><description>&lt;h2 id="-전체-시리즈-요약">📌 전체 시리즈 요약&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>순서&lt;/th>
&lt;th>주제&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/01/">🔗 실습을 위한 인프라 사전 구성 (Kubernetes, NFS, PostgreSQL, S3 등)&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/02/">🔗 Secret/보안 구성 및 Kubernetes 연동&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/03/">🔗 MLflow Tracking 서버 및 Registry 구축&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>4&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/04/">🔗 Airflow DAG Git 연동 및 Secret 기반 구성&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>5&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/05/">🔗 FastAPI 모델 서빙 &amp;amp; MLflow 모델 자동 로딩&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>6&lt;/td>
&lt;td>&lt;a href="https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/06/">🔗 Airflow + MLflow + FastAPI 연결을 통해 모델 핫스왑&lt;/a>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="-지금까지-구현한-아키텍처-요약">💡 지금까지 구현한 아키텍처 요약&lt;/h2>
&lt;pre tabindex="0">&lt;code class="language-mermaid" data-lang="mermaid">graph TD
%% 클러스터 구성
subgraph &amp;#34;Kubernetes Cluster&amp;#34;
subgraph &amp;#34;Namespace: mlflow&amp;#34;
MLflow[📦 MLflow Pod]
end
subgraph &amp;#34;Namespace: airflow&amp;#34;
Airflow[📦 Airflow Pod]
end
subgraph &amp;#34;Namespace: fastapi&amp;#34;
FastAPI[📦 FastAPI Pod]
end
end
%% 외부 시스템
subgraph &amp;#34;External Systems&amp;#34;
S3[🪣 S3 Bucket]
DB_PostgreSQL[🗄️ PostgreSQL DB]
end
%% Secret 구성
subgraph &amp;#34;Kubernetes Secrets&amp;#34;
AWS_Secret[🔐 aws-credentials-secret]
MLflow_DB_Secret[🔐 mlflow-db-secret]
Airflow_DB_Secret[🔐 airflow-db-secret]
end
%% MLflow 연동
MLflow --&amp;gt;|&amp;#34;모델 메타데이터 저장&amp;#34;| DB_PostgreSQL
MLflow --&amp;gt;|&amp;#34;모델 아티팩트 저장&amp;#34;| S3
AWS_Secret --&amp;gt; MLflow
MLflow_DB_Secret --&amp;gt; MLflow
%% Airflow 연동
Airflow --&amp;gt;|&amp;#34;모델 학습 후 등록&amp;#34;| MLflow
Airflow --&amp;gt;|&amp;#34;추론 결과 저장&amp;#34;| DB_PostgreSQL
AWS_Secret --&amp;gt; Airflow
Airflow_DB_Secret --&amp;gt; Airflow
%% FastAPI 연동
FastAPI --&amp;gt;|&amp;#34;모델 메타정보 조회&amp;#34;| MLflow
FastAPI --&amp;gt;|&amp;#34;모델 파일 다운로드&amp;#34;| S3
FastAPI --&amp;gt;|&amp;#34;추론 입력 데이터 접근&amp;#34;| S3
AWS_Secret --&amp;gt; FastAPI
%% 서비스 흐름 강조
style FastAPI fill:#d1f7c4,stroke:#3fa34d,stroke-width:2px
style Airflow fill:#cfe2ff,stroke:#2c6ecb,stroke-width:2px
style MLflow fill:#fce2c8,stroke:#e09100,stroke-width:2px
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>&lt;strong>Kubernetes 기반 Pod로 모든 구성 요소 운영&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Secret 기반 AWS 인증 정보 및 DB 정보 주입&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Ingress 기반 접근 (ex. airflow.local, mlflow.local, fastapi.local)&lt;/strong>&lt;/li>
&lt;li>&lt;strong>MLflow + Airflow + FastAPI 연계로 실시간 모델 관리/서빙 자동화&lt;/strong>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-실무-관점에서-강점">🎯 실무 관점에서 강점&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>항목&lt;/th>
&lt;th>내용&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>모델 실험 자동화&lt;/td>
&lt;td>Airflow DAG + MLflow 연동으로 다양한 모델 버전 학습 자동화&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>서빙 안정성&lt;/td>
&lt;td>FastAPI가 &lt;code>Production&lt;/code> Stage 기준으로 모델 로드 → 무중단 핫스왑 가능&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>보안 구성&lt;/td>
&lt;td>AWS 인증 정보 및 DB 정보는 Secret으로 주입&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>인프라 이식성&lt;/td>
&lt;td>Helm + Docker + Kubernetes 기반 → 어디서든 이식 가능&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>실시간 추론 확인&lt;/td>
&lt;td>Ingress 기반 UI/Endpoint 연결 → 바로 curl 테스트 가능&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="-회고">🔍 회고&lt;/h2>
&lt;h3 id="-프로덕션-환경-고려">✅ 프로덕션 환경 고려&lt;/h3>
&lt;ul>
&lt;li>운영 가능한 MLOps 구조로 설계 (유지보수/보안 고려)&lt;/li>
&lt;li>AWS S3, PostgreSQL, Kubernetes, GitOps까지 현실 환경 가정하고 구성&lt;/li>
&lt;li>Secret 설계, Volume 마운트, GitSync, 커스텀 이미지 등 세세한 부분까지 설계 주도&lt;/li>
&lt;/ul>
&lt;h3 id="-자동화-기반-설계">✅ 자동화 기반 설계&lt;/h3>
&lt;ul>
&lt;li>Airflow를 통해 모델 학습 → Registry 등록 → 서빙까지 자동화&lt;/li>
&lt;li>모델 핫스왑 실험까지 성공적으로 구현&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-부족했던-점--보완-계획">🧱 부족했던 점 &amp;amp; 보완 계획&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>항목&lt;/th>
&lt;th>개선 포인트&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>모니터링&lt;/td>
&lt;td>Prometheus + Grafana로 서빙/실험 성능 모니터링 추가 필요&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>모델 테스트 자동화&lt;/td>
&lt;td>pytest + CI 파이프라인 구성으로 품질 확보 고려&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Kubeflow 연계&lt;/td>
&lt;td>Kubeflow Pipelines 및 Katib 등과의 비교 분석 예정&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Terraform 기반 전환&lt;/td>
&lt;td>Helm 구성 요소를 코드로 관리하는 Terraform 인프라 전환 계획&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="-다음-단계-설계">📈 다음 단계 설계&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>기간&lt;/th>
&lt;th>목표&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>2025년 8월&lt;/td>
&lt;td>Kubeflow 기반 재구성 + 모델 자동 튜닝 실험&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2025년 9월&lt;/td>
&lt;td>Triton Inference Server 연동 + GPU 서빙 실습&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2025년 10월&lt;/td>
&lt;td>ScyllaDB &amp;amp; LLM 서빙 구조 실험&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>연말&lt;/td>
&lt;td>MLOps 포트폴리오 정리 및 지원서 작성&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="-마치며">✨ 마치며&lt;/h2>
&lt;p>이번 시리즈는 단순한 학습이 아니라, 설계에 대해 고민하며&lt;/p></description></item><item><title>[MLOps 플랫폼 구축 - 6단계: 실시간 모델 핫스왑 구조 실험]</title><link>https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/06/</link><pubDate>Thu, 10 Jul 2025 17:12:00 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/06/</guid><description>&lt;h2 id="-tldr">✅ TL;DR&lt;/h2>
&lt;ul>
&lt;li>&lt;code>Airflow&lt;/code>에서 선택한 모델 버전에 따라 학습 스크립트를 다르게 실행&lt;/li>
&lt;li>학습된 모델을 &lt;code>MLflow Model Registry&lt;/code>에 등록 → Production 단계로 자동 승격&lt;/li>
&lt;li>&lt;code>FastAPI&lt;/code> 서버는 &lt;code>Production 모델&lt;/code>을 다시 로드 → 별도 코드 수정 없이 핫스왑 완료&lt;/li>
&lt;li>실무에서 모델 검증/배포 사이클 자동화에 바로 응용 가능&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-구조-다이어그램-핫스왑-흐름">🧠 구조 다이어그램 (핫스왑 흐름)&lt;/h2>
&lt;pre tabindex="0">&lt;code class="language-mermaid" data-lang="mermaid">flowchart TD
A1[Airflow DAG: 모델 학습 스크립트 실행] --&amp;gt; B1[MLflow 모델 등록 - 버전 선택]
B1 --&amp;gt; C1[모델 Production 승격]
C1 --&amp;gt; D1[FastAPI 서버 재시작]
D1 --&amp;gt; E1[FastAPI → 최신 모델 로드]
E1 --&amp;gt; F1[추론 API 서빙]
subgraph 실험 관리
B1
C1
end
subgraph 추론 서비스
D1
E1
F1
end
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-핵심-구성-요소">🧩 핵심 구성 요소&lt;/h2>
&lt;h3 id="1-airflow-dag---모델-버전-선택">1. Airflow DAG - 모델 버전 선택&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># dags/train_promote_pipeline_share.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow &lt;span style="color:#f92672">import&lt;/span> DAG
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow.operators.bash &lt;span style="color:#f92672">import&lt;/span> BashOperator
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow.models &lt;span style="color:#f92672">import&lt;/span> Variable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datetime &lt;span style="color:#f92672">import&lt;/span> datetime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>default_args &lt;span style="color:#f92672">=&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;start_date&amp;#39;&lt;/span>: datetime(&lt;span style="color:#ae81ff">2023&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> DAG(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dag_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;train_promote_pipeline_share&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> default_args&lt;span style="color:#f92672">=&lt;/span>default_args,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> schedule&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">None&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> catchup&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tags&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;ml&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;train&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>) &lt;span style="color:#66d9ef">as&lt;/span> dag:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># moedel_version 변수 default_var 지정&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model_version &lt;span style="color:#f92672">=&lt;/span> Variable&lt;span style="color:#f92672">.&lt;/span>get(&lt;span style="color:#e6db74">&amp;#34;model_version&amp;#34;&lt;/span>, default_var&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;v1&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> debug_aws &lt;span style="color:#f92672">=&lt;/span> BashOperator(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;debug_aws_credentials&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bash_command&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;echo $HOME &amp;amp;&amp;amp; ls -al $HOME/.aws &amp;amp;&amp;amp; cat $HOME/.aws/credentials&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> env&lt;span style="color:#f92672">=&lt;/span>{&lt;span style="color:#e6db74">&amp;#34;HOME&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/home/airflow&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> run_train_script &lt;span style="color:#f92672">=&lt;/span> BashOperator(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;run_train_script&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># merdel_version 변수화&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bash_command&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#39;python /opt/airflow/dags/repo/ml_code/train_model_&lt;/span>&lt;span style="color:#e6db74">{&lt;/span>model_version&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">.py&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> env&lt;span style="color:#f92672">=&lt;/span>{&lt;span style="color:#e6db74">&amp;#34;HOME&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/home/airflow&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> promote_model &lt;span style="color:#f92672">=&lt;/span> BashOperator(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;promote_model_to_production&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bash_command&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;python /opt/airflow/dags/repo/ml_code/promote_model.py&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> env&lt;span style="color:#f92672">=&lt;/span>{&lt;span style="color:#e6db74">&amp;#34;HOME&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/home/airflow&amp;#34;&lt;/span>},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> debug_aws &lt;span style="color:#f92672">&amp;gt;&amp;gt;&lt;/span> run_train_script &lt;span style="color:#f92672">&amp;gt;&amp;gt;&lt;/span> promote_model
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>→ &lt;code>Airflow UI &amp;gt; Admin &amp;gt; Variables&lt;/code> 에서 &lt;code>model_version = v1&lt;/code> 또는 &lt;code>v2&lt;/code> 설정 가능&lt;/p></description></item><item><title>[MLOps 플랫폼 구축 - 4단계: Airflow : GitSync + 외부 PostgreSQL + Secret 연동]</title><link>https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/04/</link><pubDate>Thu, 03 Jul 2025 17:11:53 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/04/</guid><description>&lt;h2 id="-tldr">✨ TL;DR&lt;/h2>
&lt;ul>
&lt;li>Helm을 통해 Airflow를 배포하면서 DAG 코드를 Git 저장소에서 자동으로 동기화하는 구조 설계&lt;/li>
&lt;li>GitSync, Secret 기반 SSH 인증, 외부 PostgreSQL, AWS S3 연동까지 포함해 구성&lt;/li>
&lt;li>UI 접근은 Ingress를 통해 이루어지며, 로그는 PVC 또는 S3로 설정 가능&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-아키텍처-구성도">📐 아키텍처 구성도&lt;/h2>
&lt;pre tabindex="0">&lt;code class="language-mermaid" data-lang="mermaid">flowchart TD
subgraph K8s_Cluster[&amp;#34;Kubernetes Cluster&amp;#34;]
Scheduler[(Airflow Scheduler Pod)]
Worker[(Airflow Worker Pod)]
Webserver[(Airflow Webserver Pod)]
end
subgraph DAG_Repo[&amp;#34;Git Repository&amp;#34;]
DAG[(airflow-dags.git)]
end
subgraph Secrets[&amp;#34;K8s Secrets + Configs&amp;#34;]
SecretAWS[(aws-credentials-secret)]
SecretDB[(airflow-db-secret)]
end
subgraph External[&amp;#34;External Systems&amp;#34;]
PG[(PostgreSQL: External Metadata DB)]
NFS[(NFS: airflow-logs-pvc)]
end
%% GitSync
DAG --&amp;gt; Scheduler
DAG --&amp;gt; Worker
DAG --&amp;gt; Webserver
%% Secret 주입
SecretAWS --&amp;gt; Scheduler
SecretAWS --&amp;gt; Worker
SecretAWS --&amp;gt; Webserver
SecretDB --&amp;gt; Scheduler
%% 외부 연동
Scheduler --&amp;gt; PG
Scheduler --&amp;gt; NFS
Worker --&amp;gt; NFS
Webserver --&amp;gt; NFS
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-커스텀-airflow-이미지-구성">🐳 커스텀 Airflow 이미지 구성&lt;/h2>
&lt;p>GitSync DAG에서 MLflow 연동 또는 AWS SDK 사용을 위한 Python 패키지 설치 필요&lt;/p></description></item><item><title>[Airflow 기초 자동화 - Airflow → MLflow → FastAPI]</title><link>https://keonhoban.github.io/mlops-journey/projects/mlops_pipeline/basic/</link><pubDate>Fri, 13 Jun 2025 20:58:51 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/projects/mlops_pipeline/basic/</guid><description>&lt;h2 id="-전체-흐름-예시">🧭 전체 흐름 예시&lt;/h2>
&lt;pre tabindex="0">&lt;code>[AIRFLOW DAG 실행]
↓
[train_mlflow.py]
- iris 모델 학습
- 파라미터/메트릭 로깅
- 모델 Registry 등록
↓
[promote_mlflow.py]
- 최신 모델을 Production으로 전환
↓
[FastAPI]
- models:/IrisModel/Production → 실시간 예측
&lt;/code>&lt;/pre>&lt;p>👉 실습 코드는 &lt;a href="https://github.com/keonhoban/mlops-infra-labs/tree/main/airflow_mlflow_fastapi_dockerCompose">🔗 GitHub (Airflow + MLflow + FastAPI)&lt;/a>&lt;/p>
&lt;hr>
&lt;h2 id="-1단계-프로젝트-기본-폴더-구조-설계">✅ [1단계] 프로젝트 기본 폴더 구조 설계&lt;/h2>
&lt;h3 id="-1-전체-디렉토리-구성도">📁 1. 전체 디렉토리 구성도&lt;/h3>
&lt;pre tabindex="0">&lt;code>mlops_project/
├── airflow/ 🛫 Airflow 설정 및 DAG 스케줄러
│ ├── dags/ ← DAG 정의 디렉토리
│ │ └── train_with_mlflow.py ← 학습 DAG (MLflow 연동)
│ ├── Dockerfile.airflow ← Airflow용 Dockerfile
│ ├── requirements.txt ← Airflow 의존성
│ └── .dockerignore
│
├── fastapi/ ⚡ FastAPI 예측 API 서버
│ ├── app/
│ │ └── main.py ← 모델 서빙 엔드포인트
│ ├── Dockerfile.api ← FastAPI용 Dockerfile
│ ├── requirements.txt ← FastAPI 의존성
│ └── .dockerignore
│
├── ml_code/ 🧠 ML 학습 및 프로모션 코드
│ ├── train_mlflow.py ← 모델 학습 및 MLflow 로깅
│ └── promte_mlflow.py ← 모델 프로모션 (Staging → Production)
│
├── mlflow_store/ 🗂️ MLflow 저장소 경로 (볼륨)
│ ├── Dockerfile.mlflow ← MLflow 서버 커스터마이징
│ ├── mlflow.db ← Model Registry DB (sqlite)
│ ├── mlruns/ ← 실험 로그 디렉토리
│ ├── artifacts/ ← 모델 아티팩트 저장소
│ └── .dockerignore
│
├── docker-compose.yaml 🧩 전체 서비스 구성 정의
├── .env 🔐 민감 정보 (.env로 분리)
├── README.md 📝 전체 프로젝트 문서화
├── .gitignore
└── .dockerignore
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-2단계-docker-composeyaml-통합-구성">✅ [2단계] &lt;code>docker-compose.yaml&lt;/code> 통합 구성&lt;/h2>
&lt;h3 id="-구성-목표">🧭 구성 목표&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>서비스명&lt;/th>
&lt;th>설명&lt;/th>
&lt;th>포트&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>airflow&lt;/code>&lt;/td>
&lt;td>DAG 실행 환경 (webserver/scheduler)&lt;/td>
&lt;td>&lt;code>8080&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>postgres&lt;/code>&lt;/td>
&lt;td>Airflow 메타데이터 저장용 DB&lt;/td>
&lt;td>내부 통신&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>mlflow&lt;/code>&lt;/td>
&lt;td>MLflow UI + Registry 기능&lt;/td>
&lt;td>&lt;code>5000&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>fastapi&lt;/code>&lt;/td>
&lt;td>추론 API 서버 (모델 로딩)&lt;/td>
&lt;td>&lt;code>8000&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>이미지 사용시 주의 (UI만 제공하는 이미지 존재)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h3 id="-docker-composeyaml-전체-예시">📄 &lt;code>docker-compose.yaml&lt;/code> 전체 예시&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">version&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;3.8&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">services&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 📦 PostgreSQL: Airflow 메타데이터 저장용 DB&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">postgres&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">image&lt;/span>: &lt;span style="color:#ae81ff">postgres:13&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">container_name&lt;/span>: &lt;span style="color:#ae81ff">postgres&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">env_file&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">.env &lt;/span> &lt;span style="color:#75715e"># ← 민감정보 분리 (아이디/비번)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">environment&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">POSTGRES_USER&lt;/span>: &lt;span style="color:#ae81ff">${POSTGRES_USER}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">POSTGRES_PASSWORD&lt;/span>: &lt;span style="color:#ae81ff">${POSTGRES_PASSWORD}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">POSTGRES_DB&lt;/span>: &lt;span style="color:#ae81ff">${POSTGRES_DB}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>: &lt;span style="color:#75715e"># ← 코드/데이터 공유 및 영속성 보장&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">postgres_data:/var/lib/postgresql/data &lt;/span> &lt;span style="color:#75715e"># ← DB 데이터 유지 (재시작 대비)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 🛫 Airflow: DAG 스케줄러 및 태스크 실행&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">airflow&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">build&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">context&lt;/span>: &lt;span style="color:#ae81ff">./airflow &lt;/span> &lt;span style="color:#75715e"># → Airflow 전용 Dockerfile 경로&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">dockerfile&lt;/span>: &lt;span style="color:#ae81ff">Dockerfile.airflow&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">container_name&lt;/span>: &lt;span style="color:#ae81ff">airflow&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">command&lt;/span>: &lt;span style="color:#ae81ff">standalone &lt;/span> &lt;span style="color:#75715e"># → 로컬 테스트용 간단 실행 명령 &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># (- Scheduler + Webserver + DB 초기화까지 자동으로 한번에 실행)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># (- 실무/운영에서는 airflow-webserver, airflow-scheduler 필드 분리)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;8080:8080&amp;#34;&lt;/span> &lt;span style="color:#75715e"># → Airflow 웹 UI (localhost:8080)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">depends_on&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">postgres &lt;/span> &lt;span style="color:#75715e"># → DB가 먼저 올라와야 Airflow 시작 가능&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">env_file&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">.env&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">environment&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Airflow 메타데이터 DB 연결 주소&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">AIRFLOW__CORE__SQL_ALCHEMY_CONN&lt;/span>: &lt;span style="color:#ae81ff">${AIRFLOW__CORE__SQL_ALCHEMY_CONN}&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># Airflow 예제 DAG 불러올지 여부&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">AIRFLOW__CORE__LOAD_EXAMPLES&lt;/span>: &lt;span style="color:#ae81ff">${AIRFLOW__CORE__LOAD_EXAMPLES} &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">MLFLOW_TRACKING_URI&lt;/span>: &lt;span style="color:#ae81ff">http://mlflow:5000 &lt;/span> &lt;span style="color:#75715e"># → DAG 코드에서 MLflow 연동&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./airflow/dags:/opt/airflow/dags &lt;/span> &lt;span style="color:#75715e"># DAG 파일 mount&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./ml_code:/opt/airflow/ml_code &lt;/span> &lt;span style="color:#75715e"># 학습 코드 공유&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./mlflow_store:/mlflow &lt;/span> &lt;span style="color:#75715e"># 모델 저장소 공유&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 🔬 MLflow: 실험 추적 + 모델 레지스트리 서버&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">mlflow&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">build&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">context&lt;/span>: &lt;span style="color:#ae81ff">./mlflow_store &lt;/span> &lt;span style="color:#75715e"># 커스텀 Dockerfile 위치&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">dockerfile&lt;/span>: &lt;span style="color:#ae81ff">Dockerfile.mlflow&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;5000:5000&amp;#34;&lt;/span> &lt;span style="color:#75715e"># → MLflow UI (localhost:5000)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./mlflow_store:/mlflow &lt;/span> &lt;span style="color:#75715e"># 실험 로그 + DB + artifacts 저장&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">environment&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">MLFLOW_TRACKING_URI=http://0.0.0.0:5000 &lt;/span> &lt;span style="color:#75715e"># 내부 컨테이너 기준 URI&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># ⚡ FastAPI: 모델 서빙 API&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">fastapi&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">build&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">context&lt;/span>: &lt;span style="color:#ae81ff">./fastapi&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">dockerfile&lt;/span>: &lt;span style="color:#ae81ff">Dockerfile.api&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">container_name&lt;/span>: &lt;span style="color:#ae81ff">fastapi&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">ports&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#e6db74">&amp;#34;8000:8000&amp;#34;&lt;/span> &lt;span style="color:#75715e"># → 예측 API 엔드포인트 (localhost:8000)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./fastapi/app:/app/app &lt;/span> &lt;span style="color:#75715e"># FastAPI app 디렉토리 mount&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./ml_code:/app/ml_code &lt;/span> &lt;span style="color:#75715e"># 학습/모델 코드 공유&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#ae81ff">./mlflow_store:/mlflow &lt;/span> &lt;span style="color:#75715e"># 저장된 모델 불러오기 위한 mount&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 🗂️ 볼륨 정의 (Postgres DB 영속성 유지)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">volumes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">postgres_data&lt;/span>:
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="-추가로-해야-할-것">🎁 추가로 해야 할 것&lt;/h2>
&lt;ul>
&lt;li>Airflow 첫 실행 후엔 보통 &lt;strong>관리자 계정 생성&lt;/strong>도 해줘야 함:&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># airflow 컨테이너 접속&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker exec -it airflow bash
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 관리자 계정 생성&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>airflow users create &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --username airflow &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --password airflow &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --firstname Keoho &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --lastname Ban &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --role Admin &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> --email airflow@example.com
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h3 id="-구축-tip-airflow-fastapi-mlflow-간-공유-볼륨-구조-확인">🔁 [구축 Tip] &lt;strong>Airflow, FastAPI, MLflow 간 공유 볼륨 구조 확인&lt;/strong>&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>공유 리소스&lt;/th>
&lt;th>설명&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>./mlflow_store:/mlflow&lt;/code> (MLflow)&lt;/td>
&lt;td>MLflow 서버가 쓰는 로그/모델 저장소&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>./mlflow_store:/mlflow&lt;/code> (Airflow)&lt;/td>
&lt;td>학습 후 모델 저장 위치 공유&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>./mlflow_store:/mlflow&lt;/code> (FastAPI)&lt;/td>
&lt;td>모델 추론 시 로드 경로 공유&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>➡ &lt;strong>경로 통일성&lt;/strong>이 매우 중요함! 지금은 모두 &lt;code>./mlflow&lt;/code>로 공유 (./mlflow 하위에 /mlruns 존재)&lt;/p></description></item><item><title>[Airflow - 5단계: PythonOperator + MLflow Tracking 연동]</title><link>https://keonhoban.github.io/mlops-journey/posts/airflow/05/</link><pubDate>Tue, 10 Jun 2025 19:49:29 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/posts/airflow/05/</guid><description>&lt;blockquote>
&lt;p>목표&lt;/p>
&lt;p>PythonOperator를 사용하여 MLflow로 실험(모델 학습)을 자동화하고, 파라미터, 메트릭, 모델을 기록하는 방법을 학습합니다.&lt;/p>&lt;/blockquote>
&lt;p>👉 실습 코드는 &lt;a href="https://github.com/keonhoban/mlops-infra-labs/tree/main/airflow/05_Airflow_and_MLflow">🔗 GitHub (Mlflow - Tracking + FastAPI)&lt;/a>&lt;/p>
&lt;hr>
&lt;h2 id="-실습-전체-흐름-요약">🧭 실습 전체 흐름 요약&lt;/h2>
&lt;pre tabindex="0">&lt;code>[1단계] MLflow 실험 스크립트 작성
[2단계] Airflow DAG 구성
[3단계] DAG 실행 및 파라미터/메트릭 확인
[4단계] 모델 저장 및 로깅 상태 점검
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-디렉토리-구조">📁 디렉토리 구조&lt;/h2>
&lt;pre tabindex="0">&lt;code>airflow/
├── dags/
│ ├── train_with_mlflow.py ← DAG 파일
├── ml_code/
│ ├── train_mlflow.py ← MLflow 연동 학습 스크립트
└── mlruns/ ← MLflow 로깅 결과 저장 폴더 (자동 생성)
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-1단계-mlflow-학습-스크립트-작성">🧪 1단계: MLflow 학습 스크립트 작성&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># airflow/ml_code/train_mlflow.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> mlflow
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> mlflow.sklearn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> sklearn.datasets &lt;span style="color:#f92672">import&lt;/span> load_iris
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> sklearn.ensemble &lt;span style="color:#f92672">import&lt;/span> RandomForestClassifier
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> sklearn.metrics &lt;span style="color:#f92672">import&lt;/span> accuracy_score
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">run_experiment&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mlflow&lt;span style="color:#f92672">.&lt;/span>set_tracking_uri(&lt;span style="color:#e6db74">&amp;#34;file:/opt/airflow/mlruns&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mlflow&lt;span style="color:#f92672">.&lt;/span>set_experiment(&lt;span style="color:#e6db74">&amp;#34;airflow_mlflow_example&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">with&lt;/span> mlflow&lt;span style="color:#f92672">.&lt;/span>start_run():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 데이터 로딩&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data &lt;span style="color:#f92672">=&lt;/span> load_iris()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> X, y &lt;span style="color:#f92672">=&lt;/span> data&lt;span style="color:#f92672">.&lt;/span>data, data&lt;span style="color:#f92672">.&lt;/span>target
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># 모델 정의&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model &lt;span style="color:#f92672">=&lt;/span> RandomForestClassifier(n_estimators&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">50&lt;/span>, max_depth&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model&lt;span style="color:#f92672">.&lt;/span>fit(X, y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> preds &lt;span style="color:#f92672">=&lt;/span> model&lt;span style="color:#f92672">.&lt;/span>predict(X)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> acc &lt;span style="color:#f92672">=&lt;/span> accuracy_score(y, preds)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># MLflow 기록&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mlflow&lt;span style="color:#f92672">.&lt;/span>log_param(&lt;span style="color:#e6db74">&amp;#34;n_estimators&amp;#34;&lt;/span>, &lt;span style="color:#ae81ff">50&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mlflow&lt;span style="color:#f92672">.&lt;/span>log_param(&lt;span style="color:#e6db74">&amp;#34;max_depth&amp;#34;&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mlflow&lt;span style="color:#f92672">.&lt;/span>log_metric(&lt;span style="color:#e6db74">&amp;#34;accuracy&amp;#34;&lt;/span>, acc)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mlflow&lt;span style="color:#f92672">.&lt;/span>sklearn&lt;span style="color:#f92672">.&lt;/span>log_model(model, &lt;span style="color:#e6db74">&amp;#34;model&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="-2단계-airflow-dag-작성">🧪 2단계: Airflow DAG 작성&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># airflow/dags/train_with_mlflow.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow &lt;span style="color:#f92672">import&lt;/span> DAG
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow.operators.python &lt;span style="color:#f92672">import&lt;/span> PythonOperator
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datetime &lt;span style="color:#f92672">import&lt;/span> datetime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> sys
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sys&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>append(&lt;span style="color:#e6db74">&amp;#34;/opt/airflow/ml_code&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> train_mlflow &lt;span style="color:#f92672">import&lt;/span> run_experiment
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> DAG(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dag_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;mlflow_tracking_dag&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> start_date&lt;span style="color:#f92672">=&lt;/span>datetime(&lt;span style="color:#ae81ff">2023&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> schedule_interval&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">None&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> catchup&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>) &lt;span style="color:#66d9ef">as&lt;/span> dag:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> run_mlflow &lt;span style="color:#f92672">=&lt;/span> PythonOperator(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;run_mlflow_training&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> python_callable&lt;span style="color:#f92672">=&lt;/span>run_experiment,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="-실행-절차">✅ 실행 절차&lt;/h2>
&lt;ol>
&lt;li>&lt;code>train_mlflow.py&lt;/code> 작성&lt;/li>
&lt;li>&lt;code>train_with_mlflow.py&lt;/code> DAG 등록&lt;/li>
&lt;li>Airflow UI에서 DAG 실행&lt;/li>
&lt;li>Task 로그에서 파라미터/메트릭/모델 기록 확인&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="모듈-에러가-발생하면">❓모듈 에러가 발생하면?&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>&lt;code>docker-compose.yaml&lt;/code>에서 &lt;code>volumes:&lt;/code> 항목 확인&lt;/p></description></item><item><title>[Airflow - 4단계: BashOperator로 외부 Python 학습 스크립트 실행]</title><link>https://keonhoban.github.io/mlops-journey/posts/airflow/04/</link><pubDate>Tue, 10 Jun 2025 19:49:27 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/posts/airflow/04/</guid><description>&lt;blockquote>
&lt;p>목표&lt;/p>
&lt;ol>
&lt;li>&lt;code>train.py&lt;/code> 모델 학습 스크립트를 별도 파일로 작성&lt;/li>
&lt;li>Airflow DAG에서 해당 스크립트를 &lt;code>BashOperator&lt;/code>로 실행&lt;/li>
&lt;li>모델 학습 및 결과 확인&lt;/li>
&lt;/ol>&lt;/blockquote>
&lt;p>👉 실습 코드는 &lt;a href="https://github.com/keonhoban/mlops-infra-labs/tree/main/airflow/04_BashOperator_and_Python_ML_Script">🔗 GitHub (Mlflow - Tracking + FastAPI)&lt;/a>&lt;/p>
&lt;hr>
&lt;h2 id="-실습-전체-흐름-요약">🧭 실습 전체 흐름 요약&lt;/h2>
&lt;pre tabindex="0">&lt;code>[1단계] 학습 스크립트 작성
[2단계] BashOperator로 스크립트 실행 DAG 구성
[3단계] Airflow 웹 UI에서 실행 및 로그 확인
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-디렉토리-구조">📁 디렉토리 구조&lt;/h2>
&lt;pre tabindex="0">&lt;code>airflow/
├── dags/
│ └── run_train_script.py ← DAG 파일
├── ml_code/
│ ├── train.py ← 모델 학습 스크립트
│ └── model.pkl ← 학습된 모델 파일
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-1단계-학습-스크립트-작성-trainpy">🧪 [1단계] 학습 스크립트 작성 (&lt;code>train.py&lt;/code>)&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># airflow/ml_code/train.py&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pickle
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> sklearn.datasets &lt;span style="color:#f92672">import&lt;/span> load_iris
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> sklearn.ensemble &lt;span style="color:#f92672">import&lt;/span> RandomForestClassifier
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 데이터 로딩&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data &lt;span style="color:#f92672">=&lt;/span> load_iris()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>X, y &lt;span style="color:#f92672">=&lt;/span> data&lt;span style="color:#f92672">.&lt;/span>data, data&lt;span style="color:#f92672">.&lt;/span>target
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 모델 학습&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model &lt;span style="color:#f92672">=&lt;/span> RandomForestClassifier()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model&lt;span style="color:#f92672">.&lt;/span>fit(X, y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 모델 저장&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>model_path &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;/opt/airflow/ml_code/model.pkl&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> open(model_path, &lt;span style="color:#e6db74">&amp;#34;wb&amp;#34;&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> f:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pickle&lt;span style="color:#f92672">.&lt;/span>dump(model, f)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>모델은 /opt/airflow/ml_code/model.pkl 경로에 저장됩니다.&lt;/p></description></item><item><title>[Airflow - 3단계: ML 파이프라인 DAG 구성]</title><link>https://keonhoban.github.io/mlops-journey/posts/airflow/03/</link><pubDate>Sat, 07 Jun 2025 19:30:16 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/posts/airflow/03/</guid><description>&lt;blockquote>
&lt;p>목표&lt;/p>
&lt;p>ML 워크플로우를 DAG 형태로 구성하여&lt;/p>
&lt;p>데이터 준비 → 모델 학습 → 모델 저장 흐름을 시뮬레이션함&lt;/p>&lt;/blockquote>
&lt;p>👉 실습 코드는 &lt;a href="https://github.com/keonhoban/mlops-infra-labs/tree/main/airflow/03_ML_Pipeline">🔗 GitHub (Mlflow - Tracking + FastAPI)&lt;/a>&lt;/p>
&lt;hr>
&lt;h2 id="-실습-전체-흐름-요약">🧭 실습 전체 흐름 요약&lt;/h2>
&lt;pre tabindex="0">&lt;code>① load_data (가상 데이터 경로 리턴)
② train_model (데이터 경로 받아 학습 흉내)
③ save_model (모델 경로 받아 저장 완료 메시지)
→ XCom을 통해 단계별 결과 전달
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-실습-디렉토리-예시">📁 실습 디렉토리 예시&lt;/h2>
&lt;pre tabindex="0">&lt;code>airflow/
└── dags/
└── ml_simulation.py
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-실습-코드-ml_simulationpy">🧪 실습 코드 (ml_simulation.py)&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow &lt;span style="color:#f92672">import&lt;/span> DAG
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow.operators.python &lt;span style="color:#f92672">import&lt;/span> PythonOperator
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datetime &lt;span style="color:#f92672">import&lt;/span> datetime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">load_data&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;📥 데이터 로딩 완료 (가상)&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> {&lt;span style="color:#e6db74">&amp;#34;data_path&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/tmp/fake_data.csv&amp;#34;&lt;/span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">train_model&lt;/span>(&lt;span style="color:#f92672">**&lt;/span>context):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data &lt;span style="color:#f92672">=&lt;/span> context[&lt;span style="color:#e6db74">&amp;#39;ti&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>xcom_pull(task_ids&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;load_data&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;🧪 데이터 경로: &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>data[&lt;span style="color:#e6db74">&amp;#39;data_path&amp;#39;&lt;/span>]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;🚀 모델 학습 완료 (가상)&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> {&lt;span style="color:#e6db74">&amp;#34;model_path&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/tmp/fake_model.pkl&amp;#34;&lt;/span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">save_model&lt;/span>(&lt;span style="color:#f92672">**&lt;/span>context):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> model &lt;span style="color:#f92672">=&lt;/span> context[&lt;span style="color:#e6db74">&amp;#39;ti&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>xcom_pull(task_ids&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;train_model&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;💾 모델 저장 경로: &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>model[&lt;span style="color:#e6db74">&amp;#39;model_path&amp;#39;&lt;/span>]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">&amp;#34;✅ 저장 완료 (가상)&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> DAG(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dag_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;ml_simulation&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> start_date&lt;span style="color:#f92672">=&lt;/span>datetime(&lt;span style="color:#ae81ff">2023&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> schedule_interval&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">None&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> catchup&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>) &lt;span style="color:#66d9ef">as&lt;/span> dag:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> t1 &lt;span style="color:#f92672">=&lt;/span> PythonOperator(task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;load_data&amp;#39;&lt;/span>, python_callable&lt;span style="color:#f92672">=&lt;/span>load_data)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> t2 &lt;span style="color:#f92672">=&lt;/span> PythonOperator(task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;train_model&amp;#39;&lt;/span>, python_callable&lt;span style="color:#f92672">=&lt;/span>train_model, provide_context&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> t3 &lt;span style="color:#f92672">=&lt;/span> PythonOperator(task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;save_model&amp;#39;&lt;/span>, python_callable&lt;span style="color:#f92672">=&lt;/span>save_model, provide_context&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> t1 &lt;span style="color:#f92672">&amp;gt;&amp;gt;&lt;/span> t2 &lt;span style="color:#f92672">&amp;gt;&amp;gt;&lt;/span> t3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>✅ 저장 경로: dags/ml_simulation.py&lt;/p></description></item><item><title>[Airflow - 2단계: Python &amp; Bash Operator + XCom 데이터 전달]</title><link>https://keonhoban.github.io/mlops-journey/posts/airflow/02/</link><pubDate>Sat, 07 Jun 2025 19:30:15 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/posts/airflow/02/</guid><description>&lt;blockquote>
&lt;p>목표&lt;/p>
&lt;ol>
&lt;li>Python 함수와 Bash 스크립트를 하나의 DAG으로 구성&lt;/li>
&lt;li>XCom을 활용한 Task 간 데이터 전달 체험&lt;/li>
&lt;li>Web UI에서 실행 흐름과 로그 확인&lt;/li>
&lt;/ol>&lt;/blockquote>
&lt;p>👉 실습 코드는 &lt;a href="https://github.com/keonhoban/mlops-infra-labs/tree/main/airflow/02_PythonOperator_and_XCom">🔗 GitHub (Mlflow - Tracking + FastAPI)&lt;/a>&lt;/p>
&lt;hr>
&lt;h2 id="-실습-전체-흐름-요약">🧭 실습 전체 흐름 요약&lt;/h2>
&lt;pre tabindex="0">&lt;code>① DAG 생성: PythonOperator + BashOperator 조합
② XCom으로 태스크 간 메시지 전달
③ 로그로 전달 메시지 확인
④ 전체 DAG 실행 및 의존성 확인
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-dag-파일-구조">📁 DAG 파일 구조&lt;/h2>
&lt;pre tabindex="0">&lt;code>airflow/
├── dags/
│ └── python_bash_xcom.py ← 여기 저장
└── docker-compose.yaml
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-dag-코드-예시">🧱 DAG 코드 예시&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow &lt;span style="color:#f92672">import&lt;/span> DAG
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow.operators.python &lt;span style="color:#f92672">import&lt;/span> PythonOperator
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow.operators.bash &lt;span style="color:#f92672">import&lt;/span> BashOperator
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datetime &lt;span style="color:#f92672">import&lt;/span> datetime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">generate_message&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#e6db74">&amp;#34;🌟 Hello from PythonOperator!&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">print_xcom_message&lt;/span>(&lt;span style="color:#f92672">**&lt;/span>context):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> msg &lt;span style="color:#f92672">=&lt;/span> context[&lt;span style="color:#e6db74">&amp;#39;ti&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>xcom_pull(task_ids&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;generate_task&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> print(&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;📬 XCom received message: &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>msg&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> DAG(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dag_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;python_bash_xcom&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> start_date&lt;span style="color:#f92672">=&lt;/span>datetime(&lt;span style="color:#ae81ff">2023&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> schedule_interval&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">None&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> catchup&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>) &lt;span style="color:#66d9ef">as&lt;/span> dag:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> generate_task &lt;span style="color:#f92672">=&lt;/span> PythonOperator(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;generate_task&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> python_callable&lt;span style="color:#f92672">=&lt;/span>generate_message,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> consume_task &lt;span style="color:#f92672">=&lt;/span> PythonOperator(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;consume_task&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> python_callable&lt;span style="color:#f92672">=&lt;/span>print_xcom_message,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> provide_context&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bash_task &lt;span style="color:#f92672">=&lt;/span> BashOperator(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;bash_echo&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bash_command&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;echo &amp;#39;🎉 Bash task is running!&amp;#39;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> generate_task &lt;span style="color:#f92672">&amp;gt;&amp;gt;&lt;/span> consume_task &lt;span style="color:#f92672">&amp;gt;&amp;gt;&lt;/span> bash_task
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="-실행-방법-요약">🧪 실행 방법 요약&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>docker-compose up -d &lt;span style="color:#75715e"># Airflow 실행 중인지 확인&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol>
&lt;li>브라우저 접속: &lt;a href="http://localhost:8080/">http://localhost:8080&lt;/a>&lt;/li>
&lt;li>DAG 목록 → &lt;code>python_bash_xcom&lt;/code> ON&lt;/li>
&lt;li>▶ 버튼 클릭 → Trigger DAG&lt;/li>
&lt;li>각 Task 클릭 → Log 탭에서 실행 결과 확인&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h2 id="-결과-확인-포인트">📊 결과 확인 포인트&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Task&lt;/th>
&lt;th>로그에서 확인 내용&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>generate_task&lt;/td>
&lt;td>&lt;code>&amp;quot;🌟 Hello from PythonOperator!&amp;quot;&lt;/code> 메시지 리턴&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>consume_task&lt;/td>
&lt;td>&lt;code>📬 XCom received message:&lt;/code> 출력 확인&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>bash_task&lt;/td>
&lt;td>&lt;code>'🎉 Bash task is running!'&lt;/code> 로그 확인&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr>
&lt;h2 id="-실무-팁">🧩 실무 팁&lt;/h2>
&lt;ul>
&lt;li>XCom은 &lt;strong>간단한 문자열/경로/ID 등 소형 데이터&lt;/strong> 전달에 적합&lt;/li>
&lt;li>대용량 결과는 S3/DB에 저장 후 &lt;strong>경로만 XCom으로 전달&lt;/strong>하는 방식 추천&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="-mlops-실전-연결">🔧 MLOps 실전 연결&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>실무 시나리오&lt;/th>
&lt;th>Airflow 사용 방식&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>학습 결과 저장&lt;/td>
&lt;td>&lt;code>train_model&lt;/code> → &lt;code>register_model&lt;/code> 태스크로 XCom 전달&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>태스크 연결 흐름 추적&lt;/td>
&lt;td>Graph View에서 DAG 시각화로 관리&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>후속 작업 자동화&lt;/td>
&lt;td>BashOperator로 배포 스크립트 실행 등 자동화 가능&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>[Airflow - 1단계: 로컬 환경에서 기본 DAG 실행]</title><link>https://keonhoban.github.io/mlops-journey/posts/airflow/01/</link><pubDate>Sat, 07 Jun 2025 19:29:36 +0900</pubDate><guid>https://keonhoban.github.io/mlops-journey/posts/airflow/01/</guid><description>&lt;blockquote>
&lt;p>목표&lt;/p>
&lt;ol>
&lt;li>Docker 기반 Airflow 환경 구성&lt;/li>
&lt;li>DAG 파일을 작성하고 실행&lt;/li>
&lt;li>UI에서 워크플로우 흐름과 로그를 직접 확인&lt;/li>
&lt;/ol>&lt;/blockquote>
&lt;p>👉 실습 코드는 &lt;a href="https://github.com/keonhoban/mlops-infra-labs/tree/main/airflow/01_DAG_basic">🔗 GitHub (Mlflow - Tracking + FastAPI)&lt;/a>&lt;/p>
&lt;hr>
&lt;h2 id="-실습-전체-흐름-요약">🧭 실습 전체 흐름 요약&lt;/h2>
&lt;pre tabindex="0">&lt;code>① Docker 설치 확인
② 공식 Airflow 예제 다운로드
③ docker-compose 실행
④ DAG UI 접속 및 실행
⑤ 로그 확인으로 정상 여부 검증
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-실습-디렉토리-구조">📁 실습 디렉토리 구조&lt;/h2>
&lt;pre tabindex="0">&lt;code>airflow/
├── dags/ # DAG 파일 작성 위치
├── logs/ # 작업 로그 저장
├── plugins/ # 커스텀 플러그인 (선택)
├── docker-compose.yaml
└── .env # AIRFLOW_UID 포함
&lt;/code>&lt;/pre>&lt;hr>
&lt;h2 id="-주요-명령어-정리">🔧 주요 명령어 정리&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Airflow 예제 다운로드&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>git clone https://github.com/apache/airflow.git
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>cd airflow/dev &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> ./docker-compose/setup.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 또는 간단한 버전&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -LfO &lt;span style="color:#e6db74">&amp;#39;https://airflow.apache.org/docs/apache-airflow/2.8.2/docker-compose.yaml&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mkdir -p ./dags ./logs ./plugins
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>echo -e &lt;span style="color:#e6db74">&amp;#34;AIRFLOW_UID=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>id -u&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &amp;gt; .env
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 서비스 실행&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>docker-compose up -d
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># 접속&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>http://localhost:8080 &lt;span style="color:#f92672">(&lt;/span>ID/PW: airflow / airflow&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="-샘플-dag-예시">💡 샘플 DAG 예시&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow &lt;span style="color:#f92672">import&lt;/span> DAG
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> airflow.operators.bash &lt;span style="color:#f92672">import&lt;/span> BashOperator
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> datetime &lt;span style="color:#f92672">import&lt;/span> datetime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">with&lt;/span> DAG(dag_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;hello_airflow&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> start_date&lt;span style="color:#f92672">=&lt;/span>datetime(&lt;span style="color:#ae81ff">2023&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> schedule_interval&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;@daily&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> catchup&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>) &lt;span style="color:#66d9ef">as&lt;/span> dag:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> t1 &lt;span style="color:#f92672">=&lt;/span> BashOperator(task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;print_date&amp;#34;&lt;/span>, bash_command&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;date&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> t2 &lt;span style="color:#f92672">=&lt;/span> BashOperator(task_id&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;say_hello&amp;#34;&lt;/span>, bash_command&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;echo &amp;#39;Hello, Airflow!&amp;#39;&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> t1 &lt;span style="color:#f92672">&amp;gt;&amp;gt;&lt;/span> t2
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>👉 dags/hello_airflow.py 로 저장&lt;/p></description></item></channel></rss>