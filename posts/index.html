<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | 🏔️ MLOps Journey</title>
<meta name=keywords content><meta name=description content="Posts - 🏔️  MLOps Journey"><meta name=author content><link rel=canonical href=https://keonhoban.github.io/mlops-journey/posts/><link crossorigin=anonymous href=/mlops-journey/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=https://keonhoban.github.io/mlops-journey/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://keonhoban.github.io/mlops-journey/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://keonhoban.github.io/mlops-journey/favicon-32x32.png><link rel=apple-touch-icon href=https://keonhoban.github.io/mlops-journey/apple-touch-icon.png><link rel=mask-icon href=https://keonhoban.github.io/mlops-journey/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://keonhoban.github.io/mlops-journey/posts/index.xml><link rel=alternate hreflang=en href=https://keonhoban.github.io/mlops-journey/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://keonhoban.github.io/mlops-journey/posts/"><meta property="og:site_name" content="🏔️  MLOps Journey"><meta property="og:title" content="Posts"><meta property="og:locale" content="ko"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://keonhoban.github.io/mlops-journey/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://keonhoban.github.io/mlops-journey/ accesskey=h title="🏔️  MLOps Journey (Alt + H)">🏔️ MLOps Journey</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://keonhoban.github.io/mlops-journey/ title="🏠 Home"><span>🏠 Home</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/projects/ title="📂 Projects"><span>📂 Projects</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/posts/ title="📝 Blog"><span class=active>📝 Blog</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/about/ title="🧗 About"><span>🧗 About</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/categories/ title="📖 Categories"><span>📖 Categories</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://keonhoban.github.io/mlops-journey/>Home</a></div><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[MLOps 플랫폼 구축 - 6단계: 실시간 모델 핫스왑 구조 실험]</h2></header><div class=entry-content><p>✅ TL;DR Airflow에서 선택한 모델 버전에 따라 학습 스크립트를 다르게 실행 학습된 모델을 MLflow Model Registry에 등록 → Production 단계로 자동 승격 FastAPI 서버는 Production 모델을 다시 로드 → 별도 코드 수정 없이 핫스왑 완료 실무에서 모델 검증/배포 사이클 자동화에 바로 응용 가능 🧠 구조 다이어그램 (핫스왑 흐름) 🧩 핵심 구성 요소 1. Airflow DAG - 모델 버전 선택 # dags/train_promote_pipeline_share.py from airflow import DAG from airflow.operators.bash import BashOperator from airflow.models import Variable from datetime import datetime default_args = { 'start_date': datetime(2023, 1, 1), } with DAG( dag_id='train_promote_pipeline_share', default_args=default_args, schedule=None, catchup=False, tags=["ml", "train"] ) as dag: # moedel_version 변수 default_var 지정 model_version = Variable.get("model_version", default_var="v1") debug_aws = BashOperator( task_id='debug_aws_credentials', bash_command='echo $HOME && ls -al $HOME/.aws && cat $HOME/.aws/credentials', env={"HOME": "/home/airflow"}, ) run_train_script = BashOperator( task_id='run_train_script', # merdel_version 변수화 bash_command=f'python /opt/airflow/dags/repo/ml_code/train_model_{model_version}.py', env={"HOME": "/home/airflow"}, ) promote_model = BashOperator( task_id='promote_model_to_production', bash_command='python /opt/airflow/dags/repo/ml_code/promote_model.py', env={"HOME": "/home/airflow"}, ) debug_aws >> run_train_script >> promote_model → Airflow UI > Admin > Variables 에서 model_version = v1 또는 v2 설정 가능
...</p></div><footer class=entry-footer><span title='2025-07-10 17:12:00 +0900 +0900'>July 10, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [MLOps 플랫폼 구축 - 6단계: 실시간 모델 핫스왑 구조 실험]" href=https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/06/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[MLOps 플랫폼 구축 - 5단계: FastAPI 서빙: MLflow 모델 연동 및 핫스왑 구조 구축]</h2></header><div class=entry-content><p>✨ TL;DR MLflow에서 등록한 모델을 FastAPI 기반 REST API로 서빙합니다. mlflow.pyfunc.load_model()을 통해 Stage별 버전 관리, 핫스왑, 모델 정보 조회가 가능합니다. 쿠버네티스 기반으로 Helm Chart 배포 + AWS 인증 Secret + Ingress 접근까지 연동합니다. 📐 아키텍처 구성도 🐳 FastAPI 커스텀 이미지 📦 Dockerfile FROM python:3.12 WORKDIR /app COPY app /app COPY requirements.txt . RUN pip install --no-cache-dir -r requirements.txt CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"] 📄 requirements.txt fastapi==0.110.2 uvicorn==0.29.0 mlflow==2.13.0 pandas==2.1.4 scikit-learn==1.6.1 pydantic==2.7.1 boto3==1.34.113 numpy==1.26.4 packaging==24.2 psutil==7.0.0 scipy==1.15.3 setuptools==69.5.1 🚀 빌드 & 푸시 docker build -t ghcr.io/hoizz/fastapi-ml:mlflow-model-info . docker push ghcr.io/hoizz/fastapi-ml:mlflow-model-info 🛠️ Helm 배포 구성 🧾 values.yaml replicaCount: 1 image: repository: hoizz/fastapi-ml tag: mlflow-model-info pullPolicy: IfNotPresent service: name: fastapi-service type: ClusterIP port: 80 ingress: enabled: true className: nginx host: fastapi.local annotations: nginx.ingress.kubernetes.io/rewrite-target: / env: MLFLOW_TRACKING_URI: "http://mlflow-service.mlflow.svc.cluster.local:5000" MODEL_NAME: "my_model" MODEL_STAGE: "Production" envFrom: - secretRef: name: aws-credentials-secret 📄 핵심 템플릿 fastapi-deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: fastapi-server namespace: fastapi spec: replicas: 1 selector: matchLabels: app: fastapi template: metadata: labels: app: fastapi spec: containers: - name: fastapi image: {{ .Values.image.repository }}:{{ .Values.image.tag }} ports: - containerPort: 8000 env: - name: MLFLOW_TRACKING_URI value: {{ .Values.env.MLFLOW_TRACKING_URI }} - name: MODEL_NAME value: {{ .Values.env.MODEL_NAME }} - name: MODEL_STAGE value: {{ .Values.env.MODEL_STAGE }} envFrom: - secretRef: name: aws-credentials-secret fastapi-service.yaml apiVersion: v1 kind: Service metadata: name: fastapi-service namespace: fastapi spec: type: {{ .Values.service.type }} selector: app: fastapi ports: - port: {{ .Values.service.port }} targetPort: 8000 fastapi-ingress.yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: fastapi-ingress namespace: fastapi annotations: {{- range $key, $value := .Values.ingress.annotations }} {{ $key }}: {{ $value | quote }} {{- end }} spec: ingressClassName: {{ .Values.ingress.className }} rules: - host: {{ .Values.ingress.host }} http: paths: - path: / pathType: Prefix backend: service: name: fastapi-service port: number: {{ .Values.service.port }} ⏱ 배포 kubectl create namespace fastapi helm install fastapi fastapi-helm -n fastapi # hosts 수정 {node_ip} fastapi.local # 접근 url [http://fastapi.local](http://fastapi.local/) 🧩 Tip 항목 팁 모델 핫스왑 /model-info API 제공 → 운영 시 버전 추적 필수 모델 미존재 load_model 시 MlflowException 발생 → FastAPI가 죽지 않도록 예외 처리 Ingress 설정 /etc/hosts, className, rewrite-target 필수 확인 리소스 할당 배포 시 CPU/RAM 제한 설정으로 예측 지연 방지 🔧 MLOps 실전 연결 항목 실제 의미 FastAPI REST 서빙 실시간 추론 API 운영에 적합 mlflow Stage 사용 운영과 실험 모델 분리 및 핫스왑 가능 boto3 연동 S3 객체 접근, 로그 추적, 리포트 저장 자동화 Helm 기반 배포 팀 내 재사용 가능한 마이크로서비스 패턴 완성 🧭 다음 포스트 예고 🧠 실시간 모델 핫스왑 구조 실험
...</p></div><footer class=entry-footer><span title='2025-07-07 17:11:55 +0900 +0900'>July 7, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [MLOps 플랫폼 구축 - 5단계: FastAPI 서빙: MLflow 모델 연동 및 핫스왑 구조 구축]" href=https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/05/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[MLOps 플랫폼 구축 - 4단계: Airflow : GitSync + 외부 PostgreSQL + Secret 연동]</h2></header><div class=entry-content><p>✨ TL;DR Helm을 통해 Airflow를 배포하면서 DAG 코드를 Git 저장소에서 자동으로 동기화하는 구조 설계 GitSync, Secret 기반 SSH 인증, 외부 PostgreSQL, AWS S3 연동까지 포함해 구성 UI 접근은 Ingress를 통해 이루어지며, 로그는 PVC 또는 S3로 설정 가능 📐 아키텍처 구성도 🐳 커스텀 Airflow 이미지 구성 GitSync DAG에서 MLflow 연동 또는 AWS SDK 사용을 위한 Python 패키지 설치 필요
🔸 Dockerfile FROM apache/airflow:3.0.2-python3.12 COPY requirements.txt /tmp/requirements.txt USER airflow RUN pip install --no-cache-dir -r /tmp/requirements.txt 🔸 requirements.txt mlflow==2.13.0 pandas scikit-learn boto3 🔸 빌드 & 푸시 docker build -t hoizz/airflow-custom:v5-mlflow . docker push hoizz/airflow-custom:v5-mlflow 🛠 Helm 구성 🔹 values.yaml # 실행 엔진 설정 executor: KubernetesExecutor # 이미지 설정 images: airflow: repository: hoizz/airflow-custom # 커스텀 이미지 tag: v5-mlflow-20240712 # 태그 pullPolicy: IfNotPresent # 생성한 fernetKey 고정 (helm delete & install 이후에도 이전 variables 등 데이터 sync 가능) fernetKeySecretName: my-fernet-secret # DAG GitSync 설정 (GitOps 기반) dags: gitSync: enabled: true repo: git@github.com:keonhoban/airflow-dags.git branch: main subPath: dags depth: 1 wait: 10 rev: HEAD sshKeySecret: airflow-git-ssh-secret # DB 연동 (외부 PostgreSQL 사용) postgresql: enabled: false # 내부 Postgres 비활성화 data: metadataSecretName: airflow-db-secret # Secret 안의 base64된 connection 값 참조 # Airflow 환경 설정 config: AIRFLOW__CORE__LOAD_EXAMPLES: value: "False" AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: value: "False" AIRFLOW__WEBSERVER__EXPOSE_CONFIG: value: "True" # 리소스 설정 (권장) scheduler: resources: requests: cpu: "500m" memory: "512Mi" limits: cpu: "1" memory: "1Gi" extraVolumes: - name: aws-credentials secret: secretName: aws-credentials-secret extraVolumeMounts: - name: aws-credentials mountPath: /home/airflow/.aws readOnly: true workers: resources: requests: cpu: "500m" memory: "512Mi" limits: cpu: "1" memory: "1Gi" extraVolumes: - name: aws-credentials secret: secretName: aws-credentials-secret extraVolumeMounts: - name: aws-credentials mountPath: /home/airflow/.aws readOnly: true dagProcessor: extraVolumes: - name: aws-credentials secret: secretName: aws-credentials-secret extraVolumeMounts: - name: aws-credentials mountPath: /home/airflow/.aws readOnly: true # Ingress 설정 (Ingress Controller 기반 접근) ingress: enabled: true apiServer: enabled: true ingressClassName: nginx hosts: - name: airflow.local tls: enabled: false # 실무에서는 true + cert-manager 연동 필요 # Web UI 서비스 타입 설정 apiServer: service: type: ClusterIP # 외부 접근은 Ingress 경유 # 로그 PVC 설정 logs: persistence: enabled: true existingClaim: airflow-logs-pvc # (선택) remote 로그 저장소 설정 (예: S3) # config: # AIRFLOW__LOGGING__REMOTE_LOGGING: "True" # AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER: "s3://your-bucket-name/airflow-logs" # AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID: "aws_default" ✅ fernet_key 생성 및 구성 # 생성 python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())" # secret 적용 (파일 생성 후 kubectl apply 가능) # (git에 필요한 경우 SealedSecret or SOPS or .gitignore) apiVersion: v1 kind: Secret metadata: name: my-fernet-secret namespace: airflow type: Opaque stringData: fernet-key: "xZ69xLVkiCfJQ23fXa8oubANRIJRHZLrIeANlHhPGmQ=" # 생성한 값으로 수정 🔐 GitSync SSH Key & Secret 구성 # SSH 키 생성 ssh-keygen -t rsa -b 4096 -C "testuser@mlops.com" # GitHub UI에서 Deploy Key 등록 (공개키) # K8s Secret 생성 (비공개 키) kubectl create secret generic airflow-git-ssh-secret --from-file=gitSshKey=/root/.ssh/id_rsa -n airflow 🚀 배포 명령어 kubectl create namespace airflow helm install airflow apache-airflow/airflow -n airflow -f values.yaml 🌐 접속 확인 # /etc/hosts 수정 {NodeIP} airflow.local # 브라우저 접속 http://airflow.local 🧪 확인 사항 항목 확인 방법 Airflow UI 접근 http://airflow.local DAG GitSync GitHub push → 자동 반영 여부 확인 PostgreSQL 연결 metadata DB에 연결 로그 확인 AWS 인증 연동 boto3.client() 호출 시 에러 없는지 확인 🧩 Tip GitSync는 depth: 1, wait, rev: HEAD 옵션 설정으로 최적화 필요 metadataSecretName에는 AIRFLOW__DATABASE__SQL_ALCHEMY_CONN이 base64 인코딩되어 있어야 함 각 Pod (scheduler, worker, dagProcessor)마다 AWS credential 마운트 필요 Ingress 접근을 위해선 hosts 파일에 수동 등록 필요 (로컬 클러스터인 경우) 🔧 MLOps 실전 연결 연결 항목 실무 의미 DAG GitSync GitOps 기반으로 실험/운영 동기화 자동화 External PostgreSQL 운영 DB와 통합, 백업/모니터링 가능 boto3 연동 DAG 내 S3 접근 가능 (모델 or raw 데이터 연동) mlflow API 사용 실험 자동화 가능 (training, promotion 포함) 🚨 트러블슈팅 🔻 GitSync DAG 미반영시 체크 리스트 subPath 경로 오류 Secret에 등록된 SSH key 권한 문제 GitHub deploy key에 write 권한 누락 🧭 다음 포스트 예고 ⚙️ FastAPI 서빙 + MLflow 모델 연동
...</p></div><footer class=entry-footer><span title='2025-07-03 17:11:53 +0900 +0900'>July 3, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [MLOps 플랫폼 구축 - 4단계: Airflow : GitSync + 외부 PostgreSQL + Secret 연동]" href=https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/04/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[MLOps 플랫폼 구축 - 3단계: MLflow : PostgreSQL + S3 연동 기반 Helm 구성]</h2></header><div class=entry-content><p>✨ TL;DR MLflow를 도입시 PostgreSQL, S3, 인증 정보 주입, Helm 배포, Ingress 연동 등 설계 MLflow를 Helm으로 배포하면서 고려한 항목(보안, 아티팩트 저장소, UI 접근 등) 구성 커스텀 Docker 이미지로 psycopg2 설치, Helm chart 구성, Secret 연결까지 포함 📐 아키텍처 구성도 (with Secret & 연동 흐름) 🐳 커스텀 MLflow Docker 이미지 제작 공식 MLflow 이미지는 PostgreSQL 드라이버(psycopg2)가 포함되어 있지 않아 오류 발생
🔸 Dockerfile 예시 FROM ghcr.io/mlflow/mlflow:v2.13.0 RUN pip install psycopg2-binary boto3 🔸 빌드 & 푸시 docker build -t ghcr.io/your-id/mlflow:with-psycopg2-and-s3 . docker push ghcr.io/your-id/mlflow:with-psycopg2-and-s3 🛠 Helm Chart 구성 요소 🔹 Chart.yaml apiVersion: v2 name: mlflow description: A Helm chart for deploying MLflow on Kubernetes version: 0.1.0 appVersion: "2.13.0" 🔹 values.yaml 예시 image: repository: hoizz/mlflow tag: with-psycopg2-and-s3 pullPolicy: IfNotPresent env: defaultArtifactRoot: s3://mlflow-artifacts-keonho service: type: ClusterIP port: 5000 ingress: enabled: true className: nginx # ✅ 반드시 명시해야 NGINX가 라우팅함 host: mlflow.local annotations: nginx.ingress.kubernetes.io/rewrite-target: / nginx.ingress.kubernetes.io/proxy-body-size: 10m nginx.ingress.kubernetes.io/ssl-redirect: "false" 📄 Deployment 구성 예시 containers: - name: mlflow image: {{ .Values.image.repository }}:{{ .Values.image.tag }} ports: - containerPort: 5000 command: ["mlflow", "server"] args: - "--backend-store-uri=postgresql://$(DB_USER):$(DB_PASSWORD)@$(DB_HOST):$(DB_PORT)/$(DB_NAME)" - "--default-artifact-root={{ .Values.env.defaultArtifactRoot }}" - "--host=0.0.0.0" - "--port=5000" - "--serve-artifacts" # ✅ 이게 있어야 artifacts UI/REST 지원 가능 env: - name: DB_USER valueFrom: secretKeyRef: name: mlflow-db-secret key: username - name: DB_PASSWORD valueFrom: secretKeyRef: name: mlflow-db-secret key: password - name: DB_HOST valueFrom: configMapKeyRef: name: mlflow-db-config key: host - name: DB_PORT valueFrom: configMapKeyRef: name: mlflow-db-config key: port - name: DB_NAME valueFrom: configMapKeyRef: name: mlflow-db-config key: dbname envFrom: - secretRef: name: aws-credentials-secret 🌐 Ingress 구성 예시 로컬 k8s에 구성할 경우 LB 작동하지 않음 (퍼블릭 IP 없음) # Pod가 노드와 동일한 네트워크 사용하도록 ingress-nginx 커스텀 helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \ --namespace ingress-nginx --create-namespace \ --set controller.hostNetwork=true \ --set controller.dnsPolicy=ClusterFirstWithHostNet \ --set controller.kind=DaemonSet MLlflow ingress 구성 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: mlflow-ingress namespace: mlflow annotations: nginx.ingress.kubernetes.io/rewrite-target: / spec: ingressClassName: nginx rules: - host: mlflow.local http: paths: - path: / pathType: Prefix backend: service: name: mlflow-service port: number: 5000 🚀 배포 명령어 kubectl create namespace mlflow helm install mlflow mlflow-helm/ -n mlflow 🧪 테스트 방법 항목 확인 MLflow UI http://mlflow.local 접근 확인 실험 등록 mlflow.log_param, mlflow.log_metric, log_model() S3 연동 .mlruns 폴더가 S3에 생성되는지 확인 PostgreSQL 연동 실험, run metadata가 DB에 들어가는지 확인 🧩 실무 팁 MLflow 버전과 PostgreSQL 드라이버 호환성 주의 (psycopg2-binary 사용) 모델 URI는 "models:/my_model/Production" 형식으로 사용하면 추후 FastAPI와 연동 용이 Helm chart에서 env vs envFrom 혼용 시 우선순위 주의 🔧 MLOps 실전 연결 연결 항목 실무 의미 PostgreSQL 실험 metadata 저장소. 추적 가능성과 DB 백업 전략 필요 S3 연동 모델/로그 저장소 → 실시간 서빙까지 이어질 핵심 포인트 Helm 구성 운영 시 반복 배포, 버전 관리, GitOps 연동의 핵심 기반 Ingress 조직 내/외부에서 MLflow UI 접근 가능하게 해줌 🚨 트러블슈팅 🔻 TS_01: psycopg2 모듈 없음 → 500 오류 ModuleNotFoundError: No module named 'psycopg2' 해결: 커스텀 Docker 이미지에서 pip install psycopg2-binary 포함
...</p></div><footer class=entry-footer><span title='2025-06-30 17:11:51 +0900 +0900'>June 30, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [MLOps 플랫폼 구축 - 3단계: MLflow : PostgreSQL + S3 연동 기반 Helm 구성]" href=https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/03/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[MLOps 플랫폼 구축 - 2단계: S3 & PostgreSQL 연동을 위한 보안 구성 및 Secret 관리 전략]</h2></header><div class=entry-content><p>✨ TL;DR 외부 리소스(AWS S3, DB 등)와 연결할 때, 인증 정보를 직접 코드나 YAML에 노출하는 건 보안상 위험 Kubernetes에서는 Secret과 ConfigMap, 그리고 envFrom, volumeMount 방식을 조합하여 사용 가능 이번 포스팅에서는 MLflow, Airflow, FastAPI와 AWS S3 & PostgreSQL을 연동할 때 사용한 Secret 구성 전략과 마주친 이슈 및 해결책 공유 🧱 아키텍처 구성도 🔐 왜 Secret 처리가 중요한가? 항목 이유 AWS Access Key 노출 시 데이터 삭제/탈취 위험 있음 PostgreSQL 접속 URI 내부망 DB 구조 노출 + Credential 유출 위험 MLflow Tracking URI 내부 시스템 구조 노출 가능 ✅ 실무에선 반드시 인증정보를 Git에 노출하지 않고, 환경에 안전하게 주입할 수 있어야 함
...</p></div><footer class=entry-footer><span title='2025-06-26 17:11:49 +0900 +0900'>June 26, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [MLOps 플랫폼 구축 - 2단계: S3 & PostgreSQL 연동을 위한 보안 구성 및 Secret 관리 전략]" href=https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/02/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[MLOps 플랫폼 구축 - 1단계: 인프라 설계 및 환경 준비]</h2></header><div class=entry-content><p>✨ TL;DR 단순한 ML 파이프라인 구성을 넘어서, 인프라 설계부터 구축까지 진행 MLflow, Airflow, FastAPI를 로컬 쿠버네티스 위에서 구성, 실무에서 사용 가능한 구조를 직접 설계/구현 이번 포스팅에서는 MLOps 인프라 전체 구조, 그리고 그 기반이 되는 NFS 서버, PostgreSQL, S3 버킷, Kubernetes 클러스터 환경 공유 🧱 아키텍처 구성도 🔧 인프라 설계 개요 구성 요소 설명 Kubernetes 클러스터 로컬 환경 (VMware) 기반. Helm & Ingress 활용 MLflow 서버 외부 PostgreSQL + S3 연동. 모델 등록, 추적, 아티팩트 관리 Airflow 서버 DAG GitSync + S3 연동 + PostgreSQL 외부 DB 사용 FastAPI 서버 MLflow 모델 호출용 예측 API. Ingress로 외부 노출 NFS 서버 Airflow 로그 저장소로 사용. PVC로 연결됨 (S3 가능하지만, pvc 테스트) AWS S3 MLflow 아티팩트 저장소로 활용 PostgreSQL MLflow & Airflow의 metadata 저장소. 외부 VM에서 호스팅됨 📂 NFS 서버 구성 ✅ 설치 & 공유 디렉토리 생성 (Ubuntu 기준) sudo apt update sudo apt install -y nfs-kernel-server sudo mkdir -p /mnt/nfs_share/mlops/airflow/logs sudo chown -R 50000:root /mnt/nfs_share/mlops/airflow # 사용할 유저 UID, GID 확인 필요 sudo chmod -R 775 /mnt/nfs_share/mlops/airflow 📄 /etc/exports 설정 # 마운트 수가 적은 경우 (프로덕션 환경 적용시 root_squash 권장) /mnt/nfs_share/mlops/airflow/logs 192.168.18.0/24(rw,sync,no_subtree_check,root_squash) # 마운트 수가 많은 경우 (필요시) /mnt/nfs_share/mlops 192.168.18.0/24(rw,sync,no_subtree_check,root_squash) # 적용 sudo exportfs -rav sudo systemctl restart nfs-kernel-server 📄 PV&amp;PVC 설정
...</p></div><footer class=entry-footer><span title='2025-06-23 17:11:47 +0900 +0900'>June 23, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [MLOps 플랫폼 구축 - 1단계: 인프라 설계 및 환경 준비]" href=https://keonhoban.github.io/mlops-journey/posts/mlops-pipeline-helm/01/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[TS] Airflow 기초 자동화 - Airflow → MLflow → FastAPI</h2></header><div class=entry-content><p>Airflow + MLflow 연동 실습 중 발생한 실전 에러 정리
발생 원인 분석 + 즉시 적용 가능한 해결 방법까지 포함
🧩 배경 Airflow DAG 내부에서 mlflow.sklearn.log_model() 호출 실험 자동 등록 및 Model Registry 연동 시도 🔥 에러 1. PermissionError: [Errno 13] Permission denied: ‘/mlflow’ 🧠 원인 분석 증상 원인 /mlflow 경로 접근 실패 Airflow 컨테이너에 mount되지 않음 mlruns 쓰기 실패 공유 볼륨 누락 → 쓰기 권한 없음 실험 생성 실패 artifact 저장소 지정 실패 ✅ 해결 방법 Airflow 컨테이너에 공유 볼륨 추가 volumes: - ./mlflow:/mlflow - ./mlruns:/mlflow/mlruns 초기 실험 수동 생성 스크립트 실행 # init_experiments.py from mlflow.tracking import MlflowClient mlflow.set_tracking_uri("http://localhost:5000") client = MlflowClient() if not client.get_experiment_by_name("Iris_Model_Registry_Go"): client.create_experiment( name="Iris_Model_Registry_Go", artifact_location="file:///mlflow/mlruns/Iris_Model_Registry_Go" ) docker exec -it airflow_mlflow_1 python3 /mlflow/init_experiments.py Airflow DAG 내에서 동일한 이름 지정 mlflow.set_experiment("Iris_Model_Registry_Go") 💥 에러 2. 404 Not Found on /api/2.0/mlflow/logged-models 🧠 원인 분석 핵심 문제 상세 설명 Model Registry API 미탑재 mlflow ui 또는 mlflow server의 옵션 누락 /logged-models 경로 없음 기본 실행 시에는 Registry 관련 API가 비활성화 ✅ 해결 방법 정상 작동 조건: 실행 방식 Registry API mlflow ui ❌ 없음 mlflow server ⚠️ 일부 없음 mlflow server --serve-artifacts ✅ 모두 활성화 mlflow[extras] 패키지 ✅ 커스텀 이미지 사용 필요 📌 Dockerfile.mlflow 예시 (커스텀 구성)
...</p></div><footer class=entry-footer><span title='2025-06-13 21:06:20 +0900 +0900'>June 13, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [TS] Airflow 기초 자동화 - Airflow → MLflow → FastAPI" href=https://keonhoban.github.io/mlops-journey/posts/troubleshoot/01/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 5단계: PythonOperator + MLflow Tracking 연동]</h2></header><div class=entry-content><p>목표
PythonOperator를 사용하여 MLflow로 실험(모델 학습)을 자동화하고, 파라미터, 메트릭, 모델을 기록하는 방법을 학습합니다.
👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 [1단계] MLflow 실험 스크립트 작성 [2단계] Airflow DAG 구성 [3단계] DAG 실행 및 파라미터/메트릭 확인 [4단계] 모델 저장 및 로깅 상태 점검 📁 디렉토리 구조 airflow/ ├── dags/ │ ├── train_with_mlflow.py ← DAG 파일 ├── ml_code/ │ ├── train_mlflow.py ← MLflow 연동 학습 스크립트 └── mlruns/ ← MLflow 로깅 결과 저장 폴더 (자동 생성) 🧪 1단계: MLflow 학습 스크립트 작성 # airflow/ml_code/train_mlflow.py import mlflow import mlflow.sklearn from sklearn.datasets import load_iris from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score def run_experiment(): mlflow.set_tracking_uri("file:/opt/airflow/mlruns") mlflow.set_experiment("airflow_mlflow_example") with mlflow.start_run(): # 데이터 로딩 data = load_iris() X, y = data.data, data.target # 모델 정의 model = RandomForestClassifier(n_estimators=50, max_depth=3) model.fit(X, y) preds = model.predict(X) acc = accuracy_score(y, preds) # MLflow 기록 mlflow.log_param("n_estimators", 50) mlflow.log_param("max_depth", 3) mlflow.log_metric("accuracy", acc) mlflow.sklearn.log_model(model, "model") 🧪 2단계: Airflow DAG 작성 # airflow/dags/train_with_mlflow.py from airflow import DAG from airflow.operators.python import PythonOperator from datetime import datetime import sys sys.path.append("/opt/airflow/ml_code") from train_mlflow import run_experiment with DAG( dag_id='mlflow_tracking_dag', start_date=datetime(2023, 1, 1), schedule_interval=None, catchup=False, ) as dag: run_mlflow = PythonOperator( task_id='run_mlflow_training', python_callable=run_experiment, ) ✅ 실행 절차 train_mlflow.py 작성 train_with_mlflow.py DAG 등록 Airflow UI에서 DAG 실행 Task 로그에서 파라미터/메트릭/모델 기록 확인 ❓모듈 에러가 발생하면? docker-compose.yaml에서 volumes: 항목 확인
...</p></div><footer class=entry-footer><span title='2025-06-10 19:49:29 +0900 +0900'>June 10, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 5단계: PythonOperator + MLflow Tracking 연동]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/05/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 4단계: BashOperator로 외부 Python 학습 스크립트 실행]</h2></header><div class=entry-content><p>목표
train.py 모델 학습 스크립트를 별도 파일로 작성 Airflow DAG에서 해당 스크립트를 BashOperator로 실행 모델 학습 및 결과 확인 👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 [1단계] 학습 스크립트 작성 [2단계] BashOperator로 스크립트 실행 DAG 구성 [3단계] Airflow 웹 UI에서 실행 및 로그 확인 📁 디렉토리 구조 airflow/ ├── dags/ │ └── run_train_script.py ← DAG 파일 ├── ml_code/ │ ├── train.py ← 모델 학습 스크립트 │ └── model.pkl ← 학습된 모델 파일 🧪 [1단계] 학습 스크립트 작성 (train.py) # airflow/ml_code/train.py import pickle from sklearn.datasets import load_iris from sklearn.ensemble import RandomForestClassifier # 데이터 로딩 data = load_iris() X, y = data.data, data.target # 모델 학습 model = RandomForestClassifier() model.fit(X, y) # 모델 저장 model_path = "/opt/airflow/ml_code/model.pkl" with open(model_path, "wb") as f: pickle.dump(model, f) 모델은 /opt/airflow/ml_code/model.pkl 경로에 저장됩니다.
...</p></div><footer class=entry-footer><span title='2025-06-10 19:49:27 +0900 +0900'>June 10, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 4단계: BashOperator로 외부 Python 학습 스크립트 실행]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/04/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 3단계: ML 파이프라인 DAG 구성]</h2></header><div class=entry-content><p>목표
ML 워크플로우를 DAG 형태로 구성하여
데이터 준비 → 모델 학습 → 모델 저장 흐름을 시뮬레이션함
👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 ① load_data (가상 데이터 경로 리턴) ② train_model (데이터 경로 받아 학습 흉내) ③ save_model (모델 경로 받아 저장 완료 메시지) → XCom을 통해 단계별 결과 전달 📁 실습 디렉토리 예시 airflow/ └── dags/ └── ml_simulation.py 🧪 실습 코드 (ml_simulation.py) from airflow import DAG from airflow.operators.python import PythonOperator from datetime import datetime def load_data(): print("📥 데이터 로딩 완료 (가상)") return {"data_path": "/tmp/fake_data.csv"} def train_model(**context): data = context['ti'].xcom_pull(task_ids='load_data') print(f"🧪 데이터 경로: {data['data_path']}") print("🚀 모델 학습 완료 (가상)") return {"model_path": "/tmp/fake_model.pkl"} def save_model(**context): model = context['ti'].xcom_pull(task_ids='train_model') print(f"💾 모델 저장 경로: {model['model_path']}") print("✅ 저장 완료 (가상)") with DAG( dag_id='ml_simulation', start_date=datetime(2023, 1, 1), schedule_interval=None, catchup=False ) as dag: t1 = PythonOperator(task_id='load_data', python_callable=load_data) t2 = PythonOperator(task_id='train_model', python_callable=train_model, provide_context=True) t3 = PythonOperator(task_id='save_model', python_callable=save_model, provide_context=True) t1 >> t2 >> t3 ✅ 저장 경로: dags/ml_simulation.py
...</p></div><footer class=entry-footer><span title='2025-06-07 19:30:16 +0900 +0900'>June 7, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 3단계: ML 파이프라인 DAG 구성]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/03/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://keonhoban.github.io/mlops-journey/posts/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><p style=margin-top:1rem>© 2025 Keonho Ban | <a href=https://github.com/keonhoban target=_blank>GitHub</a> | <a href=mailto:keonho0510@naver.com>Email</a></p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>