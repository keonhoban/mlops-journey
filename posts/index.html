<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | 🏔️ MLOps Journey</title>
<meta name=keywords content><meta name=description content="Posts - 🏔️  MLOps Journey"><meta name=author content><link rel=canonical href=https://keonhoban.github.io/mlops-journey/posts/><link crossorigin=anonymous href=/mlops-journey/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=https://keonhoban.github.io/mlops-journey/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://keonhoban.github.io/mlops-journey/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://keonhoban.github.io/mlops-journey/favicon-32x32.png><link rel=apple-touch-icon href=https://keonhoban.github.io/mlops-journey/apple-touch-icon.png><link rel=mask-icon href=https://keonhoban.github.io/mlops-journey/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://keonhoban.github.io/mlops-journey/posts/index.xml><link rel=alternate hreflang=en href=https://keonhoban.github.io/mlops-journey/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://keonhoban.github.io/mlops-journey/posts/"><meta property="og:site_name" content="🏔️  MLOps Journey"><meta property="og:title" content="Posts"><meta property="og:locale" content="ko"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://keonhoban.github.io/mlops-journey/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://keonhoban.github.io/mlops-journey/ accesskey=h title="🏔️  MLOps Journey (Alt + H)">🏔️ MLOps Journey</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://keonhoban.github.io/mlops-journey/ title="🏠 Home"><span>🏠 Home</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/projects/ title="📂 Projects"><span>📂 Projects</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/posts/ title="📝 Blog"><span class=active>📝 Blog</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/about/ title="🧗 About"><span>🧗 About</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/categories/ title="📖 Categories"><span>📖 Categories</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://keonhoban.github.io/mlops-journey/>Home</a></div><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[TS] Airflow 기초 자동화 - Airflow → MLflow → FastAPI</h2></header><div class=entry-content><p>Airflow + MLflow 연동 실습 중 발생한 실전 에러 3종 정리
발생 원인 분석 + 즉시 적용 가능한 해결 방법까지 포함
🧩 배경 Airflow DAG 내부에서 mlflow.sklearn.log_model() 호출 실험 자동 등록 및 Model Registry 연동 시도 ✅ 결과적으로 3가지 에러 순차 발생 🔥 에러 1. PermissionError: [Errno 13] Permission denied: '/mlflow' 🧠 원인 분석 증상 원인 /mlflow 경로 접근 실패 Airflow 컨테이너에 mount되지 않음 mlruns 쓰기 실패 공유 볼륨 누락 → 쓰기 권한 없음 실험 생성 실패 artifact 저장소 지정 실패 ✅ 해결 방법 Airflow 컨테이너에 공유 볼륨 추가 volumes: - ./mlflow:/mlflow - ./mlruns:/mlflow/mlruns 초기 실험 수동 생성 스크립트 실행 # init_experiments.py from mlflow.tracking import MlflowClient mlflow.set_tracking_uri("http://localhost:5000") client = MlflowClient() if not client.get_experiment_by_name("Iris_Model_Registry_Go"): client.create_experiment( name="Iris_Model_Registry_Go", artifact_location="file:///mlflow/mlruns/Iris_Model_Registry_Go" ) docker exec -it airflow_mlflow_1 python3 /mlflow/init_experiments.py Airflow DAG 내에서 동일한 이름 지정 mlflow.set_experiment("Iris_Model_Registry_Go") 💥 에러 2. 404 Not Found on /api/2.0/mlflow/logged-models 🧠 원인 분석 핵심 문제 상세 설명 Model Registry API 미탑재 mlflow ui 또는 mlflow server의 옵션 누락 /logged-models 경로 없음 기본 실행 시에는 Registry 관련 API가 비활성화 ✅ 해결 방법 정상 작동 조건: 실행 방식 Registry API mlflow ui ❌ 없음 mlflow server ⚠️ 일부 없음 mlflow server --serve-artifacts ✅ 모두 활성화 mlflow[extras] 패키지 ✅ 커스텀 이미지 사용 필요 📌 Dockerfile.mlflow 예시 (커스텀 구성)
...</p></div><footer class=entry-footer><span title='2025-06-13 21:06:20 +0900 +0900'>June 13, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [TS] Airflow 기초 자동화 - Airflow → MLflow → FastAPI" href=https://keonhoban.github.io/mlops-journey/posts/troubleshoot/01/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 5단계: PythonOperator + MLflow Tracking 연동]</h2></header><div class=entry-content><p>목표
PythonOperator를 사용하여 MLflow로 실험(모델 학습)을 자동화하고, 파라미터, 메트릭, 모델을 기록하는 방법을 학습합니다.
👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 [1단계] MLflow 실험 스크립트 작성 [2단계] Airflow DAG 구성 [3단계] DAG 실행 및 파라미터/메트릭 확인 [4단계] 모델 저장 및 로깅 상태 점검 📁 디렉토리 구조 airflow/ ├── dags/ │ ├── train_with_mlflow.py ← DAG 파일 ├── ml_code/ │ ├── train_mlflow.py ← MLflow 연동 학습 스크립트 └── mlruns/ ← MLflow 로깅 결과 저장 폴더 (자동 생성) 🧪 1단계: MLflow 학습 스크립트 작성 # airflow/ml_code/train_mlflow.py import mlflow import mlflow.sklearn from sklearn.datasets import load_iris from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score def run_experiment(): mlflow.set_tracking_uri("file:/opt/airflow/mlruns") mlflow.set_experiment("airflow_mlflow_example") with mlflow.start_run(): # 데이터 로딩 data = load_iris() X, y = data.data, data.target # 모델 정의 model = RandomForestClassifier(n_estimators=50, max_depth=3) model.fit(X, y) preds = model.predict(X) acc = accuracy_score(y, preds) # MLflow 기록 mlflow.log_param("n_estimators", 50) mlflow.log_param("max_depth", 3) mlflow.log_metric("accuracy", acc) mlflow.sklearn.log_model(model, "model") 🧪 2단계: Airflow DAG 작성 # airflow/dags/train_with_mlflow.py from airflow import DAG from airflow.operators.python import PythonOperator from datetime import datetime import sys sys.path.append("/opt/airflow/ml_code") from train_mlflow import run_experiment with DAG( dag_id='mlflow_tracking_dag', start_date=datetime(2023, 1, 1), schedule_interval=None, catchup=False, ) as dag: run_mlflow = PythonOperator( task_id='run_mlflow_training', python_callable=run_experiment, ) ✅ 실행 절차 train_mlflow.py 작성 train_with_mlflow.py DAG 등록 Airflow UI에서 DAG 실행 Task 로그에서 파라미터/메트릭/모델 기록 확인 ❓모듈 에러가 발생하면? docker-compose.yaml에서 volumes: 항목 확인
...</p></div><footer class=entry-footer><span title='2025-06-10 19:49:29 +0900 +0900'>June 10, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 5단계: PythonOperator + MLflow Tracking 연동]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/05/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 4단계: BashOperator로 외부 Python 학습 스크립트 실행]</h2></header><div class=entry-content><p>목표
train.py 모델 학습 스크립트를 별도 파일로 작성 Airflow DAG에서 해당 스크립트를 BashOperator로 실행 모델 학습 및 결과 확인 👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 [1단계] 학습 스크립트 작성 [2단계] BashOperator로 스크립트 실행 DAG 구성 [3단계] Airflow 웹 UI에서 실행 및 로그 확인 📁 디렉토리 구조 airflow/ ├── dags/ │ └── run_train_script.py ← DAG 파일 ├── ml_code/ │ ├── train.py ← 모델 학습 스크립트 │ └── model.pkl ← 학습된 모델 파일 🧪 [1단계] 학습 스크립트 작성 (train.py) # airflow/ml_code/train.py import pickle from sklearn.datasets import load_iris from sklearn.ensemble import RandomForestClassifier # 데이터 로딩 data = load_iris() X, y = data.data, data.target # 모델 학습 model = RandomForestClassifier() model.fit(X, y) # 모델 저장 model_path = "/opt/airflow/ml_code/model.pkl" with open(model_path, "wb") as f: pickle.dump(model, f) 모델은 /opt/airflow/ml_code/model.pkl 경로에 저장됩니다.
...</p></div><footer class=entry-footer><span title='2025-06-10 19:49:27 +0900 +0900'>June 10, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 4단계: BashOperator로 외부 Python 학습 스크립트 실행]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/04/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 3단계: ML 파이프라인 DAG 구성]</h2></header><div class=entry-content><p>목표
ML 워크플로우를 DAG 형태로 구성하여
데이터 준비 → 모델 학습 → 모델 저장 흐름을 시뮬레이션함
👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 ① load_data (가상 데이터 경로 리턴) ② train_model (데이터 경로 받아 학습 흉내) ③ save_model (모델 경로 받아 저장 완료 메시지) → XCom을 통해 단계별 결과 전달 📁 실습 디렉토리 예시 airflow/ └── dags/ └── ml_simulation.py 🧪 실습 코드 (ml_simulation.py) from airflow import DAG from airflow.operators.python import PythonOperator from datetime import datetime def load_data(): print("📥 데이터 로딩 완료 (가상)") return {"data_path": "/tmp/fake_data.csv"} def train_model(**context): data = context['ti'].xcom_pull(task_ids='load_data') print(f"🧪 데이터 경로: {data['data_path']}") print("🚀 모델 학습 완료 (가상)") return {"model_path": "/tmp/fake_model.pkl"} def save_model(**context): model = context['ti'].xcom_pull(task_ids='train_model') print(f"💾 모델 저장 경로: {model['model_path']}") print("✅ 저장 완료 (가상)") with DAG( dag_id='ml_simulation', start_date=datetime(2023, 1, 1), schedule_interval=None, catchup=False ) as dag: t1 = PythonOperator(task_id='load_data', python_callable=load_data) t2 = PythonOperator(task_id='train_model', python_callable=train_model, provide_context=True) t3 = PythonOperator(task_id='save_model', python_callable=save_model, provide_context=True) t1 >> t2 >> t3 ✅ 저장 경로: dags/ml_simulation.py
...</p></div><footer class=entry-footer><span title='2025-06-07 19:30:16 +0900 +0900'>June 7, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 3단계: ML 파이프라인 DAG 구성]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/03/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 2단계: Python & Bash Operator + XCom 데이터 전달]</h2></header><div class=entry-content><p>목표
Python 함수와 Bash 스크립트를 하나의 DAG으로 구성 XCom을 활용한 Task 간 데이터 전달 체험 Web UI에서 실행 흐름과 로그 확인 👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 ① DAG 생성: PythonOperator + BashOperator 조합 ② XCom으로 태스크 간 메시지 전달 ③ 로그로 전달 메시지 확인 ④ 전체 DAG 실행 및 의존성 확인 📁 DAG 파일 구조 airflow/ ├── dags/ │ └── python_bash_xcom.py ← 여기 저장 └── docker-compose.yaml 🧱 DAG 코드 예시 from airflow import DAG from airflow.operators.python import PythonOperator from airflow.operators.bash import BashOperator from datetime import datetime def generate_message(): return "🌟 Hello from PythonOperator!" def print_xcom_message(**context): msg = context['ti'].xcom_pull(task_ids='generate_task') print(f"📬 XCom received message: {msg}") with DAG( dag_id='python_bash_xcom', start_date=datetime(2023, 1, 1), schedule_interval=None, catchup=False, ) as dag: generate_task = PythonOperator( task_id='generate_task', python_callable=generate_message, ) consume_task = PythonOperator( task_id='consume_task', python_callable=print_xcom_message, provide_context=True, ) bash_task = BashOperator( task_id='bash_echo', bash_command="echo '🎉 Bash task is running!'" ) generate_task >> consume_task >> bash_task 🧪 실행 방법 요약 docker-compose up -d # Airflow 실행 중인지 확인 브라우저 접속: http://localhost:8080 DAG 목록 → python_bash_xcom ON ▶ 버튼 클릭 → Trigger DAG 각 Task 클릭 → Log 탭에서 실행 결과 확인 📊 결과 확인 포인트 Task 로그에서 확인 내용 generate_task "🌟 Hello from PythonOperator!" 메시지 리턴 consume_task 📬 XCom received message: 출력 확인 bash_task '🎉 Bash task is running!' 로그 확인 🧩 실무 팁 XCom은 간단한 문자열/경로/ID 등 소형 데이터 전달에 적합 대용량 결과는 S3/DB에 저장 후 경로만 XCom으로 전달하는 방식 추천 🔧 MLOps 실전 연결 실무 시나리오 Airflow 사용 방식 학습 결과 저장 train_model → register_model 태스크로 XCom 전달 태스크 연결 흐름 추적 Graph View에서 DAG 시각화로 관리 후속 작업 자동화 BashOperator로 배포 스크립트 실행 등 자동화 가능</p></div><footer class=entry-footer><span title='2025-06-07 19:30:15 +0900 +0900'>June 7, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 2단계: Python & Bash Operator &#43; XCom 데이터 전달]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/02/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Airflow - 1단계: 로컬 환경에서 기본 DAG 실행]</h2></header><div class=entry-content><p>목표
Docker 기반 Airflow 환경 구성 DAG 파일을 작성하고 실행 UI에서 워크플로우 흐름과 로그를 직접 확인 👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 ① Docker 설치 확인 ② 공식 Airflow 예제 다운로드 ③ docker-compose 실행 ④ DAG UI 접속 및 실행 ⑤ 로그 확인으로 정상 여부 검증 📁 실습 디렉토리 구조 airflow/ ├── dags/ # DAG 파일 작성 위치 ├── logs/ # 작업 로그 저장 ├── plugins/ # 커스텀 플러그인 (선택) ├── docker-compose.yaml └── .env # AIRFLOW_UID 포함 🔧 주요 명령어 정리 # Airflow 예제 다운로드 git clone https://github.com/apache/airflow.git cd airflow/dev && ./docker-compose/setup.sh # 또는 간단한 버전 curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.8.2/docker-compose.yaml' mkdir -p ./dags ./logs ./plugins echo -e "AIRFLOW_UID=$(id -u)" > .env # 서비스 실행 docker-compose up -d # 접속 http://localhost:8080 (ID/PW: airflow / airflow) 💡 샘플 DAG 예시 from airflow import DAG from airflow.operators.bash import BashOperator from datetime import datetime with DAG(dag_id="hello_airflow", start_date=datetime(2023, 1, 1), schedule_interval="@daily", catchup=False) as dag: t1 = BashOperator(task_id="print_date", bash_command="date") t2 = BashOperator(task_id="say_hello", bash_command="echo 'Hello, Airflow!'") t1 >> t2 👉 dags/hello_airflow.py 로 저장
...</p></div><footer class=entry-footer><span title='2025-06-07 19:29:36 +0900 +0900'>June 7, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Airflow - 1단계: 로컬 환경에서 기본 DAG 실행]" href=https://keonhoban.github.io/mlops-journey/posts/airflow/01/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Kubernetes - 5단계: Prometheus + Grafana 모니터링]</h2></header><div class=entry-content><p>목표
쿠버네티스 클러스터 내 자원(Pod, Node 등) 실시간 모니터링 Prometheus로 메트릭 수집 → Grafana 대시보드 시각화 실무 MLOps 환경에서 모니터링 아키텍처 구축 기반 다지기 👉 실습 코드: 🔗 GitHub (Monitoring)
🧭 전체 흐름 요약 ① Helm 저장소 추가 ② Prometheus 설치 (메트릭 수집) ③ Grafana 설치 (대시보드 시각화) ④ Web UI 접속 → Prometheus 연결 → 대시보드 불러오기 📂 디렉토리 구성 k8s-monitoring/ ├── values-prometheus.yaml # Prometheus 커스터마이징 설정 ├── values-grafana.yaml # Grafana 설정 + 비밀번호 지정 ├── README.md ⚙️ [1단계] Helm 저장소 추가 helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo add grafana https://grafana.github.io/helm-charts helm repo update 📦 [2단계] Prometheus 설치 🔹 기본 설치 helm install prometheus prometheus-community/prometheus kubectl port-forward svc/prometheus-server 9090:80 접속: http://localhost:9090
...</p></div><footer class=entry-footer><span title='2025-06-05 20:06:43 +0900 +0900'>June 5, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Kubernetes - 5단계: Prometheus + Grafana 모니터링]" href=https://keonhoban.github.io/mlops-journey/posts/kubernetes/05/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Kubernetes - 4단계: Helm]</h2></header><div class=entry-content><p>목표
Helm CLI 설치 및 Chart 개념 이해 Nginx를 Helm으로 배포 & 기존 YAML 방식과 차이 체감 values.yaml로 설정을 바꾸고 재배포하는 방법 익히기 👉 실습 코드는 🔗 GitHub (Helm)
🧭 전체 흐름 요약 ① Helm 설치 및 Chart 저장소 등록 ② bitnami/nginx Chart 검색 → 설치 ③ 기본 설치 결과 확인 (LoadBalancer → Pending) ④ values.yaml로 NodePort 설정 변경 ⑤ 설정 적용하여 재설치 + 포트 접속 확인 📁 실습 디렉토리 구성 k8s-helm/ ├── values-nginx.yaml # 커스터마이징용 설정 파일 └── README.md ⚙️ [1단계] Helm 설치 🔧 Ubuntu 설치 명령어 curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash helm version 📦 [2단계] Chart 저장소 등록 & 검색 helm repo add bitnami https://charts.bitnami.com/bitnami helm repo update helm search repo nginx helm search repo는 Chart 목록을 검색하는 명령어
...</p></div><footer class=entry-footer><span title='2025-06-05 20:06:41 +0900 +0900'>June 5, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Kubernetes - 4단계: Helm]" href=https://keonhoban.github.io/mlops-journey/posts/kubernetes/04/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Kubernetes - 3단계 : Ingress & Nginx Controller]</h2></header><div class=entry-content><p>목표
여러 서비스를 도메인 또는 경로 기반으로 라우팅 Cluster 외부에서 서비스를 http://foo.local 형식으로 접근 실무에서 가장 많이 쓰는 Ingress 구조(Nginx Ingress Controller) 익히기 👉 실습 코드는 🔗 GitHub (Ingress_and_Nginx_Controller)
🧭 전체 흐름 요약 ① Ingress Controller 설치 (minikube addons 사용) ② nginx / httpd 서비스 배포 ③ Ingress 리소스로 경로 라우팅 설정 ④ /etc/hosts 수정 → curl 테스트로 확인 📦 실습 디렉토리 구조 k8s-ingress/ ├── deploy-nginx.yaml # nginx 배포 + 서비스 ├── deploy-httpd.yaml # httpd 배포 + 서비스 ├── ingress.yaml # Ingress 라우팅 정의 └── README.md ⚙️ [1단계] Ingress Controller 설치 minikube addons enable ingress kubectl get pods -n ingress-nginx ingress-nginx-controller Pod가 Running 상태면 설치 성공 NodePort 기본 포트: 80, 443 🧱 [2단계] 서비스 2개 배포 (nginx / httpd) 🔹 deploy-nginx.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: name: nginx-service spec: selector: app: nginx ports: - port: 80 targetPort: 80 🔹 deploy-httpd.yaml apiVersion: apps/v1 kind: Deployment metadata: name: httpd-deployment spec: replicas: 1 selector: matchLabels: app: httpd template: metadata: labels: app: httpd spec: containers: - name: httpd image: httpd ports: - containerPort: 80 --- apiVersion: v1 kind: Service metadata: name: httpd-service spec: selector: app: httpd ports: - port: 80 targetPort: 80 🗺️ [3단계] Ingress 라우팅 설정 🔹 ingress.yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: example-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: / spec: rules: - host: foo.local http: paths: - path: /nginx pathType: Prefix backend: service: name: nginx-service port: number: 80 - path: /httpd pathType: Prefix backend: service: name: httpd-service port: number: 80 🚀 [4단계] 실행 및 테스트 실습 리소스 적용 kubectl apply -f deploy-nginx.yaml kubectl apply -f deploy-httpd.yaml kubectl apply -f ingress.yaml minikube IP 확인 minikube ip # 예: 192.168.49.2 /etc/hosts 수정 sudo nano /etc/hosts # 아래 줄 추가 192.168.49.2 foo.local curl로 테스트 curl http://foo.local/nginx # nginx 화면 반환 curl http://foo.local/httpd # httpd 페이지 반환 🎯 정리 요약 항목 내용 Ingress HTTP(S) 요청을 Path/Host 기반으로 내부 서비스에 라우팅 Ingress Controller 실제 라우팅 처리 담당 (Nginx 등) /etc/hosts 로컬 DNS 역할 (클러스터 외부 접근 가능하게 설정) 활용 사례 /api, /mlflow, /jupyter 등 URL별 서비스 분리 가능 🧩 실무 팁 Ingress Controller는 단일 진입점 역할 → 도메인 or 경로 기반으로 서비스 분리 가능 실무에서는 TLS 인증서 연동 (Let’s Encrypt, Cert Manager)도 함께 구성 API Gateway 역할로도 확장 가능 (ex. Kong, Ambassador 등) /etc/hosts 설정은 개발 환경 전용 (운영에서는 DNS 서버와 연동) 🔧 MLOps 실전 연결 상황 Ingress 활용 방식 실험 추적 툴 MLflow /mlflow 경로로 노출 노트북 환경 JupyterHub /jupyter 경로로 접속 LLM 서빙 엔드포인트 /v1/chat/completions 등으로 구성 보안 연동 cert-manager + Ingress → TLS 적용</p></div><footer class=entry-footer><span title='2025-06-05 20:06:39 +0900 +0900'>June 5, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [Kubernetes - 3단계 : Ingress & Nginx Controller]" href=https://keonhoban.github.io/mlops-journey/posts/kubernetes/03/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Kubernetes - 2단계: ConfigMap & Secret]</h2></header><div class=entry-content><p>목표
환경 변수와 설정을 외부로 분리해서 관리하는 법 익히기 민감한 정보(비밀번호 등)는 Secret으로 안전하게 주입 애플리케이션에서 ConfigMap/Secret을 환경 변수 또는 파일로 읽는 구조 학습 👉 실습 코드는 🔗 GitHub (Configmap_and_Secret)
🧭 전체 흐름 요약 ① ConfigMap 생성 (일반 설정값) ② Secret 생성 (민감 정보 – base64 인코딩) ③ Pod에 환경 변수로 주입 ④ 컨테이너 안에서 값 확인 (env 명령어) ⑤ 실전 적용 및 보안 주의사항 학습 📂 실습에 사용된 파일 구성 k8s-configmap-secret/ ├── configmap.yaml # 일반 설정값 정의 ├── secret.yaml # 민감 정보 (base64 인코딩) ├── pod-env.yaml # Pod 환경 변수로 주입 └── README.md 📄 주요 YAML 파일 정리 🔹 configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: app-config data: APP_MODE: "production" APP_PORT: "8080" 🔹 secret.yaml apiVersion: v1 kind: Secret metadata: name: app-secret type: Opaque data: DB_PASSWORD: c3VwZXJzZWNyZXQ= # base64 → "supersecret" ✅ 인코딩 방법: echo -n “supersecret” | base64
...</p></div><footer class=entry-footer><span title='2025-06-05 20:06:38 +0900 +0900'>June 5, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [Kubernetes - 2단계: ConfigMap & Secret]" href=https://keonhoban.github.io/mlops-journey/posts/kubernetes/02/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://keonhoban.github.io/mlops-journey/posts/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><p style=margin-top:1rem>© 2025 Keonho Ban | <a href=https://github.com/keonhoban target=_blank>GitHub</a> | <a href=mailto:keonho0510@naver.com>Email</a></p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>