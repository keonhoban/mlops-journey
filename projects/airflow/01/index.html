<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[Airflow - 1단계: 로컬 환경에서 기본 DAG 실행] | 🏔️ MLOps Journey</title>
<meta name=keywords content><meta name=description content='
목표

Docker 기반 Airflow 환경 구성
DAG 파일을 작성하고 실행
UI에서 워크플로우 흐름과 로그를 직접 확인

👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)

🧭 실습 전체 흐름 요약
① Docker 설치 확인
② 공식 Airflow 예제 다운로드
③ docker-compose 실행
④ DAG UI 접속 및 실행
⑤ 로그 확인으로 정상 여부 검증

📁 실습 디렉토리 구조
airflow/
├── dags/              # DAG 파일 작성 위치
├── logs/              # 작업 로그 저장
├── plugins/           # 커스텀 플러그인 (선택)
├── docker-compose.yaml
└── .env               # AIRFLOW_UID 포함

🔧 주요 명령어 정리
# Airflow 예제 다운로드
git clone https://github.com/apache/airflow.git
cd airflow/dev && ./docker-compose/setup.sh

# 또는 간단한 버전
curl -LfO &#39;https://airflow.apache.org/docs/apache-airflow/2.8.2/docker-compose.yaml&#39;
mkdir -p ./dags ./logs ./plugins
echo -e "AIRFLOW_UID=$(id -u)" > .env

# 서비스 실행
docker-compose up -d

# 접속
http://localhost:8080  (ID/PW: airflow / airflow)

💡 샘플 DAG 예시
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

with DAG(dag_id="hello_airflow",
         start_date=datetime(2023, 1, 1),
         schedule_interval="@daily",
         catchup=False) as dag:

    t1 = BashOperator(task_id="print_date", bash_command="date")
    t2 = BashOperator(task_id="say_hello", bash_command="echo &#39;Hello, Airflow!&#39;")
    t1 >> t2

👉 dags/hello_airflow.py 로 저장'><meta name=author content><link rel=canonical href=https://keonhoban.github.io/mlops-journey/projects/airflow/01/><link crossorigin=anonymous href=/mlops-journey/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=https://keonhoban.github.io/mlops-journey/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://keonhoban.github.io/mlops-journey/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://keonhoban.github.io/mlops-journey/favicon-32x32.png><link rel=apple-touch-icon href=https://keonhoban.github.io/mlops-journey/apple-touch-icon.png><link rel=mask-icon href=https://keonhoban.github.io/mlops-journey/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://keonhoban.github.io/mlops-journey/projects/airflow/01/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://keonhoban.github.io/mlops-journey/projects/airflow/01/"><meta property="og:site_name" content="🏔️  MLOps Journey"><meta property="og:title" content="[Airflow - 1단계: 로컬 환경에서 기본 DAG 실행]"><meta property="og:description" content=' 목표
Docker 기반 Airflow 환경 구성 DAG 파일을 작성하고 실행 UI에서 워크플로우 흐름과 로그를 직접 확인 👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 ① Docker 설치 확인 ② 공식 Airflow 예제 다운로드 ③ docker-compose 실행 ④ DAG UI 접속 및 실행 ⑤ 로그 확인으로 정상 여부 검증 📁 실습 디렉토리 구조 airflow/ ├── dags/ # DAG 파일 작성 위치 ├── logs/ # 작업 로그 저장 ├── plugins/ # 커스텀 플러그인 (선택) ├── docker-compose.yaml └── .env # AIRFLOW_UID 포함 🔧 주요 명령어 정리 # Airflow 예제 다운로드 git clone https://github.com/apache/airflow.git cd airflow/dev && ./docker-compose/setup.sh # 또는 간단한 버전 curl -LfO &#39;https://airflow.apache.org/docs/apache-airflow/2.8.2/docker-compose.yaml&#39; mkdir -p ./dags ./logs ./plugins echo -e "AIRFLOW_UID=$(id -u)" > .env # 서비스 실행 docker-compose up -d # 접속 http://localhost:8080 (ID/PW: airflow / airflow) 💡 샘플 DAG 예시 from airflow import DAG from airflow.operators.bash import BashOperator from datetime import datetime with DAG(dag_id="hello_airflow", start_date=datetime(2023, 1, 1), schedule_interval="@daily", catchup=False) as dag: t1 = BashOperator(task_id="print_date", bash_command="date") t2 = BashOperator(task_id="say_hello", bash_command="echo &#39;Hello, Airflow!&#39;") t1 >> t2 👉 dags/hello_airflow.py 로 저장'><meta property="og:locale" content="ko"><meta property="og:type" content="article"><meta property="article:section" content="projects"><meta property="article:published_time" content="2025-06-07T19:29:36+09:00"><meta property="article:modified_time" content="2025-06-07T19:29:36+09:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="[Airflow - 1단계: 로컬 환경에서 기본 DAG 실행]"><meta name=twitter:description content='
목표

Docker 기반 Airflow 환경 구성
DAG 파일을 작성하고 실행
UI에서 워크플로우 흐름과 로그를 직접 확인

👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)

🧭 실습 전체 흐름 요약
① Docker 설치 확인
② 공식 Airflow 예제 다운로드
③ docker-compose 실행
④ DAG UI 접속 및 실행
⑤ 로그 확인으로 정상 여부 검증

📁 실습 디렉토리 구조
airflow/
├── dags/              # DAG 파일 작성 위치
├── logs/              # 작업 로그 저장
├── plugins/           # 커스텀 플러그인 (선택)
├── docker-compose.yaml
└── .env               # AIRFLOW_UID 포함

🔧 주요 명령어 정리
# Airflow 예제 다운로드
git clone https://github.com/apache/airflow.git
cd airflow/dev && ./docker-compose/setup.sh

# 또는 간단한 버전
curl -LfO &#39;https://airflow.apache.org/docs/apache-airflow/2.8.2/docker-compose.yaml&#39;
mkdir -p ./dags ./logs ./plugins
echo -e "AIRFLOW_UID=$(id -u)" > .env

# 서비스 실행
docker-compose up -d

# 접속
http://localhost:8080  (ID/PW: airflow / airflow)

💡 샘플 DAG 예시
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

with DAG(dag_id="hello_airflow",
         start_date=datetime(2023, 1, 1),
         schedule_interval="@daily",
         catchup=False) as dag:

    t1 = BashOperator(task_id="print_date", bash_command="date")
    t2 = BashOperator(task_id="say_hello", bash_command="echo &#39;Hello, Airflow!&#39;")
    t1 >> t2

👉 dags/hello_airflow.py 로 저장'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Projects","item":"https://keonhoban.github.io/mlops-journey/projects/"},{"@type":"ListItem","position":2,"name":"[Airflow - 1단계: 로컬 환경에서 기본 DAG 실행]","item":"https://keonhoban.github.io/mlops-journey/projects/airflow/01/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[Airflow - 1단계: 로컬 환경에서 기본 DAG 실행]","name":"[Airflow - 1단계: 로컬 환경에서 기본 DAG 실행]","description":" 목표\nDocker 기반 Airflow 환경 구성 DAG 파일을 작성하고 실행 UI에서 워크플로우 흐름과 로그를 직접 확인 👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)\n🧭 실습 전체 흐름 요약 ① Docker 설치 확인 ② 공식 Airflow 예제 다운로드 ③ docker-compose 실행 ④ DAG UI 접속 및 실행 ⑤ 로그 확인으로 정상 여부 검증 📁 실습 디렉토리 구조 airflow/ ├── dags/ # DAG 파일 작성 위치 ├── logs/ # 작업 로그 저장 ├── plugins/ # 커스텀 플러그인 (선택) ├── docker-compose.yaml └── .env # AIRFLOW_UID 포함 🔧 주요 명령어 정리 # Airflow 예제 다운로드 git clone https://github.com/apache/airflow.git cd airflow/dev \u0026amp;\u0026amp; ./docker-compose/setup.sh # 또는 간단한 버전 curl -LfO \u0026#39;https://airflow.apache.org/docs/apache-airflow/2.8.2/docker-compose.yaml\u0026#39; mkdir -p ./dags ./logs ./plugins echo -e \u0026#34;AIRFLOW_UID=$(id -u)\u0026#34; \u0026gt; .env # 서비스 실행 docker-compose up -d # 접속 http://localhost:8080 (ID/PW: airflow / airflow) 💡 샘플 DAG 예시 from airflow import DAG from airflow.operators.bash import BashOperator from datetime import datetime with DAG(dag_id=\u0026#34;hello_airflow\u0026#34;, start_date=datetime(2023, 1, 1), schedule_interval=\u0026#34;@daily\u0026#34;, catchup=False) as dag: t1 = BashOperator(task_id=\u0026#34;print_date\u0026#34;, bash_command=\u0026#34;date\u0026#34;) t2 = BashOperator(task_id=\u0026#34;say_hello\u0026#34;, bash_command=\u0026#34;echo \u0026#39;Hello, Airflow!\u0026#39;\u0026#34;) t1 \u0026gt;\u0026gt; t2 👉 dags/hello_airflow.py 로 저장\n","keywords":[],"articleBody":" 목표\nDocker 기반 Airflow 환경 구성 DAG 파일을 작성하고 실행 UI에서 워크플로우 흐름과 로그를 직접 확인 👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)\n🧭 실습 전체 흐름 요약 ① Docker 설치 확인 ② 공식 Airflow 예제 다운로드 ③ docker-compose 실행 ④ DAG UI 접속 및 실행 ⑤ 로그 확인으로 정상 여부 검증 📁 실습 디렉토리 구조 airflow/ ├── dags/ # DAG 파일 작성 위치 ├── logs/ # 작업 로그 저장 ├── plugins/ # 커스텀 플러그인 (선택) ├── docker-compose.yaml └── .env # AIRFLOW_UID 포함 🔧 주요 명령어 정리 # Airflow 예제 다운로드 git clone https://github.com/apache/airflow.git cd airflow/dev \u0026\u0026 ./docker-compose/setup.sh # 또는 간단한 버전 curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.8.2/docker-compose.yaml' mkdir -p ./dags ./logs ./plugins echo -e \"AIRFLOW_UID=$(id -u)\" \u003e .env # 서비스 실행 docker-compose up -d # 접속 http://localhost:8080 (ID/PW: airflow / airflow) 💡 샘플 DAG 예시 from airflow import DAG from airflow.operators.bash import BashOperator from datetime import datetime with DAG(dag_id=\"hello_airflow\", start_date=datetime(2023, 1, 1), schedule_interval=\"@daily\", catchup=False) as dag: t1 = BashOperator(task_id=\"print_date\", bash_command=\"date\") t2 = BashOperator(task_id=\"say_hello\", bash_command=\"echo 'Hello, Airflow!'\") t1 \u003e\u003e t2 👉 dags/hello_airflow.py 로 저장\n→ UI 접속 후 Graph View → hello_airflow DAG 확인\n→ 실행 후 Task 클릭 → Logs 탭에서 출력 확인 가능\n🧼 에러 대처 팁 문제 상황 해결 방법 포트 충돌 docker-compose.yaml에서 포트 변경 docker 데몬 오류 sudo systemctl restart docker UI 로그인 실패 기본 계정 airflow / airflow 확인 DAG 인식 안됨 .py 파일이 dags/ 하위에 있는지 확인 🧩 실무 팁 catchup=False: 과거 스케줄 자동 실행 방지 start_date: 항상 과거 시점 지정해야 DAG가 실행됨 DAG 파일에 주석으로 흐름/설명 남겨두면 협업에 유리 모든 DAG는 task_id 명확히 지정해야 UI에서 추적 쉬움 🔧 MLOps 실전 연결 MLOps 구성 요소 Airflow 활용 방안 데이터 수집 / 전처리 DAG로 정기적 수집/정제 처리 모델 학습 / 서빙 각 단계별 Task 정의로 자동화 MLflow / Kubeflow 연동 구성으로 추적/실험 관리 CI/CD 파이프라인 테스트 → 빌드 → 배포까지 워크플로우 구성 가능 ","wordCount":"308","inLanguage":"en","datePublished":"2025-06-07T19:29:36+09:00","dateModified":"2025-06-07T19:29:36+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://keonhoban.github.io/mlops-journey/projects/airflow/01/"},"publisher":{"@type":"Organization","name":"🏔️  MLOps Journey","logo":{"@type":"ImageObject","url":"https://keonhoban.github.io/mlops-journey/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://keonhoban.github.io/mlops-journey/ accesskey=h title="🏔️  MLOps Journey (Alt + H)">🏔️ MLOps Journey</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://keonhoban.github.io/mlops-journey/ title="🏠 Home"><span>🏠 Home</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/projects/ title="📂 Projects"><span>📂 Projects</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/posts/ title="📝 Blog"><span>📝 Blog</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/about/ title="🧗 About"><span>🧗 About</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/categories/ title="📖 Categories"><span>📖 Categories</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://keonhoban.github.io/mlops-journey/>Home</a>&nbsp;»&nbsp;<a href=https://keonhoban.github.io/mlops-journey/projects/>Projects</a></div><h1 class="post-title entry-hint-parent">[Airflow - 1단계: 로컬 환경에서 기본 DAG 실행]</h1><div class=post-meta><span title='2025-06-07 19:29:36 +0900 +0900'>June 7, 2025</span>&nbsp;·&nbsp;2 min</div></header><div class=post-content><blockquote><p>목표</p><ol><li>Docker 기반 Airflow 환경 구성</li><li>DAG 파일을 작성하고 실행</li><li>UI에서 워크플로우 흐름과 로그를 직접 확인</li></ol></blockquote><p>👉 실습 코드는 <a href=https://github.com/keonhoban/mlops-infra-labs/tree/main/airflow/01_DAG_basic>🔗 GitHub (Mlflow - Tracking + FastAPI)</a></p><hr><h2 id=-실습-전체-흐름-요약>🧭 실습 전체 흐름 요약<a hidden class=anchor aria-hidden=true href=#-실습-전체-흐름-요약>#</a></h2><pre tabindex=0><code>① Docker 설치 확인
② 공식 Airflow 예제 다운로드
③ docker-compose 실행
④ DAG UI 접속 및 실행
⑤ 로그 확인으로 정상 여부 검증
</code></pre><hr><h2 id=-실습-디렉토리-구조>📁 실습 디렉토리 구조<a hidden class=anchor aria-hidden=true href=#-실습-디렉토리-구조>#</a></h2><pre tabindex=0><code>airflow/
├── dags/              # DAG 파일 작성 위치
├── logs/              # 작업 로그 저장
├── plugins/           # 커스텀 플러그인 (선택)
├── docker-compose.yaml
└── .env               # AIRFLOW_UID 포함
</code></pre><hr><h2 id=-주요-명령어-정리>🔧 주요 명령어 정리<a hidden class=anchor aria-hidden=true href=#-주요-명령어-정리>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Airflow 예제 다운로드</span>
</span></span><span style=display:flex><span>git clone https://github.com/apache/airflow.git
</span></span><span style=display:flex><span>cd airflow/dev <span style=color:#f92672>&amp;&amp;</span> ./docker-compose/setup.sh
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 또는 간단한 버전</span>
</span></span><span style=display:flex><span>curl -LfO <span style=color:#e6db74>&#39;https://airflow.apache.org/docs/apache-airflow/2.8.2/docker-compose.yaml&#39;</span>
</span></span><span style=display:flex><span>mkdir -p ./dags ./logs ./plugins
</span></span><span style=display:flex><span>echo -e <span style=color:#e6db74>&#34;AIRFLOW_UID=</span><span style=color:#66d9ef>$(</span>id -u<span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span> &gt; .env
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 서비스 실행</span>
</span></span><span style=display:flex><span>docker-compose up -d
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 접속</span>
</span></span><span style=display:flex><span>http://localhost:8080  <span style=color:#f92672>(</span>ID/PW: airflow / airflow<span style=color:#f92672>)</span>
</span></span></code></pre></div><hr><h2 id=-샘플-dag-예시>💡 샘플 DAG 예시<a hidden class=anchor aria-hidden=true href=#-샘플-dag-예시>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> airflow <span style=color:#f92672>import</span> DAG
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> airflow.operators.bash <span style=color:#f92672>import</span> BashOperator
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> datetime <span style=color:#f92672>import</span> datetime
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> DAG(dag_id<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;hello_airflow&#34;</span>,
</span></span><span style=display:flex><span>         start_date<span style=color:#f92672>=</span>datetime(<span style=color:#ae81ff>2023</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>         schedule_interval<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;@daily&#34;</span>,
</span></span><span style=display:flex><span>         catchup<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>) <span style=color:#66d9ef>as</span> dag:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    t1 <span style=color:#f92672>=</span> BashOperator(task_id<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;print_date&#34;</span>, bash_command<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;date&#34;</span>)
</span></span><span style=display:flex><span>    t2 <span style=color:#f92672>=</span> BashOperator(task_id<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;say_hello&#34;</span>, bash_command<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;echo &#39;Hello, Airflow!&#39;&#34;</span>)
</span></span><span style=display:flex><span>    t1 <span style=color:#f92672>&gt;&gt;</span> t2
</span></span></code></pre></div><blockquote><p>👉 dags/hello_airflow.py 로 저장</p><p>→ UI 접속 후 Graph View → <code>hello_airflow</code> DAG 확인</p><p>→ 실행 후 Task 클릭 → Logs 탭에서 출력 확인 가능</p></blockquote><hr><h2 id=-에러-대처-팁>🧼 에러 대처 팁<a hidden class=anchor aria-hidden=true href=#-에러-대처-팁>#</a></h2><table><thead><tr><th>문제 상황</th><th>해결 방법</th></tr></thead><tbody><tr><td>포트 충돌</td><td><code>docker-compose.yaml</code>에서 포트 변경</td></tr><tr><td>docker 데몬 오류</td><td><code>sudo systemctl restart docker</code></td></tr><tr><td>UI 로그인 실패</td><td>기본 계정 airflow / airflow 확인</td></tr><tr><td>DAG 인식 안됨</td><td><code>.py</code> 파일이 <code>dags/</code> 하위에 있는지 확인</td></tr></tbody></table><hr><h2 id=-실무-팁>🧩 실무 팁<a hidden class=anchor aria-hidden=true href=#-실무-팁>#</a></h2><ul><li><code>catchup=False</code>: 과거 스케줄 자동 실행 방지</li><li><code>start_date</code>: <strong>항상 과거 시점</strong> 지정해야 DAG가 실행됨</li><li>DAG 파일에 주석으로 흐름/설명 남겨두면 협업에 유리</li><li>모든 DAG는 <code>task_id</code> 명확히 지정해야 UI에서 추적 쉬움</li></ul><hr><h2 id=-mlops-실전-연결>🔧 MLOps 실전 연결<a hidden class=anchor aria-hidden=true href=#-mlops-실전-연결>#</a></h2><table><thead><tr><th>MLOps 구성 요소</th><th>Airflow 활용 방안</th></tr></thead><tbody><tr><td>데이터 수집 / 전처리</td><td>DAG로 정기적 수집/정제 처리</td></tr><tr><td>모델 학습 / 서빙</td><td>각 단계별 Task 정의로 자동화</td></tr><tr><td>MLflow / Kubeflow</td><td>연동 구성으로 추적/실험 관리</td></tr><tr><td>CI/CD 파이프라인</td><td>테스트 → 빌드 → 배포까지 워크플로우 구성 가능</td></tr></tbody></table></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><p style=margin-top:1rem>© 2025 Keonho Ban | <a href=https://github.com/keonhoban target=_blank>GitHub</a> | <a href=mailto:keonho0510@naver.com>Email</a></p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>