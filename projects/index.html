<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Projects | 🏔️ MLOps Journey</title>
<meta name=keywords content><meta name=description content="Projects - 🏔️  MLOps Journey"><meta name=author content><link rel=canonical href=https://keonhoban.github.io/mlops-journey/projects/><link crossorigin=anonymous href=/mlops-journey/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF+13Dyqob6ASlTrTye8=" rel="preload stylesheet" as=style><link rel=icon href=https://keonhoban.github.io/mlops-journey/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://keonhoban.github.io/mlops-journey/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://keonhoban.github.io/mlops-journey/favicon-32x32.png><link rel=apple-touch-icon href=https://keonhoban.github.io/mlops-journey/apple-touch-icon.png><link rel=mask-icon href=https://keonhoban.github.io/mlops-journey/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://keonhoban.github.io/mlops-journey/projects/index.xml><link rel=alternate hreflang=en href=https://keonhoban.github.io/mlops-journey/projects/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://keonhoban.github.io/mlops-journey/projects/"><meta property="og:site_name" content="🏔️  MLOps Journey"><meta property="og:title" content="Projects"><meta property="og:locale" content="ko"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Projects"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Projects","item":"https://keonhoban.github.io/mlops-journey/projects/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://keonhoban.github.io/mlops-journey/ accesskey=h title="🏔️  MLOps Journey (Alt + H)">🏔️ MLOps Journey</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://keonhoban.github.io/mlops-journey/ title="🏠 Home"><span>🏠 Home</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/projects/ title="📂 Projects"><span class=active>📂 Projects</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/posts/ title="📝 Blog"><span>📝 Blog</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/about/ title="🧗 About"><span>🧗 About</span></a></li><li><a href=https://keonhoban.github.io/mlops-journey/categories/ title="📖 Categories"><span>📖 Categories</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://keonhoban.github.io/mlops-journey/>Home</a></div><h1>Projects</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Airflow 기초 자동화 - Airflow → MLflow → FastAPI]</h2></header><div class=entry-content><p>🧭 전체 흐름 예시 [AIRFLOW DAG 실행] ↓ [train_mlflow.py] - iris 모델 학습 - 파라미터/메트릭 로깅 - 모델 Registry 등록 ↓ [promote_mlflow.py] - 최신 모델을 Production으로 전환 ↓ [FastAPI] - models:/IrisModel/Production → 실시간 예측 👉 실습 코드는 🔗 GitHub (Airflow + MLflow + FastAPI)
✅ [1단계] 프로젝트 기본 폴더 구조 설계 📁 1. 전체 디렉토리 구성도 mlops_project/ ├── airflow/ 🛫 Airflow 설정 및 DAG 스케줄러 │ ├── dags/ ← DAG 정의 디렉토리 │ │ └── train_with_mlflow.py ← 학습 DAG (MLflow 연동) │ ├── Dockerfile.airflow ← Airflow용 Dockerfile │ ├── requirements.txt ← Airflow 의존성 │ └── .dockerignore │ ├── fastapi/ ⚡ FastAPI 예측 API 서버 │ ├── app/ │ │ └── main.py ← 모델 서빙 엔드포인트 │ ├── Dockerfile.api ← FastAPI용 Dockerfile │ ├── requirements.txt ← FastAPI 의존성 │ └── .dockerignore │ ├── ml_code/ 🧠 ML 학습 및 프로모션 코드 │ ├── train_mlflow.py ← 모델 학습 및 MLflow 로깅 │ └── promte_mlflow.py ← 모델 프로모션 (Staging → Production) │ ├── mlflow_store/ 🗂️ MLflow 저장소 경로 (볼륨) │ ├── Dockerfile.mlflow ← MLflow 서버 커스터마이징 │ ├── mlflow.db ← Model Registry DB (sqlite) │ ├── mlruns/ ← 실험 로그 디렉토리 │ ├── artifacts/ ← 모델 아티팩트 저장소 │ └── .dockerignore │ ├── docker-compose.yaml 🧩 전체 서비스 구성 정의 ├── .env 🔐 민감 정보 (.env로 분리) ├── README.md 📝 전체 프로젝트 문서화 ├── .gitignore └── .dockerignore ✅ [2단계] docker-compose.yaml 통합 구성 🧭 구성 목표 서비스명 설명 포트 airflow DAG 실행 환경 (webserver/scheduler) 8080 postgres Airflow 메타데이터 저장용 DB 내부 통신 mlflow MLflow UI + Registry 기능 5000 fastapi 추론 API 서버 (모델 로딩) 8000 이미지 사용시 주의 (UI만 제공하는 이미지 존재) 📄 docker-compose.yaml 전체 예시 version: '3.8' services: # 📦 PostgreSQL: Airflow 메타데이터 저장용 DB postgres: image: postgres:13 container_name: postgres env_file: - .env # ← 민감정보 분리 (아이디/비번) environment: POSTGRES_USER: ${POSTGRES_USER} POSTGRES_PASSWORD: ${POSTGRES_PASSWORD} POSTGRES_DB: ${POSTGRES_DB} volumes: # ← 코드/데이터 공유 및 영속성 보장 - postgres_data:/var/lib/postgresql/data # ← DB 데이터 유지 (재시작 대비) # 🛫 Airflow: DAG 스케줄러 및 태스크 실행 airflow: build: context: ./airflow # → Airflow 전용 Dockerfile 경로 dockerfile: Dockerfile.airflow container_name: airflow command: standalone # → 로컬 테스트용 간단 실행 명령 # (- Scheduler + Webserver + DB 초기화까지 자동으로 한번에 실행) # (- 실무/운영에서는 airflow-webserver, airflow-scheduler 필드 분리) ports: - "8080:8080" # → Airflow 웹 UI (localhost:8080) depends_on: - postgres # → DB가 먼저 올라와야 Airflow 시작 가능 env_file: - .env environment: # Airflow 메타데이터 DB 연결 주소 AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW__CORE__SQL_ALCHEMY_CONN} # Airflow 예제 DAG 불러올지 여부 AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES} MLFLOW_TRACKING_URI: http://mlflow:5000 # → DAG 코드에서 MLflow 연동 volumes: - ./airflow/dags:/opt/airflow/dags # DAG 파일 mount - ./ml_code:/opt/airflow/ml_code # 학습 코드 공유 - ./mlflow_store:/mlflow # 모델 저장소 공유 # 🔬 MLflow: 실험 추적 + 모델 레지스트리 서버 mlflow: build: context: ./mlflow_store # 커스텀 Dockerfile 위치 dockerfile: Dockerfile.mlflow ports: - "5000:5000" # → MLflow UI (localhost:5000) volumes: - ./mlflow_store:/mlflow # 실험 로그 + DB + artifacts 저장 environment: - MLFLOW_TRACKING_URI=http://0.0.0.0:5000 # 내부 컨테이너 기준 URI # ⚡ FastAPI: 모델 서빙 API fastapi: build: context: ./fastapi dockerfile: Dockerfile.api container_name: fastapi ports: - "8000:8000" # → 예측 API 엔드포인트 (localhost:8000) volumes: - ./fastapi/app:/app/app # FastAPI app 디렉토리 mount - ./ml_code:/app/ml_code # 학습/모델 코드 공유 - ./mlflow_store:/mlflow # 저장된 모델 불러오기 위한 mount # 🗂️ 볼륨 정의 (Postgres DB 영속성 유지) volumes: postgres_data: 🎁 추가로 해야 할 것 Airflow 첫 실행 후엔 보통 관리자 계정 생성도 해줘야 함: # airflow 컨테이너 접속 docker exec -it airflow bash # 관리자 계정 생성 airflow users create \ --username airflow \ --password airflow \ --firstname Keoho \ --lastname Ban \ --role Admin \ --email airflow@example.com 🔁 [구축 Tip] Airflow, FastAPI, MLflow 간 공유 볼륨 구조 확인 공유 리소스 설명 ./mlflow_store:/mlflow (MLflow) MLflow 서버가 쓰는 로그/모델 저장소 ./mlflow_store:/mlflow (Airflow) 학습 후 모델 저장 위치 공유 ./mlflow_store:/mlflow (FastAPI) 모델 추론 시 로드 경로 공유 ➡ 경로 통일성이 매우 중요함! 지금은 모두 ./mlflow로 공유 (./mlflow 하위에 /mlruns 존재)
...</p></div><footer class=entry-footer><span title='2025-06-13 20:58:51 +0900 +0900'>June 13, 2025</span>&nbsp;·&nbsp;8 min</footer><a class=entry-link aria-label="post link to [Airflow 기초 자동화 - Airflow → MLflow → FastAPI]" href=https://keonhoban.github.io/mlops-journey/projects/mlops_pipeline/basic/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[MLflow : Tracking + FastAPI 연동]</h2></header><div class=entry-content><p>목표
MLflow Tracking Server 구성 실험(Experiment), 파라미터, 메트릭, 아티팩트 기록 모델 등록 → Stage 이동 → API 연동까지 👉 실습 코드는 🔗 GitHub (Mlflow - Tracking + FastAPI)
🧭 실습 전체 흐름 요약 [1단계] MLflow Tracking Server 구성 (로컬 환경에서 실행) [2단계] 실험 실행 (train.py) → 모델 학습, 기록 [3단계] 모델 등록 및 Stage 설정 (Production 이동) [4단계] FastAPI 연동 → 예측 API 서비스 🧩 실습 디렉토리 예시 mlops-mlflow/ ├── app/ │ ├── train.py # 모델 훈련 및 실험 기록 │ └── model.pkl # 저장된 모델 ├── mlruns/ # 실험 데이터 자동 생성 ├── fastapi_app/ │ └── app.py # FastAPI 예측 API ├── Dockerfile (선택) └── README.md ✅ [1단계] MLflow 설치 & 실행 🛠️ 가상 환경 설정 # 1. venv 설치 sudo apt install python3-venv -y # 2. 가상환경 생성 python3 -m venv .venv # 3. 가상환경 활성화 source .venv/bin/activate # 4. 패키지 설치 pip install mlflow scikit-learn pandas fastapi uvicorn # 5. 나갈 때 deactivate 🔧 MLflow 서버 실행 mlflow ui --port 5000 # http://localhost:5000 에서 UI 확인 🧪 [2단계] 실험 실행 (train.py) # app/train.py import mlflow import mlflow.sklearn from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split # MLflow 설정 mlflow.set_tracking_uri("http://localhost:5000") mlflow.set_experiment("iris-rf-exp") with mlflow.start_run(): iris = load_iris() X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2) clf = RandomForestClassifier(n_estimators=100, max_depth=3) clf.fit(X_train, y_train) acc = clf.score(X_test, y_test) mlflow.log_param("n_estimators", 100) mlflow.log_param("max_depth", 3) mlflow.log_metric("accuracy", acc) mlflow.sklearn.log_model(clf, "model") # 실험 실행 python app/train.py 실험이 끝나면 mlruns/ 폴더에 실험 기록 및 모델이 저장
...</p></div><footer class=entry-footer><span title='2025-06-06 15:14:40 +0900 +0900'>June 6, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [MLflow : Tracking + FastAPI 연동]" href=https://keonhoban.github.io/mlops-journey/projects/mlflow/01/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[Terraform] EC2 & S3 리소스 자동화 구축</h2></header><div class=entry-content><p>Terraform 도입 배경
수동 콘솔 설정은 반복성과 확장성에 한계가 있음
Terraform은 버전 관리가 가능한 코드형 인프라(IaC) 로,
협업 시 동일한 환경을 빠르게 구축할 수 있는 강점을 가짐
이번 실습 목표
IAM 사용자 생성부터 EC2 & S3 자동화까지, Terraform 기반 인프라 구축 전체 흐름을 실습
👉 실습 디렉토리 전체 코드 🔗 GitHub – terraform/01-ec2-s3-basic
🔭 전체 실습 흐름 요약 [1단계] IAM 사용자 생성 (Access Key 발급) [2단계] AWS CLI 설치 및 configure [3단계] Terraform 설치 [4단계] 실습 디렉토리 + 코드 구성 [5단계] terraform init → plan → apply → EC2 & S3 생성 🧩 실습 준비 체크리스트 항목 설명 AWS 계정 루트 계정으로 로그인 후, IAM 사용자 생성 IAM 사용자 프로그래밍 접근 + AdministratorAccess 부여 AWS CLI aws configure로 API 키 등록 Terraform CLI 설치 필요 (OS별 방법 상이) SSH 키페어 EC2 접속용 .pem 키 직접 생성 🪪 1단계: IAM 사용자 생성 AWS 콘솔 → IAM → 사용자 추가 액세스 유형: 프로그래밍 방식 액세스 체크 권한: AdministratorAccess 정책 부여 실습 목적이므로 관리자 권한줬지만, 이후 필요시 Least Privilege 원칙 적용 ex) EC2FullAccess, S3FullAccess 생성 후 Access Key ID, Secret Access Key 복사 (중요!) ⚙️ 2단계: AWS CLI 설치 및 구성 ✅ 설치 명령어 🔗 AWS CLI 설치 공식 문서
...</p></div><footer class=entry-footer><span title='2025-06-04 12:51:32 +0900 +0900'>June 4, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [Terraform] EC2 & S3 리소스 자동화 구축" href=https://keonhoban.github.io/mlops-journey/projects/terraform/01/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[코드업] 기초 100제. 십자 뒤집기, 설탕과자 뽑기, 성실한 개미</h2></header><div class=entry-content><p>📘 CodeUp 문제 요약 🔹 6096 - 십자 뒤집기 https://codeup.kr/problem.php?id=6096
📝 바둑판(19x19)에서 특정 좌표를 기준으로 가로줄, 세로줄을 뒤집기
board = [list(map(int, input().split())) for _ in range(19)] n = int(input()) for _ in range(n): x, y = map(int, input().split()) x -= 1 y -= 1 for j in range(19): board[x][j] = 1 - board[x][j] board[j][y] = 1 - board[j][y] for row in board: print(' '.join(map(str, row))) 🔑 포인트 정리
배열 순서: board[row][col] 좌표 보정: x -= 1, y -= 1 (1-based → 0-based) 1 - x: 값 반전 (0 ↔ 1) 중심 좌표는 두 번 뒤집히므로 원래 값 유지됨 🔹 6097 – 설탕 과자 뽑기 https://codeup.kr/problem.php?id=6097
...</p></div><footer class=entry-footer><span title='2025-05-10 12:25:32 +0900 +0900'>May 10, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [코드업] 기초 100제. 십자 뒤집기, 설탕과자 뽑기, 성실한 개미" href=https://keonhoban.github.io/mlops-journey/projects/online_judge/01/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[셸 스크립트] 04. Monitoring</h2></header><div class=entry-content><p>✅ 디스크 사용률 초과 시 자동 로그 정리 운영 중 디스크 용량 초과로 장애가 발생하기 전에, 서버가 스스로 로그를 정리하도록 만드는 자동화 스크립트입니다.
1. 🎯 목표 ✅ 디스크 사용률이 일정 기준을 초과하면, ✅ 지정된 경로에서 오래된 로그 파일을 자동으로 삭제 ✅ 삭제된 파일은 로그로 기록 이 스크립트 하나로 디스크 감시 + 자동 삭제 + 운영 기록 보관까지 가능합니다.
2. 🧠 전체 구조 흐름 df → 각 디스크 사용률 확인 ↓ 사용률이 THRESHOLD 이상이면 ↓ 지정 경로에서 mtime 기반 오래된 로그 탐색 ↓ 삭제 + 로그 기록 예시 실행 흐름:
...</p></div><footer class=entry-footer><span title='2025-04-25 11:08:02 +0900 +0900'>April 25, 2025</span>&nbsp;·&nbsp;3 min</footer><a class=entry-link aria-label="post link to [셸 스크립트] 04. Monitoring" href=https://keonhoban.github.io/mlops-journey/projects/shell_script/04/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[셸 스크립트] 03. Deployment</h2></header><div class=entry-content><p>✅ 모델 패키징 및 배포 1. 🎯 목표 머신러닝 모델을 운영 환경에 안전하게 배포하기 위한
모델 파일 점검 → 압축 → 복원 → 원격 배포 과정을
하나의 통합 스크립트로 자동화합니다.
2. 🧠 흐름 요약 [모델 디렉토리 점검] ↓ [모델 압축 (archive)] ↓ [필요시 복원 (restore)] ↓ [배포 서버에 SCP 전송 (deploy)] 3. 🔧 전체 코드 (주석 포함) #!/usr/bin/env bash set -euo pipefail MODE=${1:-"check"} # check, archive, restore, deploy TARGET_DIR=${2:-"/opt/ml/models"} ARCHIVE_FILE=${3:-"models.tar.gz"} REQUIRED_FILES=("model.py" "requirements.txt" "config.yaml") # 간단한 로그 함수 log() { echo "[$(date '+%F %T')] $1"; } # 1. 필수 파일 존재 여부 확인 check() { [[ -d "$TARGET_DIR" ]] || { log "Missing dir: $TARGET_DIR"; exit 1; } for file in "${REQUIRED_FILES[@]}"; do [[ -e "$TARGET_DIR/$file" ]] || { log "Missing file: $file"; exit 1; } done log "File check complete" } # 2. 모델 디렉토리 압축 archive() { mkdir -p "$TARGET_DIR" tar -czf "$ARCHIVE_FILE" -C "$TARGET_DIR" . log "Archive created: $ARCHIVE_FILE" } # 3. 압축된 모델 복원 restore() { [[ -e "$ARCHIVE_FILE" ]] || { log "Missing archive: $ARCHIVE_FILE"; exit 1; } mkdir -p "$TARGET_DIR" tar -xzf "$ARCHIVE_FILE" -C "$TARGET_DIR" log "Restore done to $TARGET_DIR" } # 4. 모델 원격 서버로 전송 deploy() { USER=${4:-"ubuntu"} HOST=${5:-"127.0.0.1"} DEST=${6:-"/opt/ml/models"} scp "$ARCHIVE_FILE" "$USER@$HOST:$DEST" \ && log "Deployed to $HOST" \ || { log "Deployment failed"; exit 1; } } # 실행 분기 case "$MODE" in check) check ;; archive) archive ;; restore) restore ;; deploy) deploy "$@" ;; *) echo "Usage: $0 [check|archive|restore|deploy] [target_dir] [archive_file] [user] [host] [remote_path]" exit 1 ;; esac 4. 📌 주요 기능 설명 기능 설명 check 모델 디렉토리에 필수 파일 존재 여부 확인 archive 디렉토리 전체 압축 → .tar.gz 생성 restore 압축 해제 후 원상 복원 deploy scp로 원격 서버 전송, 사용자/호스트 지정 가능 log() 모든 결과 시간 기록 포함, 운영 추적 가능 5. 🛠️ 실무 활용 & 확장 포인트 확장 방향 설명 배포 자동화 CI/CD 파이프라인에서 이 스크립트 호출 환경 설정 외부화 .env 파일로 사용자/호스트 설정 관리 배포 확인 로직 추가 ssh "$HOST" "ls $DEST"로 전송 검증 자동화 전송 보안 강화 scp → rsync, ssh key 연동, Ansible 등으로 확장 6. 🔧 MLOps 실전 연결 MLOps 흐름 적용 예시 모델 체크포인트 보존 archive를 통해 학습 모델 압축 저장 모델 서빙 환경 이관 deploy를 통해 서버 간 모델 전송 모델 리포지터리 백업 restore로 필요시 복원 가능 GitHub Actions + SCP 배포 배포 자동화 스크립트에 직접 연동 가능 7. ✅ 정리 단순히 scp로 모델을 보내는 스크립트가 아니라,
...</p></div><footer class=entry-footer><span title='2025-04-25 11:07:57 +0900 +0900'>April 25, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [셸 스크립트] 03. Deployment" href=https://keonhoban.github.io/mlops-journey/projects/shell_script/03/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[셸 스크립트] 02. Data Processing</h2></header><div class=entry-content><p>✅ 오래된 로그 정리 및 보관 1. 🎯 목표 지정한 경로의 오래된 로그 파일을 삭제하거나, 압축 보관하는
모드 기반 자동화 스크립트입니다.
2. 🧠 흐름 요약 입력: [모드] [경로] [로그 위치] [기준 날짜] ↓ [clean] → 오래된 로그 삭제 + 로그 기록 [archive] → 오래된 로그 압축 백업 3. 🔧 전체 코드 #!/usr/bin/env bash set -euo pipefail # 인자 처리 MODE=${1:-"clean"} TARGET_PATH=${2:-"/var/log"} LOG_DIR=${3:-"/backup/logs"} DAYS_OLD=${4:-30} DATE=$(date '+%F') mkdir -p "$LOG_DIR" if [[ "$MODE" == "clean" ]]; then find "$TARGET_PATH" -type f -mtime +$DAYS_OLD -exec ls -lh {} \; > "$LOG_DIR/cleaned_$DATE.log" find "$TARGET_PATH" -type f -mtime +$DAYS_OLD -delete echo "[CLEAN] Done: $DATE" elif [[ "$MODE" == "archive" ]]; then ARCHIVE="$LOG_DIR/logs_${DAYS_OLD}days_$DATE.tar.gz" find "$TARGET_PATH" -type f -name "*.log" -mtime +$DAYS_OLD -print | tar czf "$ARCHIVE" -T - || echo "No logs to archive" echo "[ARCHIVE] Done: $ARCHIVE" else echo "Usage: $0 [clean|archive] [path] [log_dir] [days]" exit 1 fi 4. 💡 주요 기능 설명 기능 설명 MODE 인자 clean / archive 모드 분기 → 멀티 용도 스크립트 tar -T - find 결과를 안전하게 바로 압축 ls -lh → 로그 보관 삭제 전 파일 목록을 보관 → 감사 로그 Usage 출력 잘못된 인자 대응 → 실전 운영 스크립트 기준 충족 5. 🛠️ 실무 활용 & 확장 포인트 확장 방법 crontab 자동화 0 1 * * * /path/cleaner.sh clean /var/log /backup/logs 30 확장자 다양화 -name "*.log" -o -name "*.out" 등으로 확장 압축 후 업로드 aws s3 cp "$ARCHIVE" s3://log-backup-bucket/ logrotate와 연동 /etc/logrotate.d → 일정 주기 log 정리 후 이 스크립트 사용 6. 🔧 MLOps 실무 연결 흐름 적용 예시 ML 학습 로그 정리 /opt/ml/logs 폴더 주기적 clean 모델 기록 정리 mlruns/ 내 오래된 run data 보관 Kubeflow pipeline 로그 정리 /var/log/kubeflow/* 압축 보관 7. ✅ 정리 단순한 로그 정리가 아니라,
...</p></div><footer class=entry-footer><span title='2025-04-24 23:20:08 +0900 +0900'>April 24, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [셸 스크립트] 02. Data Processing" href=https://keonhoban.github.io/mlops-journey/projects/shell_script/02/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>[셸 스크립트] 01. Backup</h2></header><div class=entry-content><p>✅ 하루 한 번, 자동 백업 1. 🎯 목표 서버에서 특정 디렉토리를 매일 자동으로 백업하고,
로그까지 남기는 안정적인 자동화 스크립트를 작성합니다.
2. 🧠 전체 흐름 요약 [백업할 경로] → [압축 tar.gz 생성] → [로그 기록] → [저장 경로 이동] 3. 🔧 전체 스크립트 (주석 포함) #!/usr/bin/env bash set -euo pipefail # 백업할 경로와 저장 경로 (인자 or 기본값) SRC_PATH=${1:-"/home/ubuntu"} DST_PATH=${2:-"/backup/ubuntu_backup"} # 오늘 날짜 기준 파일명 생성 ARCHIVE_NAME="$(date '+%F').tar.gz" LOG_FILE="$DST_PATH/backup.log" # 실패 시 로그에 남기기 trap 'echo "[ERROR] Backup failed!" >> $LOG_FILE' ERR # 백업 경로 미존재 시 생성 mkdir -p "$DST_PATH" # 실제 백업 수행 if [[ -d "$SRC_PATH" ]]; then echo "[INFO] Backup started at $(date)" >> "$LOG_FILE" tar -czf "$DST_PATH/$ARCHIVE_NAME" -C "$SRC_PATH" . || exit 1 echo "[INFO] Backup success: $ARCHIVE_NAME" >> "$LOG_FILE" else echo "[ERROR] Source path not found: $SRC_PATH" >> "$LOG_FILE" exit 1 fi 4. 💡 핵심 설계 포인트 요소 설계 이유 set -euo pipefail 예외 발생 즉시 종료 + 예측 불가능한 오류 방지 ${1:-} 인자 없을 시 기본값으로 동작 → 재사용성 강화 trap '...' ERR 실패 시 로그 자동 기록 → 디버깅 편의 tar -czf 표준 압축 포맷으로 백업 mkdir -p 실행 시 폴더 미존재 문제 예방 5. 🛠️ 실무 적용 & 확장 아이디어 확장 방법 매일 자동 실행 crontab -e → 0 2 * * * /path/to/script.sh 백업 후 업로드 aws s3 cp $ARCHIVE_NAME s3://bucket/path/ 환경 설정 분리 .env 파일에서 SRC/DST 설정 불러오기 백업 알림 mail or 슬랙 알림 연동 6. 🔧 MLOps 실전 연결 포인트 흐름 적용 예시 학습 결과 자동 백업 모델 checkpoint 자동 저장 실험 로그 보존 ~/mlruns 디렉토리 백업 환경 복원 대비 Dockerfile, .env 백업 7. ✅ 정리 작은 자동화지만, 이 스크립트 하나로
...</p></div><footer class=entry-footer><span title='2025-04-24 23:19:56 +0900 +0900'>April 24, 2025</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to [셸 스크립트] 01. Backup" href=https://keonhoban.github.io/mlops-journey/projects/shell_script/01/></a></article></main><footer class=footer><p style=margin-top:1rem>© 2025 Keonho Ban | <a href=https://github.com/keonhoban target=_blank>GitHub</a> | <a href=mailto:keonho0510@naver.com>Email</a></p></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>